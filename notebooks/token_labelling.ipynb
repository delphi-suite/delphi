{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
<<<<<<< HEAD
<<<<<<< HEAD
=======
>>>>>>> a71e2a8 (improve notebook explanation)
    "# Giving tokens a label - How to categorize tokens\n",
    "\n",
    "\n",
    "The first part of this Notebook contains elements that explain how to label tokens and how the functions work.\n",
    "\n",
    "The second part shows how all tokens are labelled that are used for our delphi language models.3\n",
    "\n",
    "# 1) How to use the token labelling functions"
<<<<<<< HEAD
=======
    "# How to label tokens"
>>>>>>> bf8ef79 (add notebook)
=======
>>>>>>> a71e2a8 (improve notebook explanation)
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
=======
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
>>>>>>> bf8ef79 (add notebook)
=======
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
>>>>>>> a71e2a8 (improve notebook explanation)
   "source": [
    "# autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
<<<<<<< HEAD
<<<<<<< HEAD
    "from pprint import pprint \n",
    "\n",
    "import spacy\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import delphi\n",
    "\n",
    "# from delphi.eval import token_labelling"
=======
    "import spacy\n",
    "\n",
    "import token_labelling"
>>>>>>> bf8ef79 (add notebook)
=======
    "from pprint import pprint \n",
    "\n",
    "import spacy\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import delphi\n",
    "\n",
    "# from delphi.eval import token_labelling"
>>>>>>> a71e2a8 (improve notebook explanation)
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We analyze a simple sentence and receive the respective tokens with their analyzed attributes.  \n",
    "The grammatical/linguistic analysis is done by a model provided by spaCy for the English language."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 2,
=======
   "execution_count": 23,
>>>>>>> bf8ef79 (add notebook)
=======
   "execution_count": 2,
>>>>>>> a71e2a8 (improve notebook explanation)
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This\n"
     ]
    }
   ],
   "source": [
    "# Load the english model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Create a Doc object from a given text\n",
    "doc = nlp(\"This is a dummy sentence for testing.\")\n",
    "\n",
    "token = doc[0]\n",
    "print(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get the label for our custom token that we just printed."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 8,
=======
   "execution_count": 46,
>>>>>>> bf8ef79 (add notebook)
=======
   "execution_count": 8,
>>>>>>> a71e2a8 (improve notebook explanation)
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
<<<<<<< HEAD
=======
>>>>>>> a71e2a8 (improve notebook explanation)
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n",
      "{'Capitalized': True,\n",
      " 'Is Adjective': False,\n",
      " 'Is Adverb': False,\n",
      " 'Is Conjunction': False,\n",
      " 'Is Interjunction': False,\n",
      " 'Is Named Entity': False,\n",
      " 'Is Noun': False,\n",
      " 'Is Preposition': False,\n",
      " 'Is Pronoun': True,\n",
      " 'Is Verb': False,\n",
      " 'Starts with space': False}\n"
<<<<<<< HEAD
=======
      "[False, True, False, True, False, False, False, False, False, False, True, False, False, False, False]\n"
>>>>>>> bf8ef79 (add notebook)
=======
>>>>>>> a71e2a8 (improve notebook explanation)
     ]
    }
   ],
   "source": [
<<<<<<< HEAD
<<<<<<< HEAD
    "from delphi.eval import token_labelling\n",
    "\n",
    "label = token_labelling.label_single_token(token)\n",
    "pprint(label)"
=======
    "label = token_labelling.label_single_token(token)\n",
    "print(label)"
>>>>>>> bf8ef79 (add notebook)
=======
    "from delphi.eval import token_labelling\n",
    "\n",
    "label = token_labelling.label_single_token(token)\n",
    "pprint(label)"
>>>>>>> a71e2a8 (improve notebook explanation)
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get an understanding of what the labels acutally mean.\n",
    "Use this function to receive an explanation for a single token."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 9,
=======
   "execution_count": 42,
>>>>>>> bf8ef79 (add notebook)
=======
   "execution_count": 9,
>>>>>>> a71e2a8 (improve notebook explanation)
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Explanation of token labels --------\n",
      "Token text:          This\n",
      "Token dependency:    nominal subject\n",
      "Token POS:           pronoun\n",
      "---------------- Token labels ---------------\n",
      "  0   Starts with space    False\n",
      "  1   Capitalized          True\n",
      "  2   Is Noun              False\n",
      "  3   Is Pronoun           True\n",
      "  4   Is Adjective         False\n",
      "  5   Is Verb              False\n",
      "  6   Is Adverb            False\n",
      "  7   Is Preposition       False\n",
      "  8   Is Conjunction       False\n",
      "  9   Is Interjunction     False\n",
<<<<<<< HEAD
<<<<<<< HEAD
      " 10   Is Named Entity      False\n"
=======
      " 10   Is Subject           True\n",
      " 11   Is Object            False\n",
      " 12   Is Root              False\n",
      " 13   Is auxiliary         False\n",
      " 14   Is Named Entity      False\n"
>>>>>>> bf8ef79 (add notebook)
=======
      " 10   Is Named Entity      False\n"
>>>>>>> a71e2a8 (improve notebook explanation)
     ]
    }
   ],
   "source": [
    "token_labelling.explain_token_labels(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
<<<<<<< HEAD
<<<<<<< HEAD
=======
>>>>>>> a71e2a8 (improve notebook explanation)
    "If you are interested in all the possible labels a token can have, that spaCy is capable of assigning, then call the same function but without any argument:\n",
    "```Python\n",
    ">>> token_labelling.explain_token_labels()\n",
    "```"
<<<<<<< HEAD
=======
    "If you are interested in all the possible labels a token can have, that spaCy is capable of assigning, then call the same function but without any argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explanation of all 302 token labels (POS, dependency, NER, ...):\n",
      "    ADJ        adjective\n",
      "    ADP        adposition\n",
      "    ADV        adverb\n",
      "    AUX        auxiliary\n",
      "    CONJ       conjunction\n",
      "    CCONJ      coordinating conjunction\n",
      "    DET        determiner\n",
      "    INTJ       interjection\n",
      "    NOUN       noun\n",
      "    NUM        numeral\n",
      "    PART       particle\n",
      "    PRON       pronoun\n",
      "    PROPN      proper noun\n",
      "    PUNCT      punctuation\n",
      "    SCONJ      subordinating conjunction\n",
      "    SYM        symbol\n",
      "    VERB       verb\n",
      "    X          other\n",
      "    EOL        end of line\n",
      "    SPACE      space\n",
      "    .          punctuation mark, sentence closer\n",
      "    ,          punctuation mark, comma\n",
      "    -LRB-      left round bracket\n",
      "    -RRB-      right round bracket\n",
      "    ``         opening quotation mark\n",
      "    \"\"         closing quotation mark\n",
      "    ''         closing quotation mark\n",
      "    :          punctuation mark, colon or ellipsis\n",
      "    $          symbol, currency\n",
      "    #          symbol, number sign\n",
      "    AFX        affix\n",
      "    CC         conjunction, coordinating\n",
      "    CD         cardinal number\n",
      "    DT         determiner\n",
      "    EX         existential there\n",
      "    FW         foreign word\n",
      "    HYPH       punctuation mark, hyphen\n",
      "    IN         conjunction, subordinating or preposition\n",
      "    JJ         adjective (English), other noun-modifier (Chinese)\n",
      "    JJR        adjective, comparative\n",
      "    JJS        adjective, superlative\n",
      "    LS         list item marker\n",
      "    MD         verb, modal auxiliary\n",
      "    NIL        missing tag\n",
      "    NN         noun, singular or mass\n",
      "    NNP        noun, proper singular\n",
      "    NNPS       noun, proper plural\n",
      "    NNS        noun, plural\n",
      "    PDT        predeterminer\n",
      "    POS        possessive ending\n",
      "    PRP        pronoun, personal\n",
      "    PRP$       pronoun, possessive\n",
      "    RB         adverb\n",
      "    RBR        adverb, comparative\n",
      "    RBS        adverb, superlative\n",
      "    RP         adverb, particle\n",
      "    TO         infinitival \"to\"\n",
      "    UH         interjection\n",
      "    VB         verb, base form\n",
      "    VBD        verb, past tense\n",
      "    VBG        verb, gerund or present participle\n",
      "    VBN        verb, past participle\n",
      "    VBP        verb, non-3rd person singular present\n",
      "    VBZ        verb, 3rd person singular present\n",
      "    WDT        wh-determiner\n",
      "    WP         wh-pronoun, personal\n",
      "    WP$        wh-pronoun, possessive\n",
      "    WRB        wh-adverb\n",
      "    SP         space (English), sentence-final particle (Chinese)\n",
      "    ADD        email\n",
      "    NFP        superfluous punctuation\n",
      "    GW         additional word in multi-word expression\n",
      "    XX         unknown\n",
      "    BES        auxiliary \"be\"\n",
      "    HVS        forms of \"have\"\n",
      "    _SP        whitespace\n",
      "    $(         other sentence-internal punctuation mark\n",
      "    $,         comma\n",
      "    $.         sentence-final punctuation mark\n",
      "    ADJA       adjective, attributive\n",
      "    ADJD       adjective, adverbial or predicative\n",
      "    APPO       postposition\n",
      "    APPR       preposition; circumposition left\n",
      "    APPRART    preposition with article\n",
      "    APZR       circumposition right\n",
      "    ART        definite or indefinite article\n",
      "    CARD       cardinal number\n",
      "    FM         foreign language material\n",
      "    ITJ        interjection\n",
      "    KOKOM      comparative conjunction\n",
      "    KON        coordinate conjunction\n",
      "    KOUI       subordinate conjunction with \"zu\" and infinitive\n",
      "    KOUS       subordinate conjunction with sentence\n",
      "    NE         proper noun\n",
      "    NNE        proper noun\n",
      "    PAV        pronominal adverb\n",
      "    PROAV      pronominal adverb\n",
      "    PDAT       attributive demonstrative pronoun\n",
      "    PDS        substituting demonstrative pronoun\n",
      "    PIAT       attributive indefinite pronoun without determiner\n",
      "    PIDAT      attributive indefinite pronoun with determiner\n",
      "    PIS        substituting indefinite pronoun\n",
      "    PPER       non-reflexive personal pronoun\n",
      "    PPOSAT     attributive possessive pronoun\n",
      "    PPOSS      substituting possessive pronoun\n",
      "    PRELAT     attributive relative pronoun\n",
      "    PRELS      substituting relative pronoun\n",
      "    PRF        reflexive personal pronoun\n",
      "    PTKA       particle with adjective or adverb\n",
      "    PTKANT     answer particle\n",
      "    PTKNEG     negative particle\n",
      "    PTKVZ      separable verbal particle\n",
      "    PTKZU      \"zu\" before infinitive\n",
      "    PWAT       attributive interrogative pronoun\n",
      "    PWAV       adverbial interrogative or relative pronoun\n",
      "    PWS        substituting interrogative pronoun\n",
      "    TRUNC      word remnant\n",
      "    VAFIN      finite verb, auxiliary\n",
      "    VAIMP      imperative, auxiliary\n",
      "    VAINF      infinitive, auxiliary\n",
      "    VAPP       perfect participle, auxiliary\n",
      "    VMFIN      finite verb, modal\n",
      "    VMINF      infinitive, modal\n",
      "    VMPP       perfect participle, modal\n",
      "    VVFIN      finite verb, full\n",
      "    VVIMP      imperative, full\n",
      "    VVINF      infinitive, full\n",
      "    VVIZU      infinitive with \"zu\", full\n",
      "    VVPP       perfect participle, full\n",
      "    XY         non-word containing non-letter\n",
      "    AD         adverb\n",
      "    AS         aspect marker\n",
      "    BA         把 in ba-construction\n",
      "    CS         subordinating conjunction\n",
      "    DEC        的 in a relative clause\n",
      "    DEG        associative 的\n",
      "    DER        得 in V-de const. and V-de-R\n",
      "    DEV        地 before VP\n",
      "    ETC        for words 等, 等等\n",
      "    IJ         interjection\n",
      "    LB         被 in long bei-const\n",
      "    LC         localizer\n",
      "    M          measure word\n",
      "    MSP        other particle\n",
      "    NR         proper noun\n",
      "    NT         temporal noun\n",
      "    OD         ordinal number\n",
      "    ON         onomatopoeia\n",
      "    P          preposition excluding 把 and 被\n",
      "    PN         pronoun\n",
      "    PU         punctuation\n",
      "    SB         被 in short bei-const\n",
      "    VA         predicative adjective\n",
      "    VC         是 (copula)\n",
      "    VE         有 as the main verb\n",
      "    VV         other verb\n",
      "    NP         noun phrase\n",
      "    PP         prepositional phrase\n",
      "    VP         verb phrase\n",
      "    ADVP       adverb phrase\n",
      "    ADJP       adjective phrase\n",
      "    SBAR       subordinating conjunction\n",
      "    PRT        particle\n",
      "    PNP        prepositional noun phrase\n",
      "    acl        clausal modifier of noun (adjectival clause)\n",
      "    acomp      adjectival complement\n",
      "    advcl      adverbial clause modifier\n",
      "    advmod     adverbial modifier\n",
      "    agent      agent\n",
      "    amod       adjectival modifier\n",
      "    appos      appositional modifier\n",
      "    attr       attribute\n",
      "    aux        auxiliary\n",
      "    auxpass    auxiliary (passive)\n",
      "    case       case marking\n",
      "    cc         coordinating conjunction\n",
      "    ccomp      clausal complement\n",
      "    clf        classifier\n",
      "    complm     complementizer\n",
      "    compound   compound\n",
      "    conj       conjunct\n",
      "    cop        copula\n",
      "    csubj      clausal subject\n",
      "    csubjpass  clausal subject (passive)\n",
      "    dative     dative\n",
      "    dep        unclassified dependent\n",
      "    det        determiner\n",
      "    discourse  discourse element\n",
      "    dislocated dislocated elements\n",
      "    dobj       direct object\n",
      "    expl       expletive\n",
      "    fixed      fixed multiword expression\n",
      "    flat       flat multiword expression\n",
      "    goeswith   goes with\n",
      "    hmod       modifier in hyphenation\n",
      "    hyph       hyphen\n",
      "    infmod     infinitival modifier\n",
      "    intj       interjection\n",
      "    iobj       indirect object\n",
      "    list       list\n",
      "    mark       marker\n",
      "    meta       meta modifier\n",
      "    neg        negation modifier\n",
      "    nmod       modifier of nominal\n",
      "    nn         noun compound modifier\n",
      "    npadvmod   noun phrase as adverbial modifier\n",
      "    nsubj      nominal subject\n",
      "    nsubjpass  nominal subject (passive)\n",
      "    nounmod    modifier of nominal\n",
      "    npmod      noun phrase as adverbial modifier\n",
      "    num        number modifier\n",
      "    number     number compound modifier\n",
      "    nummod     numeric modifier\n",
      "    oprd       object predicate\n",
      "    obj        object\n",
      "    obl        oblique nominal\n",
      "    orphan     orphan\n",
      "    parataxis  parataxis\n",
      "    partmod    participal modifier\n",
      "    pcomp      complement of preposition\n",
      "    pobj       object of preposition\n",
      "    poss       possession modifier\n",
      "    possessive possessive modifier\n",
      "    preconj    pre-correlative conjunction\n",
      "    prep       prepositional modifier\n",
      "    prt        particle\n",
      "    punct      punctuation\n",
      "    quantmod   modifier of quantifier\n",
      "    rcmod      relative clause modifier\n",
      "    relcl      relative clause modifier\n",
      "    reparandum overridden disfluency\n",
      "    root       root\n",
      "    ROOT       root\n",
      "    vocative   vocative\n",
      "    xcomp      open clausal complement\n",
      "    ac         adpositional case marker\n",
      "    adc        adjective component\n",
      "    ag         genitive attribute\n",
      "    ams        measure argument of adjective\n",
      "    app        apposition\n",
      "    avc        adverbial phrase component\n",
      "    cd         coordinating conjunction\n",
      "    cj         conjunct\n",
      "    cm         comparative conjunction\n",
      "    cp         complementizer\n",
      "    cvc        collocational verb construction\n",
      "    da         dative\n",
      "    dh         discourse-level head\n",
      "    dm         discourse marker\n",
      "    ep         expletive es\n",
      "    hd         head\n",
      "    ju         junctor\n",
      "    mnr        postnominal modifier\n",
      "    mo         modifier\n",
      "    ng         negation\n",
      "    nk         noun kernel element\n",
      "    nmc        numerical component\n",
      "    oa         accusative object\n",
      "    oc         clausal object\n",
      "    og         genitive object\n",
      "    op         prepositional object\n",
      "    par        parenthetical element\n",
      "    pd         predicate\n",
      "    pg         phrasal genitive\n",
      "    ph         placeholder\n",
      "    pm         morphological particle\n",
      "    pnc        proper noun component\n",
      "    rc         relative clause\n",
      "    re         repeated element\n",
      "    rs         reported speech\n",
      "    sb         subject\n",
      "    sbp        passivized subject (PP)\n",
      "    sp         subject or predicate\n",
      "    svp        separable verb prefix\n",
      "    uc         unit component\n",
      "    vo         vocative\n",
      "    PERSON     People, including fictional\n",
      "    NORP       Nationalities or religious or political groups\n",
      "    FACILITY   Buildings, airports, highways, bridges, etc.\n",
      "    FAC        Buildings, airports, highways, bridges, etc.\n",
      "    ORG        Companies, agencies, institutions, etc.\n",
      "    GPE        Countries, cities, states\n",
      "    LOC        Non-GPE locations, mountain ranges, bodies of water\n",
      "    PRODUCT    Objects, vehicles, foods, etc. (not services)\n",
      "    EVENT      Named hurricanes, battles, wars, sports events, etc.\n",
      "    WORK_OF_ART Titles of books, songs, etc.\n",
      "    LAW        Named documents made into laws.\n",
      "    LANGUAGE   Any named language\n",
      "    DATE       Absolute or relative dates or periods\n",
      "    TIME       Times smaller than a day\n",
      "    PERCENT    Percentage, including \"%\"\n",
      "    MONEY      Monetary values, including unit\n",
      "    QUANTITY   Measurements, as of weight or distance\n",
      "    ORDINAL    \"first\", \"second\", etc.\n",
      "    CARDINAL   Numerals that do not fall under another type\n",
      "    PER        Named person or family.\n",
      "    MISC       Miscellaneous entities, e.g. events, nationalities, products or works of art\n",
      "    EVT        Festivals, cultural events, sports events, weather phenomena, wars, etc.\n",
      "    PROD       Product, i.e. artificially produced entities including speeches, radio shows, programming languages, contracts, laws and ideas\n",
      "    DRV        Words (and phrases?) that are dervied from a name, but not a name in themselves, e.g. 'Oslo-mannen' ('the man from Oslo')\n",
      "    GPE_LOC    Geo-political entity, with a locative sense, e.g. 'John lives in Spain'\n",
      "    GPE_ORG    Geo-political entity, with an organisation sense, e.g. 'Spain declined to meet with Belgium'\n"
     ]
    }
   ],
   "source": [
    "token_labelling.explain_token_labels()"
>>>>>>> bf8ef79 (add notebook)
=======
>>>>>>> a71e2a8 (improve notebook explanation)
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
<<<<<<< HEAD
<<<<<<< HEAD
    "### Batched token labelling\n",
=======
>>>>>>> bf8ef79 (add notebook)
=======
    "### Batched token labelling\n",
>>>>>>> a71e2a8 (improve notebook explanation)
    "Next, let us analyze a batch of sentences and have them labelled.\n",
    "> In this example the input sentences are not yet tokenized, so spaCy uses its internal tokenizer."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 18,
=======
   "execution_count": 55,
>>>>>>> bf8ef79 (add notebook)
=======
   "execution_count": 18,
>>>>>>> a71e2a8 (improve notebook explanation)
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token: This\n",
<<<<<<< HEAD
<<<<<<< HEAD
      "Starts with space | Capitalized | Is Noun | Is Pronoun | Is Adjective | Is Verb | Is Adverb | Is Preposition | Is Conjunction | Is Interjunction | Is Named Entity\n",
      "False             | True        | False   | True       | False        | False   | False     | False          | False          | False            | False          \n",
      "---\n",
      "Token: is\n",
      "Starts with space | Capitalized | Is Noun | Is Pronoun | Is Adjective | Is Verb | Is Adverb | Is Preposition | Is Conjunction | Is Interjunction | Is Named Entity\n",
      "False             | False       | False   | False      | False        | True    | False     | False          | False          | False            | False          \n",
      "---\n",
      "Token: a\n",
      "Starts with space | Capitalized | Is Noun | Is Pronoun | Is Adjective | Is Verb | Is Adverb | Is Preposition | Is Conjunction | Is Interjunction | Is Named Entity\n",
      "False             | False       | False   | False      | False        | False   | False     | False          | False          | False            | False          \n",
      "---\n",
      "Token: sentence\n",
      "Starts with space | Capitalized | Is Noun | Is Pronoun | Is Adjective | Is Verb | Is Adverb | Is Preposition | Is Conjunction | Is Interjunction | Is Named Entity\n",
      "False             | False       | True    | False      | False        | False   | False     | False          | False          | False            | False          \n",
      "---\n",
      "Token: .\n",
      "Starts with space | Capitalized | Is Noun | Is Pronoun | Is Adjective | Is Verb | Is Adverb | Is Preposition | Is Conjunction | Is Interjunction | Is Named Entity\n",
      "False             | False       | False   | False      | False        | False   | False     | False          | False          | False            | False          \n",
=======
      "Starts with space | Capitalized | Is Noun | Is Pronoun | Is Adjective | Is Verb | Is Adverb | Is Preposition | Is Conjunction | Is Interjunction | Is Subject | Is Object | Is Root | Is auxiliary | Is Named Entity\n",
      "False             | True        | False   | True       | False        | False   | False     | False          | False          | False            | True       | False     | False   | False        | False          \n",
=======
      "Starts with space | Capitalized | Is Noun | Is Pronoun | Is Adjective | Is Verb | Is Adverb | Is Preposition | Is Conjunction | Is Interjunction | Is Named Entity\n",
      "False             | True        | False   | True       | False        | False   | False     | False          | False          | False            | False          \n",
>>>>>>> a71e2a8 (improve notebook explanation)
      "---\n",
      "Token: is\n",
      "Starts with space | Capitalized | Is Noun | Is Pronoun | Is Adjective | Is Verb | Is Adverb | Is Preposition | Is Conjunction | Is Interjunction | Is Named Entity\n",
      "False             | False       | False   | False      | False        | True    | False     | False          | False          | False            | False          \n",
      "---\n",
      "Token: a\n",
      "Starts with space | Capitalized | Is Noun | Is Pronoun | Is Adjective | Is Verb | Is Adverb | Is Preposition | Is Conjunction | Is Interjunction | Is Named Entity\n",
      "False             | False       | False   | False      | False        | False   | False     | False          | False          | False            | False          \n",
      "---\n",
      "Token: sentence\n",
      "Starts with space | Capitalized | Is Noun | Is Pronoun | Is Adjective | Is Verb | Is Adverb | Is Preposition | Is Conjunction | Is Interjunction | Is Named Entity\n",
      "False             | False       | True    | False      | False        | False   | False     | False          | False          | False            | False          \n",
      "---\n",
      "Token: .\n",
<<<<<<< HEAD
      "Starts with space | Capitalized | Is Noun | Is Pronoun | Is Adjective | Is Verb | Is Adverb | Is Preposition | Is Conjunction | Is Interjunction | Is Subject | Is Object | Is Root | Is auxiliary | Is Named Entity\n",
      "False             | False       | False   | False      | False        | False   | False     | False          | False          | False            | False      | False     | False   | False        | False          \n",
>>>>>>> bf8ef79 (add notebook)
=======
      "Starts with space | Capitalized | Is Noun | Is Pronoun | Is Adjective | Is Verb | Is Adverb | Is Preposition | Is Conjunction | Is Interjunction | Is Named Entity\n",
      "False             | False       | False   | False      | False        | False   | False     | False          | False          | False            | False          \n",
>>>>>>> a71e2a8 (improve notebook explanation)
      "---\n",
      "\n",
      "\n",
      "5\n",
<<<<<<< HEAD
<<<<<<< HEAD
      "[{'Starts with space': False, 'Capitalized': True, 'Is Noun': False, 'Is Pronoun': True, 'Is Adjective': False, 'Is Verb': False, 'Is Adverb': False, 'Is Preposition': False, 'Is Conjunction': False, 'Is Interjunction': False, 'Is Named Entity': False}, {'Starts with space': False, 'Capitalized': False, 'Is Noun': False, 'Is Pronoun': False, 'Is Adjective': False, 'Is Verb': True, 'Is Adverb': False, 'Is Preposition': False, 'Is Conjunction': False, 'Is Interjunction': False, 'Is Named Entity': False}, {'Starts with space': False, 'Capitalized': False, 'Is Noun': False, 'Is Pronoun': False, 'Is Adjective': False, 'Is Verb': False, 'Is Adverb': False, 'Is Preposition': False, 'Is Conjunction': False, 'Is Interjunction': False, 'Is Named Entity': False}, {'Starts with space': False, 'Capitalized': False, 'Is Noun': True, 'Is Pronoun': False, 'Is Adjective': False, 'Is Verb': False, 'Is Adverb': False, 'Is Preposition': False, 'Is Conjunction': False, 'Is Interjunction': False, 'Is Named Entity': False}, {'Starts with space': False, 'Capitalized': False, 'Is Noun': False, 'Is Pronoun': False, 'Is Adjective': False, 'Is Verb': False, 'Is Adverb': False, 'Is Preposition': False, 'Is Conjunction': False, 'Is Interjunction': False, 'Is Named Entity': False}]\n"
=======
      "[[False, True, False, True, False, False, False, False, False, False, True, False, False, False, False], [False, False, False, False, False, True, False, False, False, False, False, False, True, False, False], [False, False, False, False, False, False, False, False, False, False, False, False, False, False, False], [False, False, True, False, False, False, False, False, False, False, False, False, False, False, False], [False, False, False, False, False, False, False, False, False, False, False, False, False, False, False]]\n"
>>>>>>> bf8ef79 (add notebook)
=======
      "[{'Starts with space': False, 'Capitalized': True, 'Is Noun': False, 'Is Pronoun': True, 'Is Adjective': False, 'Is Verb': False, 'Is Adverb': False, 'Is Preposition': False, 'Is Conjunction': False, 'Is Interjunction': False, 'Is Named Entity': False}, {'Starts with space': False, 'Capitalized': False, 'Is Noun': False, 'Is Pronoun': False, 'Is Adjective': False, 'Is Verb': True, 'Is Adverb': False, 'Is Preposition': False, 'Is Conjunction': False, 'Is Interjunction': False, 'Is Named Entity': False}, {'Starts with space': False, 'Capitalized': False, 'Is Noun': False, 'Is Pronoun': False, 'Is Adjective': False, 'Is Verb': False, 'Is Adverb': False, 'Is Preposition': False, 'Is Conjunction': False, 'Is Interjunction': False, 'Is Named Entity': False}, {'Starts with space': False, 'Capitalized': False, 'Is Noun': True, 'Is Pronoun': False, 'Is Adjective': False, 'Is Verb': False, 'Is Adverb': False, 'Is Preposition': False, 'Is Conjunction': False, 'Is Interjunction': False, 'Is Named Entity': False}, {'Starts with space': False, 'Capitalized': False, 'Is Noun': False, 'Is Pronoun': False, 'Is Adjective': False, 'Is Verb': False, 'Is Adverb': False, 'Is Preposition': False, 'Is Conjunction': False, 'Is Interjunction': False, 'Is Named Entity': False}]\n"
>>>>>>> a71e2a8 (improve notebook explanation)
     ]
    }
   ],
   "source": [
    "sentences = [\n",
    "    \"This is a sentence.\"\n",
    "]\n",
<<<<<<< HEAD
<<<<<<< HEAD
    "labels = token_labelling.label_batch_sentences(sentences, tokenized=False, verbose=True)\n",
=======
    "labels = token_labelling.label_batch_token(sentences, tokenized=False, verbose=True)\n",
>>>>>>> bf8ef79 (add notebook)
=======
    "labels = token_labelling.label_batch_sentences(sentences, tokenized=False, verbose=True)\n",
>>>>>>> a71e2a8 (improve notebook explanation)
    "\n",
    "print(len(labels[0]))\n",
    "print(labels[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now with our own tokenization. E.g. the one from our TinyStories models."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 19,
=======
   "execution_count": null,
>>>>>>> bf8ef79 (add notebook)
=======
   "execution_count": 19,
>>>>>>> a71e2a8 (improve notebook explanation)
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
<<<<<<< HEAD
      "5\n",
      "[{'Starts with space': False, 'Capitalized': True, 'Is Noun': True, 'Is Pronoun': False, 'Is Adjective': False, 'Is Verb': False, 'Is Adverb': False, 'Is Preposition': False, 'Is Conjunction': False, 'Is Interjunction': False, 'Is Named Entity': False}, {'Starts with space': False, 'Capitalized': False, 'Is Noun': False, 'Is Pronoun': False, 'Is Adjective': False, 'Is Verb': False, 'Is Adverb': True, 'Is Preposition': False, 'Is Conjunction': False, 'Is Interjunction': False, 'Is Named Entity': False}, {'Starts with space': False, 'Capitalized': False, 'Is Noun': False, 'Is Pronoun': False, 'Is Adjective': True, 'Is Verb': False, 'Is Adverb': False, 'Is Preposition': False, 'Is Conjunction': False, 'Is Interjunction': False, 'Is Named Entity': False}, {'Starts with space': False, 'Capitalized': False, 'Is Noun': True, 'Is Pronoun': False, 'Is Adjective': False, 'Is Verb': False, 'Is Adverb': False, 'Is Preposition': False, 'Is Conjunction': False, 'Is Interjunction': False, 'Is Named Entity': False}, {'Starts with space': False, 'Capitalized': False, 'Is Noun': False, 'Is Pronoun': False, 'Is Adjective': False, 'Is Verb': False, 'Is Adverb': False, 'Is Preposition': False, 'Is Conjunction': False, 'Is Interjunction': False, 'Is Named Entity': False}]\n"
=======
      "Token: This \n",
      "Starts with space | Capitalized | Is Noun | Is Pronoun | Is Adjective | Is Verb | Is Adverb | Is Preposition | Is Conjunction | Is Interjunction | Is Subject | Is Object | Is Root | Is auxiliary | Is Named Entity\n",
      "False             | True        | True    | False      | False        | False   | False     | False          | False          | False            | False      | False     | True    | False        | False          \n",
      "---\n",
      "Token: is \n",
      "Starts with space | Capitalized | Is Noun | Is Pronoun | Is Adjective | Is Verb | Is Adverb | Is Preposition | Is Conjunction | Is Interjunction | Is Subject | Is Object | Is Root | Is auxiliary | Is Named Entity\n",
      "False             | False       | False   | False      | False        | False   | True      | False          | False          | False            | False      | False     | False   | False        | False          \n",
      "---\n",
      "Token: a \n",
      "Starts with space | Capitalized | Is Noun | Is Pronoun | Is Adjective | Is Verb | Is Adverb | Is Preposition | Is Conjunction | Is Interjunction | Is Subject | Is Object | Is Root | Is auxiliary | Is Named Entity\n",
      "False             | False       | False   | False      | True         | False   | False     | False          | False          | False            | False      | False     | False   | False        | False          \n",
      "---\n",
      "Token: sentence\n",
      "Starts with space | Capitalized | Is Noun | Is Pronoun | Is Adjective | Is Verb | Is Adverb | Is Preposition | Is Conjunction | Is Interjunction | Is Subject | Is Object | Is Root | Is auxiliary | Is Named Entity\n",
      "False             | False       | True    | False      | False        | False   | False     | False          | False          | False            | False      | True      | False   | False        | False          \n",
      "---\n",
      "Token: .\n",
      "Starts with space | Capitalized | Is Noun | Is Pronoun | Is Adjective | Is Verb | Is Adverb | Is Preposition | Is Conjunction | Is Interjunction | Is Subject | Is Object | Is Root | Is auxiliary | Is Named Entity\n",
      "False             | False       | False   | False      | False        | False   | False     | False          | False          | False            | False      | False     | False   | False        | False          \n",
      "---\n",
      "\n",
      "\n",
      "5\n",
      "[[False, True, True, False, False, False, False, False, False, False, False, False, True, False, False], [False, False, False, False, False, False, True, False, False, False, False, False, False, False, False], [False, False, False, False, True, False, False, False, False, False, False, False, False, False, False], [False, False, True, False, False, False, False, False, False, False, False, True, False, False, False], [False, False, False, False, False, False, False, False, False, False, False, False, False, False, False]]\n"
>>>>>>> bf8ef79 (add notebook)
=======
      "5\n",
      "[{'Starts with space': False, 'Capitalized': True, 'Is Noun': True, 'Is Pronoun': False, 'Is Adjective': False, 'Is Verb': False, 'Is Adverb': False, 'Is Preposition': False, 'Is Conjunction': False, 'Is Interjunction': False, 'Is Named Entity': False}, {'Starts with space': False, 'Capitalized': False, 'Is Noun': False, 'Is Pronoun': False, 'Is Adjective': False, 'Is Verb': False, 'Is Adverb': True, 'Is Preposition': False, 'Is Conjunction': False, 'Is Interjunction': False, 'Is Named Entity': False}, {'Starts with space': False, 'Capitalized': False, 'Is Noun': False, 'Is Pronoun': False, 'Is Adjective': True, 'Is Verb': False, 'Is Adverb': False, 'Is Preposition': False, 'Is Conjunction': False, 'Is Interjunction': False, 'Is Named Entity': False}, {'Starts with space': False, 'Capitalized': False, 'Is Noun': True, 'Is Pronoun': False, 'Is Adjective': False, 'Is Verb': False, 'Is Adverb': False, 'Is Preposition': False, 'Is Conjunction': False, 'Is Interjunction': False, 'Is Named Entity': False}, {'Starts with space': False, 'Capitalized': False, 'Is Noun': False, 'Is Pronoun': False, 'Is Adjective': False, 'Is Verb': False, 'Is Adverb': False, 'Is Preposition': False, 'Is Conjunction': False, 'Is Interjunction': False, 'Is Named Entity': False}]\n"
>>>>>>> a71e2a8 (improve notebook explanation)
     ]
    }
   ],
   "source": [
    "sentences = [\n",
    "    [\"This \", \"is \", \"a \", \"sentence\", \".\"]\n",
    "]\n",
<<<<<<< HEAD
<<<<<<< HEAD
    "labelled_sentences = token_labelling.label_batch_sentences(sentences, tokenized=True, verbose=False)\n",
    "\n",
    "print(len(labelled_sentences[0]))\n",
    "print(labelled_sentences[0])"
=======
    "labels = token_labelling.label_batch_token(sentences, tokenized=True, verbose=False)\n",
    "\n",
    "print(len(labels[0]))\n",
    "print(labels[0])"
>>>>>>> bf8ef79 (add notebook)
=======
    "labelled_sentences = token_labelling.label_batch_sentences(sentences, tokenized=True, verbose=False)\n",
    "\n",
    "print(len(labelled_sentences[0]))\n",
    "print(labelled_sentences[0])"
>>>>>>> a71e2a8 (improve notebook explanation)
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
<<<<<<< HEAD
<<<<<<< HEAD
=======
>>>>>>> a71e2a8 (improve notebook explanation)
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Labelling all tokens in the dataset\n",
    "\n",
    "Now we want to label all the tokens that our tokenizer knows - its entire vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The vocab size is  50257\n"
     ]
    }
   ],
   "source": [
    "# Get all the tokens of the tokenizer\n",
    "from transformers import AutoTokenizer, PreTrainedTokenizer, PreTrainedTokenizerFast\n",
    "\n",
    "def tokenize(tokenizer: PreTrainedTokenizer, sample_txt: str) -> list[int]:\n",
    "    # supposedly this can be different than prepending the bos token id\n",
    "    return tokenizer.encode(tokenizer.bos_token + sample_txt, return_tensors=\"pt\")[0]\n",
    "\n",
    "# Decode a sentence\n",
    "def decode(tokenizer: PreTrainedTokenizer, token_ids: list[int]) -> str:\n",
    "    return tokenizer.decode(token_ids, skip_special_tokens=True)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"roneneldan/TinyStories-1M\")\n",
    "vocab_size = tokenizer.vocab_size\n",
    "print(\"The vocab size is:\", vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!          \"          #          $          %          &          '          (          )          *          \n",
      " inv       lect        supp      ating       look      man        pect        8         row         bu        \n",
      " child      since     ired       less        life       develop   ittle       dep        pass      �          \n",
      " matter    reg        ext        angu       isc        ole        aut         compet    eed        fect       \n",
      " (/        ….\"        Compar      amplification ominated    regress    Collider   informants  gazed                \n"
     ]
    }
   ],
   "source": [
    "# Let's have a look at some tokens\n",
    "ranges = [(0,10), (800,810), (1200,1210), (2300, 2310), (vocab_size-10, vocab_size)]\n",
    "for start, end in ranges:\n",
    "    for i in range(start, end):\n",
    "        print(decode(tokenizer, i).ljust(10), end=\" \")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2405771500d24b7890f87694d533486f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Labelling tokens:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# let's label each token\n",
    "labelled_token_ids_dict: dict[int, dict[str, bool]] = {}\n",
    "max_token_id = 4000  # stop at which token id, for testing, later vocab size\n",
    "batch_size = 500\n",
    "# we iterate (batchwise) over all token_ids\n",
    "for start in tqdm(range(0, max_token_id, batch_size), desc=\"Labelling tokens\"):\n",
    "    # create a batch of token_ids\n",
    "    token_ids = list(range(start, start+batch_size))\n",
    "    # decode the token_ids to get a list of tokens, a 'sentence'\n",
    "    tokens = decode(tokenizer, token_ids)  # list of tokens == sentence\n",
    "    # put the sentence into a list, to make it a batch of sentences\n",
    "    sentences = [tokens]\n",
    "    # label the batch of sentences\n",
    "    labels = token_labelling.label_batch_sentences(sentences, tokenized=True, verbose=False)\n",
    "    # create a dict with the token_ids and their labels\n",
    "    labelled_sentence_dict = dict(zip(token_ids, labels[0]))\n",
    "    # update the labelled_token_ids_dict with the new dict\n",
    "    labelled_token_ids_dict.update(labelled_sentence_dict)\n",
    "    \n",
    "    # print(token_ids)\n",
    "    # print(sentences)\n",
    "    # print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We save the dict (pickle it) for future reference.  \n",
    "With 4000 ids it currently takes ~150kB disk space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"labelled_token_ids_dict.pkl\", \"wb\") as f:\n",
    "    pickle.dump(labelled_token_ids_dict, f)\n",
    "    \n",
    "    "
   ]
<<<<<<< HEAD
=======
>>>>>>> bf8ef79 (add notebook)
=======
>>>>>>> a71e2a8 (improve notebook explanation)
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_tinyevals",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
<<<<<<< HEAD
<<<<<<< HEAD
   "version": "3.10.13"
=======
   "version": "3.8.8"
>>>>>>> bf8ef79 (add notebook)
=======
   "version": "3.10.13"
>>>>>>> a71e2a8 (improve notebook explanation)
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
