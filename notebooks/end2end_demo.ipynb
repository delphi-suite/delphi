{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plan\n",
    "1. Build a basic UI for testing purposes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo UX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mock data for UX testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/var/folders/5k/7nfpl0cs5999pzhndyybcn800000gn/T/dummy_data.csv')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import tempfile\n",
    "import pathlib\n",
    "\n",
    "tmpdir = pathlib.Path(tempfile.gettempdir())\n",
    "dummy_csv_path = tmpdir / \"dummy_data.csv\"\n",
    "\n",
    "token_classes = [\"Nouns\", \"Verbs\", \"Adjectives\"]\n",
    "training_steps_options = [100000, 200000, 400000]\n",
    "model_sizes_options = [\"Small\", \"Medium\", \"Large\"]\n",
    "\n",
    "data = {\n",
    "    \"model_size\": [],\n",
    "    \"training_steps\": [],\n",
    "    \"loss\": [],\n",
    "    \"token_class\": [],\n",
    "}\n",
    "\n",
    "# Generate dummy data\n",
    "for size in model_sizes_options:\n",
    "    for steps in training_steps_options:\n",
    "        for token_group_desc in token_classes:\n",
    "            data[\"model_size\"].append(size)\n",
    "            data[\"training_steps\"].append(steps)\n",
    "            data[\"token_class\"].append(token_group_desc)\n",
    "            # loss should be random but decrease with size and steps\n",
    "            loss = (\n",
    "                1\n",
    "                - (model_sizes_options.index(size) + 1) / len(model_sizes_options)\n",
    "                - (training_steps_options.index(steps) + 1)\n",
    "                / len(training_steps_options)\n",
    "            )\n",
    "            noisy_loss = loss + np.random.normal(0, 0.1)\n",
    "            data[\"loss\"].append(noisy_loss)\n",
    "\n",
    "# Create DataFrame\n",
    "dummy_df = pd.DataFrame(data)\n",
    "\n",
    "# Save DataFrame to a CSV file\n",
    "dummy_df.to_csv(dummy_csv_path, index=False)\n",
    "\n",
    "dummy_csv_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Pickle Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"../data/token_model_stats.pkl\", \"rb\") as f:\n",
    "    token_model_stats = pickle.load(f)\n",
    "\n",
    "with open(\"../data/token_groups.pkl\", \"rb\") as f:\n",
    "    token_groups = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing model delphi-llama2-100k\n",
      "Processing model delphi-llama2-200k\n",
      "Processing model delphi-llama2-400k\n",
      "Processing model delphi-llama2-800k\n",
      "Processing model delphi-llama2-1.6m\n",
      "Processing model delphi-llama2-3.2m\n",
      "Processing model delphi-llama2-6.4m\n",
      "Processing model delphi-llama2-12.8m\n",
      "Processing model delphi-llama2-25.6m\n"
     ]
    }
   ],
   "source": [
    "from delphi.eval.constants import LLAMA2_MODELS\n",
    "from datasets import load_dataset, Dataset\n",
    "from typing import cast\n",
    "\n",
    "from delphi.eval.hack_token_label import HackTokenLabels\n",
    "\n",
    "model_token_group_stats = {}\n",
    "for model in LLAMA2_MODELS:\n",
    "    print(f\"Processing model {model}\")\n",
    "    dataset = cast(\n",
    "        Dataset, load_dataset(f\"transcendingvictor/{model}-validation-logprobs\")\n",
    "    )\n",
    "    for token_group_desc in HackTokenLabels.ALL_LABELS:\n",
    "        token_group_model_stats = [\n",
    "            token_model_stats[(token, model)] for token in token_groups[token_group_desc.description]\n",
    "            if (token, model) in token_model_stats\n",
    "        ]\n",
    "        sum_logprob = sum(t.logprob_sum for t in token_group_model_stats)\n",
    "        sum_count = sum(t.count for t in token_group_model_stats)\n",
    "        if sum_count == 0:\n",
    "            continue\n",
    "        mean_logprob = sum(t.logprob_sum for t in token_group_model_stats) / sum(\n",
    "            t.count for t in token_group_model_stats\n",
    "        )\n",
    "        model_token_group_stats[(token_group_desc.description, model)] = mean_logprob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "with open(\"../data/model_token_group_stats.pkl\", \"rb\") as f:\n",
    "    model_token_group_stats = pickle.load(f)\n",
    "\n",
    "mtgs_df = pd.DataFrame(\n",
    "    [key + ( value, ) for key, value in model_token_group_stats.items()],\n",
    "    columns=[\"token_group\", \"model\", \"mean_logprob\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7cda8460489412a9b31429be53df1d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='comparison_type', options=('model_size', 'training_steps'), value=â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "model_size=%{x}<br>loss=%{y}<extra></extra>",
         "legendgroup": "",
         "line": {
          "color": "#636efa",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines",
         "name": "",
         "orientation": "v",
         "showlegend": false,
         "type": "scatter",
         "uid": "bd4b5e6c-b199-44aa-82c7-61ad1bf3c8cf",
         "x": [
          100000,
          200000,
          400000,
          800000,
          1600000,
          3200000,
          6400000,
          12800000,
          25600000
         ],
         "xaxis": "x",
         "y": [
          1.6812808827511345,
          1.5026616489934475,
          1.3444136511106355,
          1.1790975359301559,
          1.0652854069539708,
          0.9915043336409837,
          0.9157125103810166,
          0.8388493562153533,
          0.8081966485478549
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "legend": {
         "tracegroupgap": 0
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Loss (-mean logprob) by Model Size (Is Pronoun)"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "model_size"
         },
         "type": "log"
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "loss"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "model_size=%{x}<br>loss=%{y}<extra></extra>",
         "legendgroup": "",
         "line": {
          "color": "#636efa",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines",
         "name": "",
         "orientation": "v",
         "showlegend": false,
         "type": "scatter",
         "uid": "69fe5944-4cc0-4107-94ab-18c4cb0dbc50",
         "x": [
          100000,
          200000,
          400000,
          800000,
          1600000,
          3200000,
          6400000,
          12800000,
          25600000
         ],
         "xaxis": "x",
         "y": [
          3.041814374148337,
          2.76064780744662,
          2.451075208124139,
          2.170279853399201,
          1.9316411693226438,
          1.79180775991581,
          1.6491427718753426,
          1.4942471860243225,
          1.4343104912147209
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "legend": {
         "tracegroupgap": 0
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Loss (-mean logprob) by Model Size (Is Adverb)"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "model_size"
         },
         "type": "log"
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "loss"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import plotly.graph_objs as go\n",
    "from ipywidgets import interact, Dropdown\n",
    "import plotly.express as px\n",
    "\n",
    "# Load your data\n",
    "# df = pd.read_csv(dummy_csv_path)  # replace with your actual path\n",
    "df = mtgs_df\n",
    "mtgs_df[\"training_steps\"] = 0\n",
    "\n",
    "# dumb hack to avoid the first call to update_figure rendering a duplicate chart\n",
    "_first_call = True\n",
    "\n",
    "\n",
    "def get_model_size(model: str) -> float:\n",
    "    # model names end in model size after dash, e.g. -100k or -25.6m\n",
    "    size_str = model.split(\"-\")[-1]\n",
    "    if size_str[-1] == \"k\":\n",
    "        return float(size_str[:-1]) * 1e3\n",
    "    elif size_str[-1] == \"m\":\n",
    "        return float(size_str[:-1]) * 1e6\n",
    "    elif size_str[-1] == \"b\":\n",
    "        return float(size_str[:-1]) * 1e9\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown size suffix: {size_str[-1]}\")\n",
    "\n",
    "\n",
    "# set model_size based on df[\"model\"]\n",
    "df[\"model_size\"] = df[\"model\"].apply(get_model_size)\n",
    "df[\"loss\"] = -df[\"mean_logprob\"]\n",
    "\n",
    "_first_call = True\n",
    "\n",
    "# Function to create and update the figure\n",
    "def update_figure(comparison_type, model_size, training_steps, token_group_desc):\n",
    "    if comparison_type == \"model_size\":\n",
    "        filtered_df = df[\n",
    "            (df[\"training_steps\"] == training_steps)\n",
    "            & (df[\"token_group\"] == token_group_desc)\n",
    "        ]\n",
    "        # update existing fig with line\n",
    "        fig = go.FigureWidget(\n",
    "            px.line(filtered_df, x=\"model_size\", y=\"loss\", title=f\"Loss (-mean logprob) by Model Size ({token_group_desc})\")\n",
    "        )\n",
    "    else:\n",
    "        filtered_df = df[\n",
    "            (df[\"model_size\"] == model_size) & (df[\"token_group\"] == token_group_desc)\n",
    "        ]\n",
    "        fig = go.FigureWidget(\n",
    "            px.line(\n",
    "                filtered_df,\n",
    "                x=\"training_steps\",\n",
    "                y=\"loss\",\n",
    "                title=\"Loss (mean -logprob) by Training Steps\",\n",
    "            )\n",
    "        )\n",
    "    # set x axis to log scale\n",
    "    fig.update_xaxes(type=\"log\")\n",
    "\n",
    "    global _first_call\n",
    "    if _first_call:\n",
    "        _first_call = False\n",
    "    else:\n",
    "        fig.show()\n",
    "\n",
    "\n",
    "# Interactive widgets\n",
    "comparison_type = Dropdown(options=[\"model_size\", \"training_steps\"])\n",
    "model_size = Dropdown(options=sorted(df[\"model_size\"].unique()))\n",
    "training_steps = Dropdown(options=sorted(df[\"training_steps\"].unique()))\n",
    "token_group_desc = Dropdown(options=df[\"token_group\"].unique())\n",
    "\n",
    "# only render the chart after all the widgets have been rendered\n",
    "_ = interact(\n",
    "    update_figure,\n",
    "    comparison_type=comparison_type,\n",
    "    model_size=model_size,\n",
    "    training_steps=training_steps,\n",
    "    token_group_desc=token_group_desc,\n",
    "    __manual=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remaining Tasks\n",
    "\n",
    "1. Get all token positions\n",
    "2. Get all model token predictions\n",
    "3. Get token groups\n",
    "4. Calculate mean loss and count per token per model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cache Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import list_datasets\n",
    "from datetime import datetime\n",
    "from typing import cast\n",
    "\n",
    "datasets = list_datasets(author=\"transcendingvictor\")\n",
    "\n",
    "datasets = [dataset for dataset in datasets if cast(datetime, dataset.created_at).date() > datetime(2024, 2, 10).date()]\n",
    "\n",
    "# cache datasets\n",
    "from datasets import load_dataset\n",
    "\n",
    "for dataset in datasets:\n",
    "    load_dataset(dataset.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['transcendingvictor/delphi-llama2-100k-validation-logprobs',\n",
       " 'transcendingvictor/delphi-llama2-200k-validation-logprobs',\n",
       " 'transcendingvictor/delphi-llama2-400k-validation-logprobs',\n",
       " 'transcendingvictor/delphi-llama2-800k-validation-logprobs',\n",
       " 'transcendingvictor/delphi-llama2-1.6m-validation-logprobs',\n",
       " 'transcendingvictor/delphi-llama2-3.2m-validation-logprobs',\n",
       " 'transcendingvictor/delphi-llama2-6.4m-validation-logprobs',\n",
       " 'transcendingvictor/delphi-llama2-12.8m-validation-logprobs',\n",
       " 'transcendingvictor/delphi-llama2-25.6m-validation-logprobs']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[d.id for d in datasets]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load models from https://huggingface.co/collections/delphi-suite/llama2-65b53936f3c0cb73e741fc44\n",
    "\n",
    "from huggingface_hub import list_models, get_collection\n",
    "from datetime import datetime\n",
    "from typing import cast\n",
    "\n",
    "# list models from the delphi-suite llama-2 collection\n",
    "collection = get_collection(\"delphi-suite/llama2-65b53936f3c0cb73e741fc44\")\n",
    "\n",
    "# cache all the models in the collection\n",
    "from transformers import AutoModelForCausalLM\n",
    "\n",
    "for model in collection.items:\n",
    "    AutoModelForCausalLM.from_pretrained(model.item_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['delphi-suite/delphi-llama2-100k',\n",
       " 'delphi-suite/delphi-llama2-200k',\n",
       " 'delphi-suite/delphi-llama2-400k',\n",
       " 'delphi-suite/delphi-llama2-800k',\n",
       " 'delphi-suite/delphi-llama2-1.6m',\n",
       " 'delphi-suite/delphi-llama2-3.2m',\n",
       " 'delphi-suite/delphi-llama2-6.4m',\n",
       " 'delphi-suite/delphi-llama2-12.8m',\n",
       " 'delphi-suite/delphi-llama2-25.6m']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[c.item_id for c in collection.items]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Token Mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from delphi.eval.token_map import token_map\n",
    "from delphi.eval.utils import load_validation_dataset\n",
    "from delphi.eval import constants\n",
    "from platformdirs import user_cache_dir\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# token mapping is a dict of (token -> (document, seq))\n",
    "token_mappings_path = \"../data/token_mappings\"\n",
    "with open(token_mappings_path, \"rb\") as f:\n",
    "    token_mappings = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([1, 432, 440, 261, 403, 4045, 406, 286, 799, 478, 407, 385, 4037, 505, 268, 1555, 622, 387, 331, 397, 509, 350, 614, 1318, 375, 1280, 381, 380, 13, 2112, 606, 486, 2929, 4040, 669, 269, 921, 341, 2652, 492, 457, 579, 544, 920, 1752, 4056, 395, 729, 412, 675, 4071, 3212, 1316, 1057, 1726, 892, 1897, 993, 342, 390, 720, 366, 410, 425, 311, 434, 628, 981, 924, 888, 367, 501, 1917, 372, 3398, 577, 359, 1854, 1811, 482, 698, 264, 525, 1014, 429, 1004, 384, 1101, 1091, 4032, 507, 624, 837, 370, 2241, 317, 670, 1728, 959, 829, 1067, 424, 466, 3824, 1526, 1102, 1256, 515, 1019, 697, 713, 602, 886, 560, 1000, 2567, 500, 1235, 369, 4001, 313, 282, 1030, 1365, 1700, 4053, 3935, 2042, 551, 858, 1521, 876, 1516, 889, 495, 467, 712, 844, 4060, 503, 435, 316, 711, 3749, 1126, 601, 1301, 1947, 2164, 599, 3673, 1104, 1515, 3018, 3158, 4054, 1788, 330, 477, 326, 332, 345, 415, 4026, 363, 504, 327, 307, 1088, 832, 411, 413, 3821, 543, 1901, 468, 340, 471, 567, 1495, 1181, 324, 559, 398, 4057, 1497, 474, 757, 443, 718, 583, 904, 801, 388, 575, 1670, 422, 823, 895, 572, 625, 752, 4047, 4027, 454, 391, 777, 660, 1196, 997, 433, 386, 872, 631, 1587, 534, 1688, 1183, 787, 396, 484, 519, 541, 3278, 1143, 663, 510, 1311, 4048, 1100, 655, 1051, 1213, 732, 632, 1844, 368, 2147, 1317, 896, 822, 1942, 1620, 1839, 2685, 1309, 984, 3630, 518, 1238, 796, 1293, 547, 1254, 887, 616, 354, 1034, 1931, 945, 2012, 2052, 1103, 1873, 1134, 1369, 626, 463, 4038, 3895, 3111, 4050, 766, 1821, 2532, 2223, 1962, 1434, 3560, 607, 4052, 735, 539, 939, 617, 524, 779, 3690, 288, 1345, 453, 612, 1498, 489, 2068, 2851, 394, 3621, 707, 992, 421, 1998, 1022, 502, 745, 623, 806, 1394, 862, 1164, 2433, 754, 1530, 610, 1035, 635, 1461, 1395, 917, 1211, 1315, 1061, 2645, 810, 869, 770, 1086, 1376, 3442, 460, 1360, 531, 1407, 2556, 445, 930, 798, 861, 769, 1037, 1135, 780, 549, 1229, 545, 1016, 716, 1627, 667, 733, 4029, 2287, 469, 1770, 1702, 648, 682, 702, 805, 1009, 2062, 2451, 811, 1328, 587, 1146, 1299, 1891, 374, 737, 1439, 989, 2413, 840, 4035, 638, 2114, 1748, 1105, 687, 949, 962, 3988, 420, 1810, 677, 940, 728, 585, 2038, 1237, 656, 580, 379, 582, 838, 723, 1645, 552, 1248, 782, 885, 318, 988, 1437, 908, 1779, 894, 3936, 3970, 3188, 1448, 1652, 1397, 2317, 581, 1221, 1382, 1302, 701, 450, 814, 1480, 262, 568, 1272, 731, 2647, 1314, 1693, 2230, 1029, 3818, 2443, 1017, 1755, 825, 357, 427, 3530, 586, 657, 1404, 1018, 1202, 1710, 821, 594, 1261, 725, 1020, 730, 815, 1110, 842, 2658, 1462, 1241, 462, 1405, 1817, 1980, 1487, 1094, 1517, 498, 1107, 3672, 2191, 3898, 1131, 1836, 1364, 1001, 1090, 2516, 1218, 1096, 775, 1820, 1260, 605, 516, 809, 764, 645, 2349, 653, 909, 846, 1047, 266, 301, 2486, 1268, 2091, 955, 1636, 1549, 915, 932, 759, 1166, 2211, 976, 1463, 1474, 2272, 673, 1005, 538, 824, 923, 1465, 1930, 1982, 980, 807, 704, 1882, 1148, 689, 2522, 1247, 724, 1264, 1323, 792, 533, 636, 1337, 565, 4024, 692, 715, 272, 797, 276, 613, 1403, 2048, 706, 2692, 1349, 1393, 1216, 1232, 1643, 853, 1599, 2197, 2358, 633, 1209, 2565, 1226, 2030, 1182, 1038, 683, 1093, 4061, 491, 1271, 476, 756, 1385, 1305, 604, 2083, 739, 1733, 3115, 449, 3861, 2080, 788, 905, 1483, 1071, 746, 1141, 852, 1072, 1447, 2481, 902, 1490, 1178, 2541, 878, 848, 2620, 738, 1990, 1010, 2458, 1056, 2046, 1039, 535, 719, 2707, 2561, 383, 2127, 554, 4031, 2110, 910, 2063, 3831, 1892, 2842, 652, 472, 2305, 2834, 3723, 1340, 2319, 1003, 1076, 1053, 3896, 2425, 3886, 3625, 854, 1971, 934, 3467, 1025, 4067, 817, 919, 4036, 3393, 260, 2577, 2414, 925, 1231, 1262, 2227, 1255, 2534, 527, 2122, 1445, 1539, 2903, 1796, 1401, 1350, 4051, 2031, 1418, 1534, 1322, 2969, 3036, 776, 1297, 4063, 2551, 1139, 969, 1251, 2650, 344, 3918, 1419, 2546, 2229, 2774, 3479, 2148, 2131, 2482, 1565, 868, 1117, 2378, 289, 2132, 1949, 2402, 2579, 520, 1665, 1661, 1762, 1812, 2280, 1177, 2009, 1888, 1195, 550, 1567, 3015, 639, 1353, 986, 1837, 312, 3747, 2120, 3536, 944, 275, 1784, 1304, 3924, 2463, 523, 3100, 1055, 1603, 1745, 1396, 1951, 3003, 1352, 1785, 1236, 2356, 1078, 3014, 717, 637, 3383, 1427, 2320, 1122, 2072, 1185, 4042, 795, 305, 497, 1606, 1412, 1054, 3712, 1507, 1203, 1342, 1514, 1493, 2469, 1084, 2715, 1756, 263, 1157, 2359, 4034, 1023, 897, 4000, 879, 1266, 3950, 3812, 1180, 768, 3143, 3213, 483, 1908, 3301, 2336, 464, 1145, 931, 2163, 1616, 3413, 1653, 2124, 1359, 1657, 1043, 1808, 1092, 1773, 951, 901, 1194, 2678, 3765, 1099, 3728, 1746, 1171, 851, 4044, 285, 2473, 343, 2873, 1556, 2237, 1281, 3525, 1651, 1912, 1032, 1467, 1421, 875, 3689, 4023, 1743, 3654, 1602, 3784, 1391, 3296, 664, 2390, 2806, 1334, 569, 1320, 465, 1387, 2548, 1650, 1127, 1214, 3636, 3934, 2073, 2621, 441, 841, 1547, 1249, 4041, 2802, 1153, 3349, 1471, 1206, 1886, 1799, 3868, 1028, 3366, 2350, 355, 2638, 1586, 1863, 1442, 1027, 1589, 839, 1679, 1717, 2807, 596, 907, 1444, 1826, 4059, 573, 828, 1165, 4055, 1344, 2655, 1386, 2302, 338, 487, 2024, 686, 1660, 267, 987, 1639, 3055, 1560, 3354, 960, 597, 3490, 1132, 2934, 1862, 1265, 979, 1187, 281, 1855, 3471, 3071, 1046, 3011, 1431, 278, 1896, 1335, 1227, 2256, 1778, 456, 1945, 339, 1192, 570, 1824, 3227, 1089, 1173, 3785, 900, 1731, 1348, 2403, 2235, 2527, 2095, 3833, 1920, 1697, 864, 1109, 679, 1502, 727, 1230, 1552, 882, 3065, 1488, 1944, 2128, 3627, 2372, 2265, 2134, 2057, 3343, 3438, 914, 2589, 3224, 2862, 956, 287, 4077, 295, 584, 922, 1698, 1955, 1885, 703, 1191, 1392, 3740, 863, 382, 2998, 1031, 1220, 3597, 1805, 1200, 1375, 2016, 2602, 1625, 3258, 2609, 1527, 3331, 609, 2512, 1750, 2699, 3982, 629, 365, 1932, 1330, 2683, 958, 1783, 865, 361, 3999, 1655, 3580, 265, 1479, 576, 4025, 950, 2244, 455, 2520, 1083, 1861, 1685, 517, 2461, 1607, 1760, 2452, 371, 1605, 2947, 985, 2342, 2471, 1011, 954, 2932, 4028, 1300, 3013, 3220, 2351, 1137, 1529, 1691, 2376, 2106, 3890, 3638, 1425, 2322, 1594, 514, 1430, 439, 1505, 1263, 1125, 3067, 1860, 1294, 948, 2299, 1219, 480, 447, 1847, 2162, 1413, 3892, 2718, 1852, 1673, 2075, 3513, 1898, 2247, 3141, 685, 2800, 1543, 1169, 1436, 937, 1561, 2797, 3060, 2326, 2300, 2002, 2189, 2822, 2487, 926, 2595, 966, 1545, 4078, 1063, 1473, 2980, 3548, 349, 4082, 1870, 2549, 2255, 3121, 850, 3352, 1233, 2744, 1981, 1333, 310, 2967, 3661, 1713, 2629, 1207, 3949, 871, 3910, 1097, 3839, 1212, 1809, 1457, 302, 1683, 291, 2020, 1524, 2133, 3855, 3124, 1557, 3790, 1489, 3177, 893, 3518, 548, 3300, 3231, 3087, 1523, 3829, 973, 2478, 1121, 785, 1481, 2145, 3010, 3751, 3675, 2217, 1977, 1296, 1279, 1082, 1883, 2742, 595, 1795, 2863, 3501, 1144, 873, 300, 1190, 280, 722, 1522, 591, 603, 1841, 2499, 4073, 1494, 2219, 2570, 2111, 3016, 4039, 1354, 2146, 2614, 1692, 1747, 1983, 2591, 3377, 2392, 1749, 1398, 3037, 1732, 1706, 335, 3448, 1634, 1383, 2165, 1308, 2306, 1155, 3568, 336, 493, 3147, 2203, 4010, 475, 1381, 709, 1085, 2575, 4075, 2022, 1617, 3321, 2311, 3169, 1923, 1288, 2198, 1283, 2649, 3708, 1478, 3474, 1584, 2948, 4065, 2462, 562, 1075, 2791, 3510, 2143, 3913, 273, 681, 3102, 2789, 437, 1372, 1703, 2172, 1108, 2153, 2613, 1470, 1341, 1793, 1228, 2113, 2412, 3076, 1608, 3483, 4030, 2283, 1823, 1492, 2545, 3057, 3667, 1306, 283, 2781, 3592, 2700, 791, 2098, 1572, 1973, 1496, 3081, 2159, 803, 1541, 1991, 2508, 2065, 1649, 1940, 2854, 2354, 1077, 946, 1258, 1802, 1647, 4068, 3424, 2243, 835, 1066, 1916, 654, 378, 642, 2935, 3285, 1964, 3769, 436, 3032, 574, 2130, 2118, 1619, 393, 1172, 3216, 1275, 4069, 3091, 2824, 4033, 1853, 270, 1581, 3314, 3340, 634, 322, 936, 571, 2674, 3175, 877, 3842, 1284, 1867, 1282, 1718, 820, 1825, 4046, 1154, 3230, 1537, 1313, 2034, 3985, 1174, 2775, 672, 978, 1454, 334, 762, 296, 2340, 1546, 2199, 3250, 2628, 4003, 2361, 2368, 1388, 2224, 2667, 1303, 1753, 284, 1927, 2447, 640, 1626, 2515, 2918, 2809, 1774, 1476, 3947, 1259, 753, 3838, 1740, 3889, 2884, 3256, 773, 2560, 4074, 1804, 1292, 3619, 2722, 1637, 2408, 3452, 1124, 1321, 3193, 3083, 2568, 4043, 306, 563, 2371, 1635, 1994, 1807, 3330, 1797, 1542, 1119, 1358, 320, 1379, 2292, 694, 2427, 2717, 2912, 1621, 1319, 974, 1239, 2155, 3612, 348, 4049, 1879, 2013, 2496, 3084, 1569, 2375, 2023, 2504, 1642, 2523, 990, 1723, 830, 734, 1290, 3637, 3529, 1936, 726, 1999, 347, 1922, 1767, 3051, 1508, 2457, 2923, 1570, 845, 3248, 662, 3182, 1588, 442, 2195, 1822, 2388, 3254, 2790, 3272, 1813, 1562, 3428, 2986, 2267, 1433, 3364, 2905, 1992, 690, 1532, 1965, 3203, 2389, 416, 2793, 1666, 314, 418, 1267, 2720, 346, 1895, 1721, 2773, 3058, 3307, 765, 1456, 3355, 3632, 3472, 3517, 1243, 290, 1641, 1060, 3556, 1050, 1420, 3375, 3735, 1222, 333, 2796, 1367, 323, 2043, 3324, 529, 2103, 2157, 2677, 1759, 2820, 1198, 1631, 2222, 2422, 2709, 2385, 3604, 1201, 1310, 2014, 2801, 3860, 3995, 3569, 2975, 1408, 2785, 643, 2759, 3461, 1158, 3593, 1455, 1868, 688, 1475, 3257, 2719, 2297, 1274, 928, 1761, 2830, 1550, 1910, 4066, 303, 2238, 1285, 2841, 1859, 3234, 561, 1715, 781, 1850, 1798, 1416, 1714, 3454, 2436, 3077, 2839, 3047, 3629, 1429, 2006, 1967, 2271, 3929, 2345, 292, 528, 4093, 556, 1568, 3584, 2603, 3397, 3979, 3865, 1073, 3677, 2377, 1564, 2069, 271, 293, 834, 3412, 1307, 2432, 3031, 2596, 710, 4058, 2209, 2664, 1510, 3104, 1504, 3652, 2874, 2489, 536, 555, 4076, 2269, 1592, 600, 417, 3943, 1720, 3378, 2585, 2117, 743, 1781, 2472, 485, 881, 1378, 1469, 913, 2273, 1963, 557, 1098, 1734, 2925, 2435, 277, 400, 3663, 3382, 3029, 3857, 2757, 2625, 1926, 408, 1042, 2610, 3872, 1800, 1727, 2539, 2944, 2328, 1402, 3345, 1273, 2882, 3129, 2341, 3007, 470, 2697, 1509, 1737, 1347, 2909, 1160, 2633, 488, 2624, 479, 3614, 2810, 2092, 3922, 1988, 2011, 2787, 1791, 1356, 2838, 2519, 1671, 3843, 3481, 1771, 3830, 2323, 419, 3524, 1049, 1424, 3909, 2440, 1729, 4017, 1590, 2082, 3241, 3134, 2312, 1223, 1149, 2771, 3729, 3707, 3994, 1857, 3710, 1959, 3508, 376, 748, 911, 2090, 3173, 2881, 3927, 2232, 2126, 1371, 2749, 1976, 1449, 1459, 1943, 1468, 3848, 1414, 1595, 2788, 2264, 2910, 1881, 2061, 2051, 356, 1828, 2723, 1205, 1843, 592, 3486, 1765, 3288, 972, 2931, 2974, 1464, 2725, 3464, 2448, 2215, 1242, 511, 3498, 2533, 2421, 2415, 401, 621, 1151, 2588, 3399, 1007, 1677, 2626, 1662, 2737, 2353, 1295, 699, 808, 3370, 1909, 3075, 1884, 3659, 2077, 2550, 2509, 2445, 294, 1928, 3881, 2125, 1676, 2507, 2708, 452, 2384, 2900, 3695, 1978, 2202, 2859, 319, 3561, 3557, 3379, 2477, 2698, 2221, 1563, 953, 4072, 353, 1674, 3080, 3575, 4084, 619, 3786, 3469, 3600, 3683, 1689, 3907, 3681, 1658, 1678, 3030, 2586, 1384, 1327, 1632, 2313, 2704, 2156, 2405, 983, 964, 2514, 566, 2123, 3431, 3316, 2917, 1806, 3405, 1667, 3944, 3168, 2866, 2654, 1338, 3426, 912, 1680, 2643, 308, 3750, 3642, 2587, 1903, 3298, 2748, 3885, 2695, 3581, 1466, 2566, 2474, 1535, 3738, 3475, 2584, 1794, 3000, 2868, 1979, 3952, 963, 2107, 3951, 742, 360, 2324, 3516, 2502, 3478, 458, 2528, 3905, 2825, 3038, 3262, 1833, 714, 298, 2644, 1351, 1482, 414, 3724, 3293, 351, 3299, 611, 499, 1193, 661, 1389, 2852, 826, 630, 2381, 2177, 1520, 3247, 1438, 2604, 1613, 3243, 2346, 2284, 3876, 2028, 2954, 3734, 2295, 3082, 1764, 2053, 1423, 884, 2428, 3358, 2231, 3166, 2285, 2926, 1790, 3200, 1312, 3933, 2045, 329, 2557, 916, 279, 2362, 1140, 2018, 751, 1422, 2397, 2140, 309, 1450, 274, 2530, 2922, 1709, 693, 1287, 1451, 3187, 451, 3852, 3281, 3034, 1840, 2987, 1015, 3123, 3494, 2004, 1696, 3682, 2623, 2008, 2096, 2055, 2187, 1380, 2564, 3856, 2430, 2357, 3463, 671, 2286, 2772, 1245, 1548, 1234, 2168, 2887, 1604, 767, 2277, 3711, 1559, 3170, 2571, 3489, 315, 833, 3294, 3052, 3845, 3984, 3826, 2829, 2330, 1446, 3804, 2501, 3323, 1491, 1757, 598, 2505, 3864, 2185, 2416, 1705, 521, 1224, 3271, 2398, 1411, 259, 2178, 3493, 650, 3815, 646, 4064, 473, 691, 2696, 938, 2823, 3966, 2821, 1045, 1257, 2245, 3553, 3727, 2511, 615, 1544, 2167, 2765, 299, 337, 1390, 3276, 328, 947, 3429, 1856, 3476, 2794, 1842, 3455, 2252, 2426, 819, 3608, 2494, 2089, 2206, 2747, 1170, 2553, 2309, 1614, 3098, 3684, 1540, 2263, 1939, 1950, 3491, 3771, 1624, 1995, 2274, 3908, 1357, 3702, 3499, 2116, 929, 1339, 2544, 2731, 426, 3066, 1370, 1695, 2752, 2691, 2942, 2559, 1681, 1355, 1687, 971, 2660, 3495, 2161, 1184, 684, 1664, 2558, 618, 3796, 3631, 927, 1623, 1278, 3079, 1040, 297, 1240, 1969, 1780, 3001, 2281, 2216, 2724, 1329, 2050, 2740, 935, 1501, 998, 1081, 1286, 2792, 2173, 2423, 2777, 3745, 3028, 1277, 2642, 2850, 2331, 3446, 1711, 774, 3902, 1324, 3217, 3044, 2988, 3766, 3599, 1111, 2431, 2085, 3190, 2894, 1583, 2573, 389, 1512, 1024, 3912, 1744, 3643, 2491, 2668, 2204, 942, 2911, 3385, 2686, 2282, 1834, 1591, 3685, 2418, 816, 918, 2303, 1905, 2753, 1013, 404, 1147, 608, 2805, 2021, 2883, 3132, 2158, 2738, 3387, 749, 593, 2875, 2962, 1830, 3507, 1123, 2210, 2240, 1792, 3356, 2531, 2994, 3764, 3703, 2327, 1899, 3926, 373, 1363, 1612, 866, 2429, 537, 3191, 3109, 2983, 2047, 2246, 2276, 2766, 2714, 1250, 2869, 3623, 3840, 2074, 1966, 2424, 3062, 2612, 2521, 2739, 3704, 2569, 2705, 2876, 3304, 3326, 1872, 3297, 4020, 2896, 2442, 3407, 744, 2321, 2952, 2580, 3893, 4012, 3587, 2701, 1937, 2288, 3969, 994, 2622, 3374, 3678, 2600, 2035, 1638, 2630, 2563, 2836, 1069, 3870, 2335, 2816, 2449, 2702, 1472, 1948, 1163, 2251, 526, 3851, 3563, 1815, 1188, 2804, 3368, 3743, 2101, 3680, 2634, 1954, 2833, 2729, 496, 2364, 1835, 2576, 3618, 2137, 1415, 890, 2234, 3009, 1694, 2275, 3904, 977, 3564, 1579, 2639, 3799, 3899, 3813, 2562, 1827, 3549, 4015, 3662, 2636, 3433, 3776, 1276, 321, 996, 2760, 755, 1686, 2193, 3849, 1875, 2682, 512, 3105, 3505, 880, 2475, 620, 3439, 405, 352, 1575, 2982, 1136, 2728, 3178, 2179, 1118, 3533, 2743, 740, 3523, 2495, 2339, 651, 2919, 2756, 1598, 3573, 1989, 1816, 1159, 3937, 1777, 3640, 481, 3520, 1044, 3202, 2419, 304, 2688, 2315, 2406, 3242, 859, 2151, 1065, 2971, 3721, 358, 3156, 760, 3906, 2476, 3823, 3940, 3527, 676, 1935, 4011, 3477, 2374, 578, 2139, 2902, 2466, 3877, 392, 2081, 1400, 1531, 3195, 2213, 2901, 3809, 957, 2734, 3384, 2500, 3732, 3787, 3185, 3622, 2268, 2885, 1460, 1175, 1956, 377, 540, 2370, 2176, 1346, 2615, 2249, 778, 3253, 2460, 4021, 3172, 3998, 2184, 423, 1656, 362, 857, 1704, 3674, 3085, 1993, 3457, 4019, 3582, 933, 700, 1722, 1503, 1848, 564, 3822, 2150, 3588, 3874, 1087, 1566, 2754, 1701, 3020, 2646, 3993, 1361, 1253, 3847, 1876, 1161, 3155, 3140, 2253, 3736, 2635, 2844, 2631, 1996, 409, 1150, 2764, 2201, 1874, 2262, 2007, 3509, 3198, 2485, 2228, 2904, 402, 2087, 1890, 3579, 2819, 3992, 2960, 2041, 1518, 3733, 3887, 2661, 490, 3884, 2017, 2348, 2079, 943, 1610, 2779, 1684, 3545, 2109, 3965, 2950, 3500, 1615, 3609, 2308, 2059, 2470, 982, 3450, 3503, 965, 891, 2465, 1754, 3539, 2856, 3687, 2529, 2337, 4085, 506, 3646, 3420, 1558, 1682, 1911, 1452, 3325, 3261, 3265, 2105, 3531, 1887, 2183, 1622, 2741, 3290, 3653, 783, 1331, 1176, 2526, 2930, 658, 2847, 3069, 800, 2681, 2601, 2690, 2200, 2936, 3362, 2036, 3996, 1708, 2218, 3289, 2855, 2898, 2154, 3240, 2492, 3462, 2248, 3819, 4005, 2899, 3798, 794, 2446, 3165, 1325, 1763, 2687, 2015, 1582, 3161, 2254, 1739, 1443, 2409, 3541, 665, 4022, 3122, 3040, 2618, 3235, 3459, 2890, 3113, 2913, 3862, 3669, 3649, 3002, 3814, 3948, 2679, 1938, 2250, 2318, 3402, 3025, 1889, 1477, 2659, 3837, 1986, 3496, 2067, 3335, 1741, 1958, 1128, 2236, 2732, 2393, 1041, 2135, 513, 2070, 1577, 3811, 3880, 813, 1858, 649, 2119, 3237, 3144, 459, 2864, 3056, 2878, 3295, 1987, 2488, 3566, 2730, 3244, 2943, 2166, 2958, 3432, 3869, 1646, 1217, 1609, 2316, 3901, 641, 1519, 3980, 2380, 2726, 3138, 3045, 2506, 2977, 2598, 2662, 1997, 2304, 2060, 2369, 3793, 2795, 750, 1210, 2174, 1244, 3752, 3595, 2382, 3960, 2175, 2438, 3078, 1374, 2554, 708, 3434, 4062, 1576, 2333, 3806, 1768, 3054, 2404, 2891, 2716, 3521, 1742, 1644, 2848, 3938, 1133, 2383, 2094, 3093, 3419, 3131, 1914, 2906, 2194, 2171, 3583, 2670, 1906, 1878, 2214, 3041, 3571, 2594, 3408, 3791, 2858, 1326, 1864, 3332, 3586, 2510, 2049, 2991, 1915, 2525, 2933, 3443, 2611, 2293, 1062, 1838, 2893, 3990, 2291, 2616, 399, 3228, 1435, 1298, 3615, 3767, 2966, 2877, 2920, 2572, 2410, 2149, 2780, 1629, 2656, 2672, 3411, 1776, 3647, 3955, 2755, 3064, 364, 3883, 3006, 1924, 627, 3021, 2693, 3598, 532, 647, 736, 1052, 4008, 4018, 1068, 3739, 2871, 3035, 3180, 2999, 3232, 2845, 1712, 3782, 3882, 1877, 1961, 3762, 3435, 2581, 3287, 2289, 3706, 2675, 3610, 2783, 1406, 3449, 741, 3430, 3760, 3347, 3644, 3192, 2170, 3562, 2879, 3283, 696, 2582, 2711, 2578, 3816, 2152, 1758, 3126, 1012, 2039, 2673, 3967, 3817, 1941, 1880, 3931, 2338, 3522, 2480, 2266, 2467, 1079, 4094, 1611, 2464, 1336, 1366, 2207, 2141, 3897, 3008, 2907, 3506, 1580, 2138, 2270, 1008, 3894, 644, 870, 3686, 1006, 3958, 3263, 2712, 3465, 3059, 2420, 2964, 3492, 1851, 2332, 1668, 3127, 3534, 1902, 3725, 2985, 2387, 1070, 2992, 4081, 1769, 3919, 4013, 3873, 3148, 2352, 1373, 674, 2019, 659, 1426, 2968, 1751, 2665, 1735, 1536, 3211, 2627, 3466, 2208, 3341, 1199, 3792, 3700, 3427, 3422, 3511, 2831, 867, 542, 3251, 3997, 2455, 3795, 3718, 3333, 1818, 3094, 3650, 1819, 2258, 3825, 3174, 2032, 3694, 3353, 1919, 2745, 2121, 1766, 2782, 2817, 2407, 2927, 1113, 3591, 546, 3267, 2543, 3613, 790, 1953, 1578, 3671, 3551, 3334, 3171, 3572, 3306, 3805, 553, 3836, 2599, 2468, 3746, 2784, 2301, 2808, 2892, 2186, 2058, 2066, 2373, 3380, 3975, 1252, 3286, 2835, 2434, 3218, 3577, 3246, 2928, 3396, 666, 1585, 680, 3404, 3713, 3660, 461, 3194, 3312, 2536, 3184, 3989, 2949, 3391, 3381, 3209, 3963, 1984, 3485, 3394, 2084, 3197, 588, 2552, 3280, 3238, 2953, 1573, 1738, 3722, 3968, 2027, 1675, 2826, 3400, 2981, 2648, 3778, 1600, 1506, 3773, 2608, 2078, 2363, 3774, 1716, 2360, 1690, 1730, 3589, 3042, 3565, 3395, 3451, 3226, 2484, 695, 883, 3108, 3544, 508, 2329, 3633, 3337, 2188, 2401, 2915, 804, 3756, 1803, 2180, 3097, 2840, 3222, 3137, 2129, 3017, 3360, 3440, 1849, 3453, 3484, 1618, 3639, 3731, 3974, 3046, 1648, 3339, 3714, 3558, 3858, 3373, 2010, 3914, 3916, 2684, 1699, 2181, 3691, 1846, 2071, 3236, 3268, 3039, 3891, 1332, 590, 3012, 2278, 2003, 1362, 2767, 2537, 1918, 2978, 2396, 3005, 1152, 431, 3788, 4007, 3658, 2450, 4083, 2916, 3142, 2144, 1553, 2814, 2970, 2946, 3688, 2798, 3555, 3488, 898, 2770, 970, 1269, 3620, 2959, 860, 3460, 3406, 4006, 3292, 3456, 2735, 2619, 1786, 2597, 3149, 3152, 1033, 2542, 1972, 1167, 1960, 784, 2846, 2535, 1772, 952, 2456, 2399, 3033, 3867, 3962, 3468, 1528, 1246, 2811, 3119, 2941, 438, 961, 4086, 4087, 3763, 831, 2961, 2497, 3668, 2142, 3162, 2169, 3777, 747, 2853, 3810, 3770, 4004, 2037, 3350, 2056, 1120, 2689, 2861, 2294, 3027, 2849, 3748, 1719, 2417, 3423, 2989, 3961, 3458, 2574, 2086, 1074, 1409, 3106, 3697, 3074, 1291, 3445, 3367, 2924, 428, 3151, 3365, 3201, 3781, 3139, 3932, 1640, 3070, 3828, 1957, 1894, 3361, 3310, 1925, 444, 772, 3761, 2733, 3259, 1129, 3502, 2347, 2937, 3801, 3585, 1970, 2076, 2239, 3421, 2490, 3260, 2694, 4016, 3945, 2454, 3574, 1484, 3871, 812, 3233, 2997, 789, 2669, 3783, 2298, 1551, 3987, 3363, 3925, 3705, 4080, 3742, 3528, 1021, 1934, 3512, 3679, 995, 3114, 3388, 3543, 967, 3624, 2984, 2040, 3542, 3284, 668, 2607, 3088, 1059, 3327, 3497, 3780, 494, 3709, 1672, 2395, 4079, 3269, 1186, 3357, 2857, 3133, 3552, 3626, 1513, 3282, 1026, 446, 3554, 2192, 3417, 2233, 761, 2832, 3594, 847, 2641, 2812, 3808, 2220, 1368, 3651, 2976, 3921, 2182, 1106, 3875, 1865, 2786, 836, 2605, 3344, 3803, 3515, 2843, 2888, 2190, 3403, 3757, 2951, 1142, 3928, 2386, 3359, 2334, 2940, 1663, 3611, 1138, 2033, 3252, 3617, 2955, 1630, 3717, 3755, 1410, 2632, 1707, 3092, 2870, 3504, 3319, 1921, 2996, 522, 3409, 1893, 3807, 3154, 3186, 3720, 3903, 1189, 3981, 3414, 2776, 705, 3136, 2503, 1904, 1511, 3596, 3863, 3118, 786, 2160, 3964, 3578, 2860, 4014, 3329, 3535, 3648, 1179, 3053, 3841, 3519, 3196, 2710, 2100, 3844, 2257, 2651, 1933, 2379, 3744, 1441, 2355, 2956, 3607, 855, 3086, 1225, 4009, 2260, 3322, 3022, 530, 3204, 1913, 2493, 2097, 1036, 3820, 3019, 1080, 3779, 3392, 3112, 899, 2366, 3800, 2990, 2973, 2769, 2606, 3317, 2518, 2498, 1801, 3759, 1095, 999, 3941, 2394, 2762, 3221, 2593, 1787, 3157, 2453, 3116, 3616, 3072, 3526, 2479, 3164, 3953, 3789, 3223, 3376, 2837, 3634, 3570, 1775, 3900, 3719, 3730, 3303, 2000, 3972, 2517, 1417, 3225, 968, 2938, 1215, 1724, 3389, 3567, 2746, 1197, 3336, 3641, 2437, 3603, 3676, 325, 3245, 3043, 3976, 3342, 1064, 2736, 3338, 1831, 2290, 3441, 2637, 3048, 3532, 941, 1829, 1130, 3911, 3101, 4090, 3930, 3920, 3369, 2196, 3888, 3699, 2099, 856, 3068, 1659, 2314, 4002, 3775, 793, 3249, 2703, 1985, 3726, 2617, 1974, 3189, 3444, 1377, 1669, 2226, 2993, 3096, 2939, 3176, 3318, 1343, 2721, 3665, 2671, 3602, 3346, 3050, 2865, 3181, 2555, 3482, 3313, 448, 2889, 2895, 2914, 1789, 3302, 3547, 2411, 1725, 1968, 3315, 3415, 2344, 3090, 4088, 3208, 1871, 2054, 1115, 4092, 2590, 3698, 2921, 1499, 2001, 2657, 1654, 3480, 3023, 2995, 3089, 2867, 3959, 2897, 2540, 1500, 3827, 2538, 3125, 3954, 2886, 1929, 2310, 1975, 3696, 3386, 3802, 3372, 3214, 2064, 2441, 3957, 3487, 1596, 2044, 2093, 558, 3348, 3850, 1458, 3270, 3956, 1399, 2026, 3024, 2242, 1048, 2279, 3305, 2957, 3199, 771, 763, 2115, 1866, 2136, 3099, 3275, 2763, 3107, 2343, 2005, 3666, 1270, 2963, 3605, 2259, 3153, 2818, 1485, 3255, 3309, 2029, 3320, 1432, 1628, 2225, 2104, 4089, 3004, 2828, 589, 3120, 2583, 3971, 1533, 1204, 2524, 2880, 3942, 3135, 1832, 3026, 1946, 2761, 802, 906, 3390, 1845, 3279, 2367, 1814, 991, 843, 3103, 721, 1782, 3473, 1114, 1058, 2778, 3768, 2439, 3311, 3692, 2640, 4091, 2979, 3110, 2803, 3645, 1574, 827, 2400, 3063, 2680, 678, 3576, 3277, 3073, 2872, 1002, 3794, 2261, 849, 2459, 2212, 3210, 3167, 2706, 3179, 2108, 3470, 3546, 3150, 2676, 3655, 3866, 2813, 1571, 3737, 3514, 2758, 3401, 3436, 3917, 2205, 818, 1601, 3219, 2325, 1112, 2727, 2666, 3657, 3758, 874, 3447, 3215, 1907, 2444, 2025, 1525])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_mappings.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "logprob_ds = load_dataset(constants.LLAMA2_LOGPROB_DATASETS[0])['validation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from datasets import Dataset\n",
    "tokenized_ds = cast(Dataset, load_dataset(constants.tokenized_corpus_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# token mapping is a dict of (token -> (document, seq))\n",
    "token_mappings_path = \"../data/token_mappings\"\n",
    "with open(token_mappings_path, \"rb\") as f:\n",
    "    token_mappings = pickle.load(f)\n",
    "\n",
    "# get positions of all occurrences of a token in the tokenized corpus\n",
    "def get_token_positions(token: int) -> list[ tuple[ int, int ] ]:\n",
    "    return token_mappings[token]\n",
    "    # return [(i, j) for i, doc in enumerate(tokenized_ds['validation']['tokens']) for j, t in enumerate(doc) if t == token]\n",
    "\n",
    "def get_logprob(token: int) -> float:\n",
    "    # ignore occurances at the start of each document\n",
    "    positions = [p for p in get_token_positions(token) if p[1] != 0]\n",
    "    if len(positions) == 0:\n",
    "        return 0.0\n",
    "    return sum([logprob_ds[i]['logprobs'][j - 1] for i, j in positions]) / len(positions)\n",
    "\n",
    "token_counts = {k: len(v) for k, v in token_mappings.items()}\n",
    "\n",
    "token_logprobs = {token: get_logprob(token) for token in token_mappings.keys()}\n",
    "\n",
    "def get_group_weighted_logprog(group: list[int]) -> float:\n",
    "    token_counts = {k: len(v) for k, v in token_mappings.items()}\n",
    "    token_logprobs = {token: get_logprob(token) for token in token_mappings.keys()}\n",
    "    group = [token for token in group if token in token_logprobs]\n",
    "    if len(group) == 0:\n",
    "        logging.warning(f\"Group {group} has no tokens in token_logprobs; returning 0.0\")\n",
    "        return 0.0\n",
    "    return sum([token_logprobs[token] * token_counts[token] for token in group]) / sum([token_counts[token] for token in group])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3.92385858499659"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_group_weighted_logprog([2, 3, 4, 5, 6, 7, 8, 9, 10, 25, 101, 4001, 2003, 2004])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import cast\n",
    "from datasets import Dataset\n",
    "\n",
    "@dataclass\n",
    "class TokenModelStats:\n",
    "    token: int\n",
    "    model: str\n",
    "    logprob_sum: float\n",
    "    count: int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.00271428469568491"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logprob_ds[0][\"logprobs\"][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing model transcendingvictor/delphi-llama2-100k-validation-logprobs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10982it [09:30, 19.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing model transcendingvictor/delphi-llama2-200k-validation-logprobs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10982it [09:30, 19.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing model transcendingvictor/delphi-llama2-400k-validation-logprobs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10982it [09:24, 19.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing model transcendingvictor/delphi-llama2-800k-validation-logprobs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10982it [09:26, 19.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing model transcendingvictor/delphi-llama2-1.6m-validation-logprobs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10982it [09:26, 19.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing model transcendingvictor/delphi-llama2-3.2m-validation-logprobs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10982it [09:24, 19.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing model transcendingvictor/delphi-llama2-6.4m-validation-logprobs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10982it [09:23, 19.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing model transcendingvictor/delphi-llama2-12.8m-validation-logprobs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10982it [09:34, 19.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing model transcendingvictor/delphi-llama2-25.6m-validation-logprobs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10982it [09:20, 19.58it/s]\n"
     ]
    }
   ],
   "source": [
    "# we're going to iterate through models, and for each model we're going to iterate through all the tokens\n",
    "# and calculate the weighted logprob for each token, then store them in a dict of (token, model_name) -> TokenModelStats\n",
    "\n",
    "from transformers import AutoModelForCausalLM\n",
    "from delphi.eval.constants import LLAMA2_LOGPROB_DATASETS\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def get_model_name_from_logprob_dataset_name(dataset_id: str) -> str:\n",
    "    return dataset_id.split(\"/\")[-1].split(\"-validation-logprobs\")[0]\n",
    "\n",
    "tokenized_ds = cast(Dataset, load_dataset(constants.tokenized_corpus_dataset))[\"validation\"][\"tokens\"]  # type: ignore\n",
    "model_token_stats = {}\n",
    "for model_dataset in constants.LLAMA2_LOGPROB_DATASETS:\n",
    "    model_name = get_model_name_from_logprob_dataset_name(model_dataset)\n",
    "    print(f\"Processing model {model_dataset}\")\n",
    "    logprob_ds = cast(Dataset, load_dataset(model_dataset))['validation']\n",
    "    token_counts = dict()\n",
    "    token_logprob_sums = dict()\n",
    "    for i, doc in tqdm(enumerate(tokenized_ds)):\n",
    "        for j, token in enumerate(doc):\n",
    "            if j == 0:\n",
    "                continue\n",
    "            if token not in token_counts:\n",
    "                token_counts[token] = 0\n",
    "                token_logprob_sums[token] = 0.0\n",
    "            token_counts[token] += 1\n",
    "            try:\n",
    "                token_logprob_sums[token] += logprob_ds[i]['logprobs'][j - 1]\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing token {token} at position {i}, {j}\" )\n",
    "                raise e\n",
    "    for token, token_count in token_counts.items():\n",
    "        token_logprob_sum = token_logprob_sums[token]\n",
    "        model_token_stats[(token, model_name)] = TokenModelStats(token, model_name, token_logprob_sum, token_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"../data/token_model_stats.pkl\", \"rb\") as f:\n",
    "    model_token_stats = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TokenModelStats(token=1000, model='delphi-llama2-100k', logprob_sum=-4283.318835604936, count=1941)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_token_stats[(1000, \"delphi-llama2-100k\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/token_model_stats.pkl\", \"wb\") as f:\n",
    "    pickle.dump(model_token_stats, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_token_group_loss(\n",
    "    group: list[int],\n",
    "    model: str,\n",
    "    model_token_stats: dict[tuple[int, str], TokenModelStats],\n",
    ") -> float:\n",
    "    group = [token for token in group if (token, model) in model_token_stats]\n",
    "    if len(group) == 0:\n",
    "        logging.warning(\n",
    "            f\"Group {group} has no tokens in model_token_stats; returning 0.0\"\n",
    "        )\n",
    "        return 0.0\n",
    "    return sum(\n",
    "        [model_token_stats[(token, model)].logprob_sum for token in group]\n",
    "    ) / sum([model_token_stats[(token, model)].count for token in group])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3.924027909847916"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_token_group_loss([2, 3, 4, 5, 6, 7, 8, 9, 10, 25, 101, 4001, 2003, 2004], \"delphi-llama2-100k\", model_token_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_group_logprob(token_group: list[int]) -> float:\n",
    "    # ignore occurances at the start of each document\n",
    "    positions = []\n",
    "    for t in token_group:\n",
    "        positions.extend([p for p in get_token_positions(t) if p[1] != 0])\n",
    "    if len(positions) == 0:\n",
    "        return 0.0\n",
    "    return sum([logprob_ds[i]['logprobs'][j - 1] for i, j in positions]) / len(positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "def get_group_logprob_for_dataset(token_group: list[int], dataset: Dataset) -> float:\n",
    "    positions = []\n",
    "    for t in token_group:\n",
    "        positions.extend([p for p in get_token_positions(t) if p[1] != 0])\n",
    "    if len(positions) == 0:\n",
    "        return 0.0\n",
    "    return sum([dataset[i]['logprobs'][j - 1] for i, j in positions]) / len(positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.7847248025381741"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_group_logprob_for_dataset(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(432,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=432, model='delphi-llama2-100k', logprob_sum=-8307.888183057308, count=17415),\n",
       " (440,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=440, model='delphi-llama2-100k', logprob_sum=-1179.9694573320448, count=16567),\n",
       " (261,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=261, model='delphi-llama2-100k', logprob_sum=-150585.52900058636, count=151848),\n",
       " (403,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=403, model='delphi-llama2-100k', logprob_sum=-9401.606191883911, count=21844),\n",
       " (4045,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=4045, model='delphi-llama2-100k', logprob_sum=-207269.675427588, count=233957),\n",
       " (406,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=406, model='delphi-llama2-100k', logprob_sum=-26130.437831838615, count=21305),\n",
       " (286,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=286, model='delphi-llama2-100k', logprob_sum=-125618.99626725074, count=107556),\n",
       " (799,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=799, model='delphi-llama2-100k', logprob_sum=-12123.617525309324, count=3151),\n",
       " (478,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=478, model='delphi-llama2-100k', logprob_sum=-18903.716076817364, count=12365),\n",
       " (407,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=407, model='delphi-llama2-100k', logprob_sum=-9651.548405426904, count=21040),\n",
       " (385,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=385, model='delphi-llama2-100k', logprob_sum=-37560.27122853976, count=20568),\n",
       " (4037,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=4037, model='delphi-llama2-100k', logprob_sum=-274867.8461031233, count=419484),\n",
       " (505,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=505, model='delphi-llama2-100k', logprob_sum=-20895.584796205163, count=10482),\n",
       " (268,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=268, model='delphi-llama2-100k', logprob_sum=-136369.46767106897, count=150129),\n",
       " (1555,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1555, model='delphi-llama2-100k', logprob_sum=-2180.317711830139, count=389),\n",
       " (622,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=622, model='delphi-llama2-100k', logprob_sum=-16479.318051477894, count=5907),\n",
       " (387,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=387, model='delphi-llama2-100k', logprob_sum=-21857.45202998817, count=15317),\n",
       " (331,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=331, model='delphi-llama2-100k', logprob_sum=-13728.139138053753, count=43098),\n",
       " (397,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=397, model='delphi-llama2-100k', logprob_sum=-35331.459838295355, count=21493),\n",
       " (509,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=509, model='delphi-llama2-100k', logprob_sum=-28463.58284400776, count=10425),\n",
       " (350,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=350, model='delphi-llama2-100k', logprob_sum=-72418.7455187589, count=34938),\n",
       " (614,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=614, model='delphi-llama2-100k', logprob_sum=-13862.97884219396, count=5977),\n",
       " (1318,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1318, model='delphi-llama2-100k', logprob_sum=-5210.574332475662, count=1118),\n",
       " (375,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=375, model='delphi-llama2-100k', logprob_sum=-28468.81613742761, count=25200),\n",
       " (1280,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1280, model='delphi-llama2-100k', logprob_sum=-3918.2366712652147, count=1159),\n",
       " (381,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=381, model='delphi-llama2-100k', logprob_sum=-54592.59120862931, count=25283),\n",
       " (380,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=380, model='delphi-llama2-100k', logprob_sum=-37441.50451241713, count=25793),\n",
       " (13,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=13, model='delphi-llama2-100k', logprob_sum=-68629.48184800183, count=91185),\n",
       " (2112,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2112, model='delphi-llama2-100k', logprob_sum=-6075.0870826561, count=4092),\n",
       " (606,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=606, model='delphi-llama2-100k', logprob_sum=-25576.50695568323, count=6290),\n",
       " (486,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=486, model='delphi-llama2-100k', logprob_sum=-23888.150235034525, count=7107),\n",
       " (2929,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2929, model='delphi-llama2-100k', logprob_sum=-1614.1293687820435, count=215),\n",
       " (4040,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=4040, model='delphi-llama2-100k', logprob_sum=-1730.4620931502432, count=963),\n",
       " (669,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=669, model='delphi-llama2-100k', logprob_sum=-19135.28017473221, count=5047),\n",
       " (269,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=269, model='delphi-llama2-100k', logprob_sum=-258536.64844002645, count=194588),\n",
       " (921,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=921, model='delphi-llama2-100k', logprob_sum=-11373.71804779768, count=2509),\n",
       " (341,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=341, model='delphi-llama2-100k', logprob_sum=-36041.169386230875, count=37723),\n",
       " (2652,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2652, model='delphi-llama2-100k', logprob_sum=-1073.4563946723938, count=250),\n",
       " (492,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=492, model='delphi-llama2-100k', logprob_sum=-28816.198710268363, count=11158),\n",
       " (457,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=457, model='delphi-llama2-100k', logprob_sum=-27744.75704645738, count=14302),\n",
       " (579,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=579, model='delphi-llama2-100k', logprob_sum=-29722.53632134199, count=7090),\n",
       " (544,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=544, model='delphi-llama2-100k', logprob_sum=-27594.45975126326, count=8186),\n",
       " (920,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=920, model='delphi-llama2-100k', logprob_sum=-2082.5957894325256, count=343),\n",
       " (1752,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1752, model='delphi-llama2-100k', logprob_sum=-3354.0809030532837, count=524),\n",
       " (4056,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=4056, model='delphi-llama2-100k', logprob_sum=-47062.34914426878, count=18617),\n",
       " (395,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=395, model='delphi-llama2-100k', logprob_sum=-47754.13096880913, count=18855),\n",
       " (729,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=729, model='delphi-llama2-100k', logprob_sum=-10167.552930183709, count=4074),\n",
       " (412,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=412, model='delphi-llama2-100k', logprob_sum=-47556.82427226752, count=19908),\n",
       " (675,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=675, model='delphi-llama2-100k', logprob_sum=-18605.7873211205, count=4732),\n",
       " (4071,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=4071, model='delphi-llama2-100k', logprob_sum=-1577.710058927536, count=246),\n",
       " (3212,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=3212, model='delphi-llama2-100k', logprob_sum=-84.14499370753765, count=86),\n",
       " (1316,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1316, model='delphi-llama2-100k', logprob_sum=-6333.783849239349, count=1211),\n",
       " (1057,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1057, model='delphi-llama2-100k', logprob_sum=-8425.571177840233, count=1696),\n",
       " (1726,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1726, model='delphi-llama2-100k', logprob_sum=-3348.6774327754974, count=583),\n",
       " (892,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=892, model='delphi-llama2-100k', logprob_sum=-8233.354217082262, count=2508),\n",
       " (1897,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1897, model='delphi-llama2-100k', logprob_sum=-1802.3593538962305, count=503),\n",
       " (993,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=993, model='delphi-llama2-100k', logprob_sum=-9843.402307271957, count=2009),\n",
       " (342,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=342, model='delphi-llama2-100k', logprob_sum=-65437.6459093485, count=38493),\n",
       " (390,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=390, model='delphi-llama2-100k', logprob_sum=-21824.53887132369, count=21231),\n",
       " (720,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=720, model='delphi-llama2-100k', logprob_sum=-7833.757345015183, count=3669),\n",
       " (366,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=366, model='delphi-llama2-100k', logprob_sum=-47455.7790489234, count=29736),\n",
       " (410,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=410, model='delphi-llama2-100k', logprob_sum=-34515.91429725289, count=20029),\n",
       " (425,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=425, model='delphi-llama2-100k', logprob_sum=-39899.869742162526, count=11246),\n",
       " (311,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=311, model='delphi-llama2-100k', logprob_sum=-57498.20430041477, count=52188),\n",
       " (434,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=434, model='delphi-llama2-100k', logprob_sum=-52961.66323093325, count=17045),\n",
       " (628,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=628, model='delphi-llama2-100k', logprob_sum=-12342.385053880513, count=5939),\n",
       " (981,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=981, model='delphi-llama2-100k', logprob_sum=-3670.453022061847, count=2060),\n",
       " (924,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=924, model='delphi-llama2-100k', logprob_sum=-3516.568485688884, count=2363),\n",
       " (888,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=888, model='delphi-llama2-100k', logprob_sum=-7346.444836028852, count=2585),\n",
       " (1,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1, model='delphi-llama2-100k', logprob_sum=-18479.299718447146, count=27511),\n",
       " (367,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=367, model='delphi-llama2-100k', logprob_sum=-5613.086778223515, count=1126),\n",
       " (501,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=501, model='delphi-llama2-100k', logprob_sum=-377.2179862111807, count=148),\n",
       " (1917,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1917, model='delphi-llama2-100k', logprob_sum=-2350.1868218779564, count=481),\n",
       " (372,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=372, model='delphi-llama2-100k', logprob_sum=-25203.102346471976, count=11694),\n",
       " (3398,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=3398, model='delphi-llama2-100k', logprob_sum=-1115.7475950717926, count=166),\n",
       " (577,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=577, model='delphi-llama2-100k', logprob_sum=-26538.549996972084, count=6577),\n",
       " (359,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=359, model='delphi-llama2-100k', logprob_sum=-59394.43541361904, count=25631),\n",
       " (1854,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1854, model='delphi-llama2-100k', logprob_sum=-1925.2099948376417, count=487),\n",
       " (1811,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1811, model='delphi-llama2-100k', logprob_sum=-2187.2254636883736, count=545),\n",
       " (482,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=482, model='delphi-llama2-100k', logprob_sum=-25908.773093402386, count=9479),\n",
       " (698,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=698, model='delphi-llama2-100k', logprob_sum=-15882.704790771008, count=4488),\n",
       " (264,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=264, model='delphi-llama2-100k', logprob_sum=-237800.78725457005, count=209949),\n",
       " (525,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=525, model='delphi-llama2-100k', logprob_sum=-12521.253503884189, count=9166),\n",
       " (1014,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1014, model='delphi-llama2-100k', logprob_sum=-6752.659204062074, count=1849),\n",
       " (429,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=429, model='delphi-llama2-100k', logprob_sum=-45350.72503050417, count=17621),\n",
       " (1004,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1004, model='delphi-llama2-100k', logprob_sum=-3300.3575892448425, count=643),\n",
       " (384,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=384, model='delphi-llama2-100k', logprob_sum=-47507.2030008845, count=24810),\n",
       " (1101,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1101, model='delphi-llama2-100k', logprob_sum=-6211.792765751481, count=1560),\n",
       " (1091,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1091, model='delphi-llama2-100k', logprob_sum=-4447.808271032758, count=1574),\n",
       " (4032,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=4032, model='delphi-llama2-100k', logprob_sum=-24288.217041477397, count=42823),\n",
       " (507,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=507, model='delphi-llama2-100k', logprob_sum=-34048.92972216755, count=10360),\n",
       " (624,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=624, model='delphi-llama2-100k', logprob_sum=-17927.53972554207, count=6121),\n",
       " (837,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=837, model='delphi-llama2-100k', logprob_sum=-5006.776573388837, count=2921),\n",
       " (370,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=370, model='delphi-llama2-100k', logprob_sum=-37003.13807610521, count=27029),\n",
       " (2241,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2241, model='delphi-llama2-100k', logprob_sum=-1602.1098029613495, count=234),\n",
       " (317,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=317, model='delphi-llama2-100k', logprob_sum=-98312.73838175833, count=38740),\n",
       " (670,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=670, model='delphi-llama2-100k', logprob_sum=-4642.016611814499, count=869),\n",
       " (1728,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1728, model='delphi-llama2-100k', logprob_sum=-2646.5350339710712, count=610),\n",
       " (959,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=959, model='delphi-llama2-100k', logprob_sum=-5341.023637890816, count=1150),\n",
       " (829,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=829, model='delphi-llama2-100k', logprob_sum=-10477.966302931309, count=2907),\n",
       " (1067,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1067, model='delphi-llama2-100k', logprob_sum=-3677.979906268418, count=1689),\n",
       " (424,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=424, model='delphi-llama2-100k', logprob_sum=-38598.64833884314, count=17305),\n",
       " (466,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=466, model='delphi-llama2-100k', logprob_sum=-25602.49306824431, count=13072),\n",
       " (3824,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=3824, model='delphi-llama2-100k', logprob_sum=-518.7817126512527, count=98),\n",
       " (1526,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1526, model='delphi-llama2-100k', logprob_sum=-4783.561835885048, count=768),\n",
       " (1102,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1102, model='delphi-llama2-100k', logprob_sum=-3704.4464192921296, count=1603),\n",
       " (1256,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1256, model='delphi-llama2-100k', logprob_sum=-3931.415304630995, count=1115),\n",
       " (515,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=515, model='delphi-llama2-100k', logprob_sum=-25328.1303319484, count=9662),\n",
       " (1019,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1019, model='delphi-llama2-100k', logprob_sum=-9530.377584815025, count=1899),\n",
       " (697,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=697, model='delphi-llama2-100k', logprob_sum=-15469.85566085577, count=4457),\n",
       " (713,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=713, model='delphi-llama2-100k', logprob_sum=-15182.873721659184, count=4465),\n",
       " (602,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=602, model='delphi-llama2-100k', logprob_sum=-14167.94644734636, count=6016),\n",
       " (886,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=886, model='delphi-llama2-100k', logprob_sum=-10183.264666803181, count=2584),\n",
       " (560,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=560, model='delphi-llama2-100k', logprob_sum=-22648.770629048347, count=7634),\n",
       " (1000,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1000, model='delphi-llama2-100k', logprob_sum=-4283.318835604936, count=1941),\n",
       " (2567,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2567, model='delphi-llama2-100k', logprob_sum=-1980.3642435073853, count=272),\n",
       " (500,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=500, model='delphi-llama2-100k', logprob_sum=-19333.92378589604, count=10833),\n",
       " (1235,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1235, model='delphi-llama2-100k', logprob_sum=-6081.393727302551, count=1229),\n",
       " (369,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=369, model='delphi-llama2-100k', logprob_sum=-72439.45319782197, count=28874),\n",
       " (4001,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=4001, model='delphi-llama2-100k', logprob_sum=-620.8694496825337, count=159),\n",
       " (313,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=313, model='delphi-llama2-100k', logprob_sum=-100029.59973216197, count=51307),\n",
       " (282,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=282, model='delphi-llama2-100k', logprob_sum=-68286.12958767405, count=47010),\n",
       " (1030,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1030, model='delphi-llama2-100k', logprob_sum=-7583.451973795891, count=1881),\n",
       " (1365,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1365, model='delphi-llama2-100k', logprob_sum=-4624.72452044487, count=938),\n",
       " (1700,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1700, model='delphi-llama2-100k', logprob_sum=-3228.159956395626, count=628),\n",
       " (4053,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=4053, model='delphi-llama2-100k', logprob_sum=-7842.190741949715, count=10356),\n",
       " (3935,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=3935, model='delphi-llama2-100k', logprob_sum=-649.6267558646505, count=9509),\n",
       " (2042,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2042, model='delphi-llama2-100k', logprob_sum=-1794.8214253783226, count=431),\n",
       " (551,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=551, model='delphi-llama2-100k', logprob_sum=-19448.60345590487, count=8338),\n",
       " (858,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=858, model='delphi-llama2-100k', logprob_sum=-5963.485726501793, count=1862),\n",
       " (1521,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1521, model='delphi-llama2-100k', logprob_sum=-2073.007172241807, count=918),\n",
       " (876,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=876, model='delphi-llama2-100k', logprob_sum=-9389.306504954584, count=2555),\n",
       " (1516,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1516, model='delphi-llama2-100k', logprob_sum=-4019.6857835054398, count=873),\n",
       " (889,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=889, model='delphi-llama2-100k', logprob_sum=-10396.593260630965, count=2572),\n",
       " (495,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=495, model='delphi-llama2-100k', logprob_sum=-22124.354784704745, count=11232),\n",
       " (467,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=467, model='delphi-llama2-100k', logprob_sum=-28430.83628543839, count=11192),\n",
       " (712,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=712, model='delphi-llama2-100k', logprob_sum=-11372.069007307291, count=3803),\n",
       " (844,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=844, model='delphi-llama2-100k', logprob_sum=-5196.820335317869, count=2794),\n",
       " (4060,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=4060, model='delphi-llama2-100k', logprob_sum=-16776.203116431832, count=8212),\n",
       " (503,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=503, model='delphi-llama2-100k', logprob_sum=-11627.60841033049, count=5290),\n",
       " (435,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=435, model='delphi-llama2-100k', logprob_sum=-26952.469406079035, count=13162),\n",
       " (316,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=316, model='delphi-llama2-100k', logprob_sum=-50198.01291294256, count=49155),\n",
       " (711,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=711, model='delphi-llama2-100k', logprob_sum=-16816.40267699957, count=4393),\n",
       " (3749,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=3749, model='delphi-llama2-100k', logprob_sum=-1017.7812118530273, count=158),\n",
       " (1126,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1126, model='delphi-llama2-100k', logprob_sum=-8445.293231248856, count=1580),\n",
       " (601,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=601, model='delphi-llama2-100k', logprob_sum=-21074.542423263192, count=5650),\n",
       " (1301,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1301, model='delphi-llama2-100k', logprob_sum=-1871.1829713582993, count=295),\n",
       " (1947,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1947, model='delphi-llama2-100k', logprob_sum=-1957.853378918022, count=566),\n",
       " (2164,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2164, model='delphi-llama2-100k', logprob_sum=-2497.6384100914, count=424),\n",
       " (599,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=599, model='delphi-llama2-100k', logprob_sum=-24013.598751218058, count=6599),\n",
       " (3673,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=3673, model='delphi-llama2-100k', logprob_sum=-1024.2394304275513, count=111),\n",
       " (1104,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1104, model='delphi-llama2-100k', logprob_sum=-8174.8072682619095, count=1572),\n",
       " (1515,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1515, model='delphi-llama2-100k', logprob_sum=-1928.5542156994343, count=745),\n",
       " (3018,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=3018, model='delphi-llama2-100k', logprob_sum=-1566.787005662918, count=232),\n",
       " (3158,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=3158, model='delphi-llama2-100k', logprob_sum=-1061.8167496919632, count=189),\n",
       " (4054,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=4054, model='delphi-llama2-100k', logprob_sum=-50703.832288629936, count=41177),\n",
       " (1788,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1788, model='delphi-llama2-100k', logprob_sum=-2651.9338334798813, count=539),\n",
       " (330,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=330, model='delphi-llama2-100k', logprob_sum=-48244.78036542982, count=37800),\n",
       " (477,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=477, model='delphi-llama2-100k', logprob_sum=-23341.474450707436, count=11475),\n",
       " (326,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=326, model='delphi-llama2-100k', logprob_sum=-39288.989949245006, count=24636),\n",
       " (332,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=332, model='delphi-llama2-100k', logprob_sum=-84431.51035606675, count=42768),\n",
       " (345,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=345, model='delphi-llama2-100k', logprob_sum=-70457.55642100493, count=38618),\n",
       " (415,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=415, model='delphi-llama2-100k', logprob_sum=-25738.005046429695, count=19423),\n",
       " (4026,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=4026, model='delphi-llama2-100k', logprob_sum=-4681.911520883768, count=14223),\n",
       " (363,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=363, model='delphi-llama2-100k', logprob_sum=-17733.812844001455, count=9804),\n",
       " (504,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=504, model='delphi-llama2-100k', logprob_sum=-16624.44399268739, count=9553),\n",
       " (327,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=327, model='delphi-llama2-100k', logprob_sum=-68286.89681806788, count=43508),\n",
       " (307,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=307, model='delphi-llama2-100k', logprob_sum=-27214.61829027065, count=48830),\n",
       " (1088,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1088, model='delphi-llama2-100k', logprob_sum=-3373.2517703026533, count=1650),\n",
       " (832,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=832, model='delphi-llama2-100k', logprob_sum=-12260.731413573027, count=2957),\n",
       " (411,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=411, model='delphi-llama2-100k', logprob_sum=-34333.051152065396, count=19663),\n",
       " (413,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=413, model='delphi-llama2-100k', logprob_sum=-22889.03831784008, count=17632),\n",
       " (3821,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=3821, model='delphi-llama2-100k', logprob_sum=-582.5124964416027, count=131),\n",
       " (543,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=543, model='delphi-llama2-100k', logprob_sum=-24130.87918008305, count=8486),\n",
       " (1901,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1901, model='delphi-llama2-100k', logprob_sum=-2210.8478595018387, count=541),\n",
       " (468,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=468, model='delphi-llama2-100k', logprob_sum=-23165.90574304387, count=12359),\n",
       " (340,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=340, model='delphi-llama2-100k', logprob_sum=-28372.28549745679, count=18384),\n",
       " (471,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=471, model='delphi-llama2-100k', logprob_sum=-11057.995320104063, count=12071),\n",
       " (567,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=567, model='delphi-llama2-100k', logprob_sum=-21886.71235898137, count=7638),\n",
       " (1495,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1495, model='delphi-llama2-100k', logprob_sum=-2577.6428919434547, count=885),\n",
       " (1181,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1181, model='delphi-llama2-100k', logprob_sum=-2531.5230657458305, count=505),\n",
       " (324,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=324, model='delphi-llama2-100k', logprob_sum=-30887.437264923006, count=13207),\n",
       " (559,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=559, model='delphi-llama2-100k', logprob_sum=-19376.23958107829, count=6891),\n",
       " (398,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=398, model='delphi-llama2-100k', logprob_sum=-36727.57169709355, count=21964),\n",
       " (4057,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=4057, model='delphi-llama2-100k', logprob_sum=-4532.951385729015, count=1657),\n",
       " (1497,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1497, model='delphi-llama2-100k', logprob_sum=-72.42996371537447, count=83),\n",
       " (474,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=474, model='delphi-llama2-100k', logprob_sum=-28056.270981620997, count=12381),\n",
       " (757,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=757, model='delphi-llama2-100k', logprob_sum=-5087.3496936376905, count=3675),\n",
       " (443,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=443, model='delphi-llama2-100k', logprob_sum=-22811.955473690876, count=13969),\n",
       " (718,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=718, model='delphi-llama2-100k', logprob_sum=-11098.430332928896, count=2711),\n",
       " (583,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=583, model='delphi-llama2-100k', logprob_sum=-22739.039746433496, count=6944),\n",
       " (904,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=904, model='delphi-llama2-100k', logprob_sum=-1784.6408425280824, count=2445),\n",
       " (801,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=801, model='delphi-llama2-100k', logprob_sum=-1796.8496067552478, count=3127),\n",
       " (388,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=388, model='delphi-llama2-100k', logprob_sum=-9481.61401951313, count=2258),\n",
       " (575,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=575, model='delphi-llama2-100k', logprob_sum=-15138.47351012379, count=7145),\n",
       " (1670,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1670, model='delphi-llama2-100k', logprob_sum=-3414.3142869472504, count=636),\n",
       " (422,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=422, model='delphi-llama2-100k', logprob_sum=-18722.586640179157, count=5720),\n",
       " (823,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=823, model='delphi-llama2-100k', logprob_sum=-2364.9650921931025, count=3035),\n",
       " (895,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=895, model='delphi-llama2-100k', logprob_sum=-5879.506444945931, count=2478),\n",
       " (572,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=572, model='delphi-llama2-100k', logprob_sum=-19291.01316844113, count=7035),\n",
       " (625,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=625, model='delphi-llama2-100k', logprob_sum=-16548.815319031477, count=5510),\n",
       " (752,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=752, model='delphi-llama2-100k', logprob_sum=-14502.423465967178, count=3471),\n",
       " (4047,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=4047, model='delphi-llama2-100k', logprob_sum=-7944.828968316317, count=2412),\n",
       " (4027,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=4027, model='delphi-llama2-100k', logprob_sum=-4914.041024692357, count=3979),\n",
       " (454,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=454, model='delphi-llama2-100k', logprob_sum=-48.26717188069597, count=222),\n",
       " (391,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=391, model='delphi-llama2-100k', logprob_sum=-56691.10930927005, count=21981),\n",
       " (777,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=777, model='delphi-llama2-100k', logprob_sum=-10913.82538881898, count=2619),\n",
       " (660,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=660, model='delphi-llama2-100k', logprob_sum=-13546.080581199378, count=4996),\n",
       " (1196,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1196, model='delphi-llama2-100k', logprob_sum=-2920.860192462802, count=1410),\n",
       " (997,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=997, model='delphi-llama2-100k', logprob_sum=-3088.064556928264, count=2031),\n",
       " (433,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=433, model='delphi-llama2-100k', logprob_sum=-21154.350488648284, count=16440),\n",
       " (386,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=386, model='delphi-llama2-100k', logprob_sum=-52867.9059853123, count=24505),\n",
       " (872,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=872, model='delphi-llama2-100k', logprob_sum=-13235.25618392229, count=2642),\n",
       " (631,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=631, model='delphi-llama2-100k', logprob_sum=-24069.16661298275, count=5622),\n",
       " (1587,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1587, model='delphi-llama2-100k', logprob_sum=-2367.4449874628335, count=751),\n",
       " (534,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=534, model='delphi-llama2-100k', logprob_sum=-24105.346024900675, count=7822),\n",
       " (1688,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1688, model='delphi-llama2-100k', logprob_sum=-3963.364117860794, count=613),\n",
       " (1183,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1183, model='delphi-llama2-100k', logprob_sum=-7233.625628173351, count=1372),\n",
       " (787,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=787, model='delphi-llama2-100k', logprob_sum=-5952.425135821104, count=1937),\n",
       " (396,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=396, model='delphi-llama2-100k', logprob_sum=-35366.99018897652, count=19054),\n",
       " (484,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=484, model='delphi-llama2-100k', logprob_sum=-16271.492150751874, count=11518),\n",
       " (519,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=519, model='delphi-llama2-100k', logprob_sum=-24729.434556068853, count=8653),\n",
       " (541,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=541, model='delphi-llama2-100k', logprob_sum=-19890.907532811165, count=7460),\n",
       " (3278,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=3278, model='delphi-llama2-100k', logprob_sum=-487.86977409757674, count=156),\n",
       " (1143,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1143, model='delphi-llama2-100k', logprob_sum=-4715.67968198657, count=1477),\n",
       " (663,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=663, model='delphi-llama2-100k', logprob_sum=-14994.074913322926, count=5148),\n",
       " (510,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=510, model='delphi-llama2-100k', logprob_sum=-3161.0435978770256, count=419),\n",
       " (1311,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1311, model='delphi-llama2-100k', logprob_sum=-427.92528631165624, count=221),\n",
       " (4048,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=4048, model='delphi-llama2-100k', logprob_sum=-14952.537914472166, count=12642),\n",
       " (1100,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1100, model='delphi-llama2-100k', logprob_sum=-3580.9301199764013, count=1606),\n",
       " (655,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=655, model='delphi-llama2-100k', logprob_sum=-5935.762620597146, count=5075),\n",
       " (1051,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1051, model='delphi-llama2-100k', logprob_sum=-5480.646248102188, count=1880),\n",
       " (1213,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1213, model='delphi-llama2-100k', logprob_sum=-6739.2166657447815, count=1292),\n",
       " (732,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=732, model='delphi-llama2-100k', logprob_sum=-4511.546476805583, count=4116),\n",
       " (632,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=632, model='delphi-llama2-100k', logprob_sum=-15917.077916637063, count=5734),\n",
       " (1844,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1844, model='delphi-llama2-100k', logprob_sum=-10594.505805164576, count=3593),\n",
       " (368,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=368, model='delphi-llama2-100k', logprob_sum=-17267.130629241467, count=5479),\n",
       " (2147,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2147, model='delphi-llama2-100k', logprob_sum=-1764.5460320711136, count=373),\n",
       " (1317,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1317, model='delphi-llama2-100k', logprob_sum=-5016.4426638484, count=1099),\n",
       " (896,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=896, model='delphi-llama2-100k', logprob_sum=-10023.02084928751, count=2336),\n",
       " (822,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=822, model='delphi-llama2-100k', logprob_sum=-4675.457979977131, count=1347),\n",
       " (1942,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1942, model='delphi-llama2-100k', logprob_sum=-5461.305574478582, count=3439),\n",
       " (1620,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1620, model='delphi-llama2-100k', logprob_sum=-2389.7523630857468, count=720),\n",
       " (1839,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1839, model='delphi-llama2-100k', logprob_sum=-1584.5321506261826, count=467),\n",
       " (2685,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2685, model='delphi-llama2-100k', logprob_sum=-1673.1496176719666, count=216),\n",
       " (1309,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1309, model='delphi-llama2-100k', logprob_sum=-4157.7635489702225, count=1157),\n",
       " (984,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=984, model='delphi-llama2-100k', logprob_sum=-6742.042004153132, count=2024),\n",
       " (3630,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=3630, model='delphi-llama2-100k', logprob_sum=-1092.6159119606018, count=138),\n",
       " (518,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=518, model='delphi-llama2-100k', logprob_sum=-823.401353658177, count=389),\n",
       " (1238,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1238, model='delphi-llama2-100k', logprob_sum=-5763.820513784885, count=1322),\n",
       " (796,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=796, model='delphi-llama2-100k', logprob_sum=-6001.0889941602945, count=1573),\n",
       " (1293,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1293, model='delphi-llama2-100k', logprob_sum=-4111.322653267533, count=1136),\n",
       " (547,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=547, model='delphi-llama2-100k', logprob_sum=-12023.898039616644, count=3181),\n",
       " (1254,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1254, model='delphi-llama2-100k', logprob_sum=-6058.743788123131, count=1239),\n",
       " (887,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=887, model='delphi-llama2-100k', logprob_sum=-10094.18115618825, count=2564),\n",
       " (616,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=616, model='delphi-llama2-100k', logprob_sum=-12562.778915748, count=5849),\n",
       " (354,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=354, model='delphi-llama2-100k', logprob_sum=-29525.759100882162, count=28177),\n",
       " (1034,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1034, model='delphi-llama2-100k', logprob_sum=-2531.9519317522645, count=1025),\n",
       " (1931,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1931, model='delphi-llama2-100k', logprob_sum=-255.28350734710693, count=26),\n",
       " (945,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=945, model='delphi-llama2-100k', logprob_sum=-444.00651411764557, count=608),\n",
       " (2012,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2012, model='delphi-llama2-100k', logprob_sum=-1813.0740970373154, count=436),\n",
       " (2052,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2052, model='delphi-llama2-100k', logprob_sum=-2859.970588684082, count=455),\n",
       " (1103,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1103, model='delphi-llama2-100k', logprob_sum=-1844.2638178616762, count=368),\n",
       " (1873,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1873, model='delphi-llama2-100k', logprob_sum=-1297.1381556987762, count=213),\n",
       " (1134,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1134, model='delphi-llama2-100k', logprob_sum=-3007.6766847372055, count=614),\n",
       " (1369,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1369, model='delphi-llama2-100k', logprob_sum=-2563.5093397647142, count=967),\n",
       " (626,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=626, model='delphi-llama2-100k', logprob_sum=-3419.214287519455, count=442),\n",
       " (463,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=463, model='delphi-llama2-100k', logprob_sum=-482.0314843133092, count=326),\n",
       " (4038,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=4038, model='delphi-llama2-100k', logprob_sum=-3315.817830549553, count=928),\n",
       " (3895,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=3895, model='delphi-llama2-100k', logprob_sum=-90.80814646556973, count=116),\n",
       " (3111,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=3111, model='delphi-llama2-100k', logprob_sum=-641.0541359782219, count=178),\n",
       " (4050,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=4050, model='delphi-llama2-100k', logprob_sum=-14160.87977720797, count=5242),\n",
       " (766,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=766, model='delphi-llama2-100k', logprob_sum=-872.4766107918695, count=1010),\n",
       " (1821,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1821, model='delphi-llama2-100k', logprob_sum=-1725.3955295085907, count=516),\n",
       " (2532,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2532, model='delphi-llama2-100k', logprob_sum=-1171.1237672567368, count=276),\n",
       " (2223,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2223, model='delphi-llama2-100k', logprob_sum=-1424.2912335395813, count=335),\n",
       " (1962,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1962, model='delphi-llama2-100k', logprob_sum=-1232.9899306111038, count=447),\n",
       " (1434,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1434, model='delphi-llama2-100k', logprob_sum=-3861.64783680439, count=942),\n",
       " (3560,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=3560, model='delphi-llama2-100k', logprob_sum=-545.1975323781371, count=126),\n",
       " (607,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=607, model='delphi-llama2-100k', logprob_sum=-17189.860363453627, count=6332),\n",
       " (4052,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=4052, model='delphi-llama2-100k', logprob_sum=-17554.705426760018, count=9797),\n",
       " (735,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=735, model='delphi-llama2-100k', logprob_sum=-16390.137991070747, count=4006),\n",
       " (539,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=539, model='delphi-llama2-100k', logprob_sum=-6017.851866334677, count=2515),\n",
       " (939,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=939, model='delphi-llama2-100k', logprob_sum=-7004.374821275473, count=2199),\n",
       " (617,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=617, model='delphi-llama2-100k', logprob_sum=-9569.739454045892, count=5673),\n",
       " (524,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=524, model='delphi-llama2-100k', logprob_sum=-12541.936262448784, count=6437),\n",
       " (779,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=779, model='delphi-llama2-100k', logprob_sum=-6182.726673755329, count=3469),\n",
       " (3690,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=3690, model='delphi-llama2-100k', logprob_sum=-899.398848772049, count=161),\n",
       " (288,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=288, model='delphi-llama2-100k', logprob_sum=-48827.3730467353, count=32859),\n",
       " (1345,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1345, model='delphi-llama2-100k', logprob_sum=-4865.899679005146, count=1044),\n",
       " (453,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=453, model='delphi-llama2-100k', logprob_sum=-36919.424418121576, count=11499),\n",
       " (612,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=612, model='delphi-llama2-100k', logprob_sum=-6108.447943329811, count=1291),\n",
       " (1498,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1498, model='delphi-llama2-100k', logprob_sum=-844.3058241825784, count=831),\n",
       " (489,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=489, model='delphi-llama2-100k', logprob_sum=-28821.712659299374, count=8643),\n",
       " (2068,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2068, model='delphi-llama2-100k', logprob_sum=-980.5749118234962, count=444),\n",
       " (2851,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2851, model='delphi-llama2-100k', logprob_sum=-317.26954859495163, count=214),\n",
       " (394,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=394, model='delphi-llama2-100k', logprob_sum=-44507.49868307263, count=23802),\n",
       " (3621,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=3621, model='delphi-llama2-100k', logprob_sum=-884.0253291130066, count=146),\n",
       " (707,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=707, model='delphi-llama2-100k', logprob_sum=-9659.20057392586, count=4472),\n",
       " (992,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=992, model='delphi-llama2-100k', logprob_sum=-9134.852061033249, count=2025),\n",
       " (421,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=421, model='delphi-llama2-100k', logprob_sum=-1705.9536555870436, count=864),\n",
       " (1998,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1998, model='delphi-llama2-100k', logprob_sum=-2364.146763443947, count=469),\n",
       " (1022,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1022, model='delphi-llama2-100k', logprob_sum=-4073.146684244275, count=1934),\n",
       " (502,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=502, model='delphi-llama2-100k', logprob_sum=-27370.97134178877, count=10377),\n",
       " (745,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=745, model='delphi-llama2-100k', logprob_sum=-15536.951192706823, count=3793),\n",
       " (623,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=623, model='delphi-llama2-100k', logprob_sum=-15250.232338417321, count=5485),\n",
       " (806,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=806, model='delphi-llama2-100k', logprob_sum=-6263.407369082794, count=2381),\n",
       " (1394,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1394, model='delphi-llama2-100k', logprob_sum=-3828.646357625723, count=979),\n",
       " (862,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=862, model='delphi-llama2-100k', logprob_sum=-10256.795525968075, count=2304),\n",
       " (1164,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1164, model='delphi-llama2-100k', logprob_sum=-6729.717947578058, count=1297),\n",
       " (2433,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2433, model='delphi-llama2-100k', logprob_sum=-1714.9400166273117, count=299),\n",
       " (754,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=754, model='delphi-llama2-100k', logprob_sum=-15867.48402416706, count=3758),\n",
       " (1530,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1530, model='delphi-llama2-100k', logprob_sum=-3271.588918477297, count=831),\n",
       " (610,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=610, model='delphi-llama2-100k', logprob_sum=-15851.747674327344, count=6450),\n",
       " (1035,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1035, model='delphi-llama2-100k', logprob_sum=-4981.371967077255, count=1561),\n",
       " (635,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=635, model='delphi-llama2-100k', logprob_sum=-12356.658711474389, count=5854),\n",
       " (1461,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1461, model='delphi-llama2-100k', logprob_sum=-5156.523537993431, count=953),\n",
       " (1395,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1395, model='delphi-llama2-100k', logprob_sum=-3631.5145628051832, count=949),\n",
       " (917,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=917, model='delphi-llama2-100k', logprob_sum=-9114.720046281815, count=2159),\n",
       " (1211,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1211, model='delphi-llama2-100k', logprob_sum=-3970.786314368248, count=771),\n",
       " (1315,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1315, model='delphi-llama2-100k', logprob_sum=-4402.855592310429, count=1067),\n",
       " (1061,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1061, model='delphi-llama2-100k', logprob_sum=-6258.6609479263425, count=1770),\n",
       " (2645,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2645, model='delphi-llama2-100k', logprob_sum=-1087.7964992523193, count=238),\n",
       " (810,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=810, model='delphi-llama2-100k', logprob_sum=-5328.763680398464, count=1348),\n",
       " (869,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=869, model='delphi-llama2-100k', logprob_sum=-5713.7020098008215, count=2497),\n",
       " (770,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=770, model='delphi-llama2-100k', logprob_sum=-3647.0717237368226, count=1157),\n",
       " (1086,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1086, model='delphi-llama2-100k', logprob_sum=-7401.195590145886, count=1628),\n",
       " (1376,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1376, model='delphi-llama2-100k', logprob_sum=-4795.263516962528, count=1036),\n",
       " (3442,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=3442, model='delphi-llama2-100k', logprob_sum=-535.8396240845323, count=140),\n",
       " (460,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=460, model='delphi-llama2-100k', logprob_sum=-22921.26872279588, count=12527),\n",
       " (1360,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1360, model='delphi-llama2-100k', logprob_sum=-5706.897490203381, count=998),\n",
       " (531,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=531, model='delphi-llama2-100k', logprob_sum=-23448.9556710124, count=9001),\n",
       " (1407,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1407, model='delphi-llama2-100k', logprob_sum=-2922.458784211427, count=933),\n",
       " (2556,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2556, model='delphi-llama2-100k', logprob_sum=-1635.0799416303635, count=272),\n",
       " (445,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=445, model='delphi-llama2-100k', logprob_sum=-23996.07101525739, count=9201),\n",
       " (930,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=930, model='delphi-llama2-100k', logprob_sum=-4476.21759647876, count=2103),\n",
       " (798,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=798, model='delphi-llama2-100k', logprob_sum=-6517.520116224885, count=3070),\n",
       " (861,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=861, model='delphi-llama2-100k', logprob_sum=-8621.365989655256, count=2746),\n",
       " (769,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=769, model='delphi-llama2-100k', logprob_sum=-6507.626415014267, count=2025),\n",
       " (1037,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1037, model='delphi-llama2-100k', logprob_sum=-4859.122698664665, count=1845),\n",
       " (1135,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1135, model='delphi-llama2-100k', logprob_sum=-6147.0553433299065, count=1493),\n",
       " (780,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=780, model='delphi-llama2-100k', logprob_sum=-9858.66612466774, count=3557),\n",
       " (549,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=549, model='delphi-llama2-100k', logprob_sum=-28828.646812677383, count=8304),\n",
       " (1229,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1229, model='delphi-llama2-100k', logprob_sum=-2304.5674493312836, count=308),\n",
       " (545,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=545, model='delphi-llama2-100k', logprob_sum=-685.7799012791365, count=413),\n",
       " (1016,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1016, model='delphi-llama2-100k', logprob_sum=-756.7845815464389, count=374),\n",
       " (716,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=716, model='delphi-llama2-100k', logprob_sum=-15254.684145152569, count=4468),\n",
       " (1627,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1627, model='delphi-llama2-100k', logprob_sum=-3883.940268278122, count=698),\n",
       " (667,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=667, model='delphi-llama2-100k', logprob_sum=-13735.99890290387, count=5093),\n",
       " (733,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=733, model='delphi-llama2-100k', logprob_sum=-11328.818991452456, count=3834),\n",
       " (4029,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=4029, model='delphi-llama2-100k', logprob_sum=-5972.4664483872475, count=3069),\n",
       " (2287,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2287, model='delphi-llama2-100k', logprob_sum=-2026.1863768100739, count=339),\n",
       " (469,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=469, model='delphi-llama2-100k', logprob_sum=-34507.86435186118, count=12501),\n",
       " (1770,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1770, model='delphi-llama2-100k', logprob_sum=-2273.791415050626, count=503),\n",
       " (1702,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1702, model='delphi-llama2-100k', logprob_sum=-1657.3265574909747, count=599),\n",
       " (648,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=648, model='delphi-llama2-100k', logprob_sum=-5181.640225721989, count=2452),\n",
       " (682,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=682, model='delphi-llama2-100k', logprob_sum=-15489.56349053979, count=4585),\n",
       " (702,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=702, model='delphi-llama2-100k', logprob_sum=-15163.028053879738, count=4501),\n",
       " (805,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=805, model='delphi-llama2-100k', logprob_sum=-17279.822612047195, count=3122),\n",
       " (1009,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1009, model='delphi-llama2-100k', logprob_sum=-7145.215389847755, count=1909),\n",
       " (2062,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2062, model='delphi-llama2-100k', logprob_sum=-2695.234347343445, count=423),\n",
       " (2451,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2451, model='delphi-llama2-100k', logprob_sum=-1872.8334004282951, count=323),\n",
       " (811,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=811, model='delphi-llama2-100k', logprob_sum=-12354.513798713684, count=2797),\n",
       " (1328,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1328, model='delphi-llama2-100k', logprob_sum=-5433.284677095711, count=1196),\n",
       " (587,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=587, model='delphi-llama2-100k', logprob_sum=-11736.83872269094, count=3537),\n",
       " (1146,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1146, model='delphi-llama2-100k', logprob_sum=-4672.462004840374, count=1492),\n",
       " (1299,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1299, model='delphi-llama2-100k', logprob_sum=-2866.6501820608974, count=1190),\n",
       " (1891,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1891, model='delphi-llama2-100k', logprob_sum=-21665.442757641897, count=17222),\n",
       " (374,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=374, model='delphi-llama2-100k', logprob_sum=-13155.819621518254, count=7786),\n",
       " (737,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=737, model='delphi-llama2-100k', logprob_sum=-5579.78949829936, count=2688),\n",
       " (1439,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1439, model='delphi-llama2-100k', logprob_sum=-5272.252313375473, count=900),\n",
       " (989,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=989, model='delphi-llama2-100k', logprob_sum=-10309.415244698524, count=2082),\n",
       " (2413,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2413, model='delphi-llama2-100k', logprob_sum=-1751.8104481697083, count=303),\n",
       " (840,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=840, model='delphi-llama2-100k', logprob_sum=-4452.122948268428, count=2928),\n",
       " (4035,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=4035, model='delphi-llama2-100k', logprob_sum=-8457.704491624143, count=6560),\n",
       " (638,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=638, model='delphi-llama2-100k', logprob_sum=-1962.639416217804, count=254),\n",
       " (2114,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2114, model='delphi-llama2-100k', logprob_sum=-379.4362865462899, count=205),\n",
       " (1748,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1748, model='delphi-llama2-100k', logprob_sum=-2468.094850599766, count=587),\n",
       " (1105,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1105, model='delphi-llama2-100k', logprob_sum=-6293.837068773806, count=1664),\n",
       " (687,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=687, model='delphi-llama2-100k', logprob_sum=-13847.448910817504, count=4675),\n",
       " (949,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=949, model='delphi-llama2-100k', logprob_sum=-5675.929556131363, count=2098),\n",
       " (962,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=962, model='delphi-llama2-100k', logprob_sum=-4813.889331743121, count=2147),\n",
       " (3988,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=3988, model='delphi-llama2-100k', logprob_sum=-512.3788496479392, count=132),\n",
       " (420,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=420, model='delphi-llama2-100k', logprob_sum=-26609.287347828504, count=17331),\n",
       " (1810,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1810, model='delphi-llama2-100k', logprob_sum=-1417.770658493042, count=166),\n",
       " (677,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=677, model='delphi-llama2-100k', logprob_sum=-442.08007353311405, count=407),\n",
       " (940,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=940, model='delphi-llama2-100k', logprob_sum=-8136.53135356307, count=2224),\n",
       " (728,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=728, model='delphi-llama2-100k', logprob_sum=-16829.946371495724, count=4095),\n",
       " (585,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=585, model='delphi-llama2-100k', logprob_sum=-17255.523845572025, count=7026),\n",
       " (2038,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2038, model='delphi-llama2-100k', logprob_sum=-1509.291984796524, count=253),\n",
       " (1237,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1237, model='delphi-llama2-100k', logprob_sum=-5206.716533780098, count=1231),\n",
       " (656,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=656, model='delphi-llama2-100k', logprob_sum=-9293.816119091585, count=4873),\n",
       " (580,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=580, model='delphi-llama2-100k', logprob_sum=-15807.987591691315, count=7032),\n",
       " (379,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=379, model='delphi-llama2-100k', logprob_sum=-17574.711834556423, count=6259),\n",
       " (582,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=582, model='delphi-llama2-100k', logprob_sum=-24627.557903543115, count=6879),\n",
       " (838,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=838, model='delphi-llama2-100k', logprob_sum=-9970.699522018433, count=2914),\n",
       " (723,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=723, model='delphi-llama2-100k', logprob_sum=-19556.205936677754, count=4102),\n",
       " (1645,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1645, model='delphi-llama2-100k', logprob_sum=-1965.1819100882858, count=627),\n",
       " (552,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=552, model='delphi-llama2-100k', logprob_sum=-14922.23673180095, count=6581),\n",
       " (1248,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1248, model='delphi-llama2-100k', logprob_sum=-5084.73407548666, count=1254),\n",
       " (782,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=782, model='delphi-llama2-100k', logprob_sum=-138.5426989942789, count=130),\n",
       " (885,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=885, model='delphi-llama2-100k', logprob_sum=-475.2356791496277, count=61),\n",
       " (318,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=318, model='delphi-llama2-100k', logprob_sum=-951.2232907284051, count=535),\n",
       " (988,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=988, model='delphi-llama2-100k', logprob_sum=-1088.2590236258693, count=696),\n",
       " (1437,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1437, model='delphi-llama2-100k', logprob_sum=-4610.657659769058, count=896),\n",
       " (908,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=908, model='delphi-llama2-100k', logprob_sum=-5151.663560390472, count=1424),\n",
       " (1779,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1779, model='delphi-llama2-100k', logprob_sum=-737.3966829925776, count=525),\n",
       " (894,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=894, model='delphi-llama2-100k', logprob_sum=-8937.323208600283, count=2561),\n",
       " (3936,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=3936, model='delphi-llama2-100k', logprob_sum=-654.7092788219452, count=129),\n",
       " (3970,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=3970, model='delphi-llama2-100k', logprob_sum=-548.2271795272827, count=112),\n",
       " (3188,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=3188, model='delphi-llama2-100k', logprob_sum=-963.0919435024261, count=166),\n",
       " (1448,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1448, model='delphi-llama2-100k', logprob_sum=-3778.013473302126, count=959),\n",
       " (1652,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1652, model='delphi-llama2-100k', logprob_sum=-2315.124507457018, count=678),\n",
       " (1397,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1397, model='delphi-llama2-100k', logprob_sum=-5327.270740389824, count=1004),\n",
       " (2317,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2317, model='delphi-llama2-100k', logprob_sum=-2157.9811491966248, count=341),\n",
       " (581,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=581, model='delphi-llama2-100k', logprob_sum=-25668.245160251856, count=7121),\n",
       " (1221,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1221, model='delphi-llama2-100k', logprob_sum=-3174.6481983065605, count=1270),\n",
       " (1382,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1382, model='delphi-llama2-100k', logprob_sum=-5204.802939176559, count=855),\n",
       " (1302,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1302, model='delphi-llama2-100k', logprob_sum=-3796.945957660675, count=1010),\n",
       " (701,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=701, model='delphi-llama2-100k', logprob_sum=-14081.98167160526, count=3556),\n",
       " (450,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=450, model='delphi-llama2-100k', logprob_sum=-29137.373496366665, count=12349),\n",
       " (814,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=814, model='delphi-llama2-100k', logprob_sum=-6327.863778845407, count=3096),\n",
       " (1480,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1480, model='delphi-llama2-100k', logprob_sum=-2316.499329544604, count=610),\n",
       " (262,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=262, model='delphi-llama2-100k', logprob_sum=-9306.660396814346, count=1310),\n",
       " (568,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=568, model='delphi-llama2-100k', logprob_sum=-1158.646315611899, count=475),\n",
       " (1272,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1272, model='delphi-llama2-100k', logprob_sum=-1926.0024495143443, count=823),\n",
       " (731,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=731, model='delphi-llama2-100k', logprob_sum=-9015.632934570312, count=2509),\n",
       " (2647,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2647, model='delphi-llama2-100k', logprob_sum=-1403.0066959261894, count=244),\n",
       " (1314,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1314, model='delphi-llama2-100k', logprob_sum=-2658.159124620259, count=852),\n",
       " (1693,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1693, model='delphi-llama2-100k', logprob_sum=-2702.3159519732, count=718),\n",
       " (2230,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2230, model='delphi-llama2-100k', logprob_sum=-945.8058798089623, count=302),\n",
       " (1029,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1029, model='delphi-llama2-100k', logprob_sum=-10418.902546405792, count=1942),\n",
       " (3818,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=3818, model='delphi-llama2-100k', logprob_sum=-606.8049639388919, count=168),\n",
       " (2443,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2443, model='delphi-llama2-100k', logprob_sum=-1557.0764220952988, count=320),\n",
       " (1017,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1017, model='delphi-llama2-100k', logprob_sum=-6207.385980963707, count=1863),\n",
       " (1755,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1755, model='delphi-llama2-100k', logprob_sum=-3358.4420578479767, count=584),\n",
       " (825,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=825, model='delphi-llama2-100k', logprob_sum=-4725.254562386312, count=2367),\n",
       " (357,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=357, model='delphi-llama2-100k', logprob_sum=-6212.070720076561, count=1346),\n",
       " (427,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=427, model='delphi-llama2-100k', logprob_sum=-723.6197103820741, count=246),\n",
       " (3530,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=3530, model='delphi-llama2-100k', logprob_sum=-918.0692881345749, count=163),\n",
       " (586,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=586, model='delphi-llama2-100k', logprob_sum=-16950.932032316923, count=7007),\n",
       " (657,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=657, model='delphi-llama2-100k', logprob_sum=-20554.265035778284, count=5225),\n",
       " (1404,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1404, model='delphi-llama2-100k', logprob_sum=-4291.406599551439, count=971),\n",
       " (1018,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1018, model='delphi-llama2-100k', logprob_sum=-9902.88418239355, count=1980),\n",
       " (1202,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1202, model='delphi-llama2-100k', logprob_sum=-6601.859297126532, count=1437),\n",
       " (1710,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1710, model='delphi-llama2-100k', logprob_sum=-3034.2404901981354, count=497),\n",
       " (821,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=821, model='delphi-llama2-100k', logprob_sum=-7697.558165252209, count=2409),\n",
       " (594,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=594, model='delphi-llama2-100k', logprob_sum=-23807.836288541555, count=6585),\n",
       " (1261,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1261, model='delphi-llama2-100k', logprob_sum=-4648.193906053901, count=1232),\n",
       " (725,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=725, model='delphi-llama2-100k', logprob_sum=-10444.777920868248, count=3276),\n",
       " (1020,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1020, model='delphi-llama2-100k', logprob_sum=-4863.184776607901, count=1785),\n",
       " (730,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=730, model='delphi-llama2-100k', logprob_sum=-8863.048733770847, count=2554),\n",
       " (815,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=815, model='delphi-llama2-100k', logprob_sum=-9185.86094892025, count=2116),\n",
       " (1110,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1110, model='delphi-llama2-100k', logprob_sum=-6489.435090601444, count=1618),\n",
       " (842,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=842, model='delphi-llama2-100k', logprob_sum=-10646.777576819062, count=2876),\n",
       " (2658,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2658, model='delphi-llama2-100k', logprob_sum=-1722.4669892787933, count=256),\n",
       " (1462,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1462, model='delphi-llama2-100k', logprob_sum=-2127.460376739502, count=482),\n",
       " (1241,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1241, model='delphi-llama2-100k', logprob_sum=-6923.432750344276, count=1284),\n",
       " (462,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=462, model='delphi-llama2-100k', logprob_sum=-3645.6570844021626, count=1968),\n",
       " (1405,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1405, model='delphi-llama2-100k', logprob_sum=-3113.2579159736633, count=611),\n",
       " (1817,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1817, model='delphi-llama2-100k', logprob_sum=-3018.8957875967026, count=519),\n",
       " (1980,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1980, model='delphi-llama2-100k', logprob_sum=-1589.7109569311142, count=422),\n",
       " (1487,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1487, model='delphi-llama2-100k', logprob_sum=-2094.828843390569, count=860),\n",
       " (1094,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1094, model='delphi-llama2-100k', logprob_sum=-6738.794082283974, count=1562),\n",
       " (1517,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1517, model='delphi-llama2-100k', logprob_sum=-3601.2503717392683, count=855),\n",
       " (498,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=498, model='delphi-llama2-100k', logprob_sum=-20241.75321654603, count=11103),\n",
       " (1107,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1107, model='delphi-llama2-100k', logprob_sum=-6126.805188894272, count=1519),\n",
       " (3672,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=3672, model='delphi-llama2-100k', logprob_sum=-1251.4735803604126, count=167),\n",
       " (2191,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2191, model='delphi-llama2-100k', logprob_sum=-1428.5225713402033, count=366),\n",
       " (3898,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=3898, model='delphi-llama2-100k', logprob_sum=-597.3070337772369, count=89),\n",
       " (1131,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1131, model='delphi-llama2-100k', logprob_sum=-7375.407154560089, count=1452),\n",
       " (1836,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1836, model='delphi-llama2-100k', logprob_sum=-6325.126745950431, count=5292),\n",
       " (1364,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1364, model='delphi-llama2-100k', logprob_sum=-3115.8665163517, count=514),\n",
       " (1001,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1001, model='delphi-llama2-100k', logprob_sum=-6851.677026882768, count=1990),\n",
       " (1090,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1090, model='delphi-llama2-100k', logprob_sum=-6305.783476471901, count=1349),\n",
       " (2516,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2516, model='delphi-llama2-100k', logprob_sum=-706.3054519891739, count=126),\n",
       " (1218,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1218, model='delphi-llama2-100k', logprob_sum=-2888.9382662773132, count=830),\n",
       " (1096,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1096, model='delphi-llama2-100k', logprob_sum=-5793.4227721095085, count=1662),\n",
       " (775,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=775, model='delphi-llama2-100k', logprob_sum=-5059.705024719238, count=1058),\n",
       " (1820,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1820, model='delphi-llama2-100k', logprob_sum=-2512.8491899967194, count=559),\n",
       " (1260,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1260, model='delphi-llama2-100k', logprob_sum=-5797.3313945531845, count=1176),\n",
       " (605,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=605, model='delphi-llama2-100k', logprob_sum=-4158.309886932373, count=575),\n",
       " (516,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=516, model='delphi-llama2-100k', logprob_sum=-405.7205851152539, count=138),\n",
       " (809,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=809, model='delphi-llama2-100k', logprob_sum=-12846.751116514206, count=3052),\n",
       " (764,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=764, model='delphi-llama2-100k', logprob_sum=-11263.924876451492, count=3650),\n",
       " (645,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=645, model='delphi-llama2-100k', logprob_sum=-17790.848513484, count=4870),\n",
       " (2349,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2349, model='delphi-llama2-100k', logprob_sum=-1931.392012000084, count=338),\n",
       " (653,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=653, model='delphi-llama2-100k', logprob_sum=-20762.339582547545, count=5368),\n",
       " (909,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=909, model='delphi-llama2-100k', logprob_sum=-10092.528188765049, count=2507),\n",
       " (846,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=846, model='delphi-llama2-100k', logprob_sum=-11300.915365815163, count=2956),\n",
       " (1047,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1047, model='delphi-llama2-100k', logprob_sum=-1175.2865678071976, count=161),\n",
       " (266,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=266, model='delphi-llama2-100k', logprob_sum=-5593.6918564855005, count=6481),\n",
       " (301,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=301, model='delphi-llama2-100k', logprob_sum=-9176.896871061843, count=7651),\n",
       " (2486,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2486, model='delphi-llama2-100k', logprob_sum=-2028.4637231826782, count=282),\n",
       " (1268,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1268, model='delphi-llama2-100k', logprob_sum=-3669.2381577417254, count=1138),\n",
       " (2091,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2091, model='delphi-llama2-100k', logprob_sum=-1512.3486575484276, count=448),\n",
       " (955,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=955, model='delphi-llama2-100k', logprob_sum=-8390.048870801926, count=1988),\n",
       " (1636,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1636, model='delphi-llama2-100k', logprob_sum=-3166.935896754265, count=653),\n",
       " (1549,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1549, model='delphi-llama2-100k', logprob_sum=-2928.251664698124, count=750),\n",
       " (915,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=915, model='delphi-llama2-100k', logprob_sum=-1060.1276593208313, count=117),\n",
       " (932,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=932, model='delphi-llama2-100k', logprob_sum=-597.0804397240281, count=704),\n",
       " (759,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=759, model='delphi-llama2-100k', logprob_sum=-7308.42890083231, count=2739),\n",
       " (1166,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1166, model='delphi-llama2-100k', logprob_sum=-4633.856747150421, count=711),\n",
       " (2211,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2211, model='delphi-llama2-100k', logprob_sum=-2030.6029212474823, count=346),\n",
       " (976,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=976, model='delphi-llama2-100k', logprob_sum=-9183.460240125656, count=2071),\n",
       " (1463,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1463, model='delphi-llama2-100k', logprob_sum=-4652.948447525501, count=978),\n",
       " (1474,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1474, model='delphi-llama2-100k', logprob_sum=-1795.355498845689, count=988),\n",
       " (2272,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2272, model='delphi-llama2-100k', logprob_sum=-896.7507284246385, count=348),\n",
       " (673,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=673, model='delphi-llama2-100k', logprob_sum=-19810.950978577137, count=5008),\n",
       " (1005,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1005, model='delphi-llama2-100k', logprob_sum=-4520.86322221905, count=1199),\n",
       " (538,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=538, model='delphi-llama2-100k', logprob_sum=-31538.67856580019, count=8657),\n",
       " (824,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=824, model='delphi-llama2-100k', logprob_sum=-8354.322253774852, count=2912),\n",
       " (923,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=923, model='delphi-llama2-100k', logprob_sum=-11138.935138344765, count=2303),\n",
       " (1465,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1465, model='delphi-llama2-100k', logprob_sum=-3434.0721442997456, count=875),\n",
       " (1930,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1930, model='delphi-llama2-100k', logprob_sum=-242.83840324170887, count=187),\n",
       " (1982,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1982, model='delphi-llama2-100k', logprob_sum=-2785.8523013591766, count=357),\n",
       " (980,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=980, model='delphi-llama2-100k', logprob_sum=-637.5889285579324, count=285),\n",
       " (807,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=807, model='delphi-llama2-100k', logprob_sum=-9450.391783382744, count=3169),\n",
       " (704,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=704, model='delphi-llama2-100k', logprob_sum=-9167.220285087824, count=2088),\n",
       " (1882,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1882, model='delphi-llama2-100k', logprob_sum=-3123.370534658432, count=524),\n",
       " (1148,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1148, model='delphi-llama2-100k', logprob_sum=-5796.06705494225, count=1369),\n",
       " (689,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=689, model='delphi-llama2-100k', logprob_sum=-9071.99475744646, count=4703),\n",
       " (2522,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2522, model='delphi-llama2-100k', logprob_sum=-1513.5066010951996, count=261),\n",
       " (1247,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1247, model='delphi-llama2-100k', logprob_sum=-4965.64472746104, count=1276),\n",
       " (724,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=724, model='delphi-llama2-100k', logprob_sum=-10148.508767843246, count=2395),\n",
       " (1264,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1264, model='delphi-llama2-100k', logprob_sum=-5677.385695494711, count=1236),\n",
       " (1323,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1323, model='delphi-llama2-100k', logprob_sum=-5343.646439790726, count=1116),\n",
       " (792,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=792, model='delphi-llama2-100k', logprob_sum=-6668.939937423915, count=2827),\n",
       " (533,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=533, model='delphi-llama2-100k', logprob_sum=-22042.219335502014, count=8899),\n",
       " (636,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=636, model='delphi-llama2-100k', logprob_sum=-11344.706662595272, count=3857),\n",
       " (1337,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1337, model='delphi-llama2-100k', logprob_sum=-3796.315528988838, count=676),\n",
       " (565,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=565, model='delphi-llama2-100k', logprob_sum=-8044.124095737934, count=2198),\n",
       " (4024,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=4024, model='delphi-llama2-100k', logprob_sum=-5341.98062903923, count=3651),\n",
       " (692,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=692, model='delphi-llama2-100k', logprob_sum=-11764.073604404926, count=4166),\n",
       " (715,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=715, model='delphi-llama2-100k', logprob_sum=-6010.163973428309, count=1691),\n",
       " (272,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=272, model='delphi-llama2-100k', logprob_sum=-5787.141291379929, count=749),\n",
       " (797,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=797, model='delphi-llama2-100k', logprob_sum=-186.74510461091995, count=83),\n",
       " (276,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=276, model='delphi-llama2-100k', logprob_sum=-1539.2007136517204, count=747),\n",
       " (613,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=613, model='delphi-llama2-100k', logprob_sum=-397.24781187670305, count=181),\n",
       " (1403,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1403, model='delphi-llama2-100k', logprob_sum=-3765.747411504388, count=955),\n",
       " (2048,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2048, model='delphi-llama2-100k', logprob_sum=-2194.7518582344055, count=396),\n",
       " (706,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=706, model='delphi-llama2-100k', logprob_sum=-16767.537737242877, count=4552),\n",
       " (2692,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2692, model='delphi-llama2-100k', logprob_sum=-1966.6154422033578, count=1149),\n",
       " (1349,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1349, model='delphi-llama2-100k', logprob_sum=-4520.627306193113, count=892),\n",
       " (1393,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1393, model='delphi-llama2-100k', logprob_sum=-4260.95392164588, count=930),\n",
       " (1216,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1216, model='delphi-llama2-100k', logprob_sum=-2986.4596461057663, count=483),\n",
       " (1232,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1232, model='delphi-llama2-100k', logprob_sum=-4111.031245157123, count=1334),\n",
       " (1643,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1643, model='delphi-llama2-100k', logprob_sum=-3396.5283029079437, count=644),\n",
       " (853,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=853, model='delphi-llama2-100k', logprob_sum=-11145.76432056725, count=2776),\n",
       " (1599,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1599, model='delphi-llama2-100k', logprob_sum=-3698.2714478373528, count=689),\n",
       " (2197,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2197, model='delphi-llama2-100k', logprob_sum=-2167.5407140254974, count=300),\n",
       " (2358,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2358, model='delphi-llama2-100k', logprob_sum=-2032.1952424049377, count=323),\n",
       " (633,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=633, model='delphi-llama2-100k', logprob_sum=-11808.721346110106, count=3849),\n",
       " (1209,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1209, model='delphi-llama2-100k', logprob_sum=-6627.147490024567, count=1334),\n",
       " (2565,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2565, model='delphi-llama2-100k', logprob_sum=-1933.0761647224426, count=286),\n",
       " (1226,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1226, model='delphi-llama2-100k', logprob_sum=-4032.630728872493, count=1356),\n",
       " (2030,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2030, model='delphi-llama2-100k', logprob_sum=-2132.2532999515533, count=433),\n",
       " (1182,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1182, model='delphi-llama2-100k', logprob_sum=-6750.682844281197, count=1361),\n",
       " (1038,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1038, model='delphi-llama2-100k', logprob_sum=-8484.603376567364, count=1799),\n",
       " (683,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=683, model='delphi-llama2-100k', logprob_sum=-4420.851754710078, count=1449),\n",
       " (1093,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1093, model='delphi-llama2-100k', logprob_sum=-8543.067841768265, count=1623),\n",
       " (4061,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=4061, model='delphi-llama2-100k', logprob_sum=-8506.436921715736, count=2478),\n",
       " (491,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=491, model='delphi-llama2-100k', logprob_sum=-625.103045420954, count=3491),\n",
       " (1271,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1271, model='delphi-llama2-100k', logprob_sum=-5129.46991950646, count=1305),\n",
       " (476,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=476, model='delphi-llama2-100k', logprob_sum=-19247.56041847123, count=11376),\n",
       " (756,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=756, model='delphi-llama2-100k', logprob_sum=-11516.87780834362, count=3747),\n",
       " (1385,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1385, model='delphi-llama2-100k', logprob_sum=-4990.763309717178, count=1007),\n",
       " (1305,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1305, model='delphi-llama2-100k', logprob_sum=-1859.5130970478058, count=369),\n",
       " (604,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=604, model='delphi-llama2-100k', logprob_sum=-15802.774330470711, count=6559),\n",
       " (2083,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2083, model='delphi-llama2-100k', logprob_sum=-2678.5312284231186, count=438),\n",
       " (739,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=739, model='delphi-llama2-100k', logprob_sum=-14722.652121417224, count=3947),\n",
       " (1733,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1733, model='delphi-llama2-100k', logprob_sum=-2141.874392386526, count=521),\n",
       " (3115,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=3115, model='delphi-llama2-100k', logprob_sum=-823.6505477428436, count=186),\n",
       " (449,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=449, model='delphi-llama2-100k', logprob_sum=-17905.344113422558, count=4259),\n",
       " (3861,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=3861, model='delphi-llama2-100k', logprob_sum=-654.1336656212807, count=128),\n",
       " (2080,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2080, model='delphi-llama2-100k', logprob_sum=-138.66096484917216, count=373),\n",
       " (788,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=788, model='delphi-llama2-100k', logprob_sum=-11968.320081748068, count=3394),\n",
       " (905,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=905, model='delphi-llama2-100k', logprob_sum=-7390.679767767899, count=2538),\n",
       " (1483,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1483, model='delphi-llama2-100k', logprob_sum=-1483.0605947002769, count=901),\n",
       " (1071,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1071, model='delphi-llama2-100k', logprob_sum=-4192.770407736301, count=1600),\n",
       " (746,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=746, model='delphi-llama2-100k', logprob_sum=-9671.053739704192, count=3211),\n",
       " (1141,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1141, model='delphi-llama2-100k', logprob_sum=-5543.055844962597, count=1661),\n",
       " (852,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=852, model='delphi-llama2-100k', logprob_sum=-11642.345999479294, count=2866),\n",
       " (1072,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1072, model='delphi-llama2-100k', logprob_sum=-7991.914467930794, count=1657),\n",
       " (1447,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1447, model='delphi-llama2-100k', logprob_sum=-3456.5601902604103, count=534),\n",
       " (2481,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2481, model='delphi-llama2-100k', logprob_sum=-2022.725128531456, count=302),\n",
       " (902,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=902, model='delphi-llama2-100k', logprob_sum=-10053.48216292262, count=2523),\n",
       " (1490,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1490, model='delphi-llama2-100k', logprob_sum=-2704.937996864319, count=673),\n",
       " (1178,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1178, model='delphi-llama2-100k', logprob_sum=-4300.999971903861, count=1475),\n",
       " (2541,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2541, model='delphi-llama2-100k', logprob_sum=-1034.9234310984612, count=184),\n",
       " (878,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=878, model='delphi-llama2-100k', logprob_sum=-6486.283912036568, count=2915),\n",
       " (848,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=848, model='delphi-llama2-100k', logprob_sum=-7244.188932210207, count=2814),\n",
       " (2620,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2620, model='delphi-llama2-100k', logprob_sum=-1806.76385140419, count=281),\n",
       " (738,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=738, model='delphi-llama2-100k', logprob_sum=-158.8813919723034, count=76),\n",
       " (1990,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1990, model='delphi-llama2-100k', logprob_sum=-1836.9569410979748, count=461),\n",
       " (1010,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1010, model='delphi-llama2-100k', logprob_sum=-8695.252073705196, count=1934),\n",
       " (2458,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2458, model='delphi-llama2-100k', logprob_sum=-203.18482725135982, count=290),\n",
       " (1056,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1056, model='delphi-llama2-100k', logprob_sum=-7838.650790333748, count=1839),\n",
       " (2046,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2046, model='delphi-llama2-100k', logprob_sum=-1589.5197229236364, count=442),\n",
       " (1039,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1039, model='delphi-llama2-100k', logprob_sum=-7261.275014698505, count=1816),\n",
       " (535,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=535, model='delphi-llama2-100k', logprob_sum=-1126.4206538200378, count=122),\n",
       " (719,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=719, model='delphi-llama2-100k', logprob_sum=-2034.046761734644, count=997),\n",
       " (2707,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2707, model='delphi-llama2-100k', logprob_sum=-1797.975706577301, count=239),\n",
       " (2561,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2561, model='delphi-llama2-100k', logprob_sum=-1320.2702153921127, count=230),\n",
       " (383,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=383, model='delphi-llama2-100k', logprob_sum=-2658.2206756547384, count=1788),\n",
       " (2127,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2127, model='delphi-llama2-100k', logprob_sum=-1333.5202910006046, count=391),\n",
       " (554,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=554, model='delphi-llama2-100k', logprob_sum=-2432.9578932523727, count=343),\n",
       " (4031,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=4031, model='delphi-llama2-100k', logprob_sum=-2529.1984371677972, count=1512),\n",
       " (2110,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2110, model='delphi-llama2-100k', logprob_sum=-211.32732200808823, count=130),\n",
       " (910,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=910, model='delphi-llama2-100k', logprob_sum=-7578.088507577777, count=2157),\n",
       " (2063,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2063, model='delphi-llama2-100k', logprob_sum=-962.3318572342396, count=386),\n",
       " (3831,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=3831, model='delphi-llama2-100k', logprob_sum=-708.7487353980541, count=145),\n",
       " (1892,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1892, model='delphi-llama2-100k', logprob_sum=-1815.7969331741333, count=536),\n",
       " (2842,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2842, model='delphi-llama2-100k', logprob_sum=-1384.7729625701904, count=198),\n",
       " (652,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=652, model='delphi-llama2-100k', logprob_sum=-3122.8467658758163, count=517),\n",
       " (472,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=472, model='delphi-llama2-100k', logprob_sum=-329.1158164255321, count=196),\n",
       " (2305,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2305, model='delphi-llama2-100k', logprob_sum=-1456.6981826424599, count=315),\n",
       " (2834,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2834, model='delphi-llama2-100k', logprob_sum=-1622.7801704406738, count=229),\n",
       " (3723,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=3723, model='delphi-llama2-100k', logprob_sum=-887.5058240294456, count=159),\n",
       " (1340,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1340, model='delphi-llama2-100k', logprob_sum=-5547.9508854448795, count=896),\n",
       " (2319,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2319, model='delphi-llama2-100k', logprob_sum=-1515.1887340545654, count=314),\n",
       " (1003,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1003, model='delphi-llama2-100k', logprob_sum=-5621.860565140843, count=1462),\n",
       " (1076,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1076, model='delphi-llama2-100k', logprob_sum=-7961.067251801491, count=1689),\n",
       " (1053,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1053, model='delphi-llama2-100k', logprob_sum=-2831.606333255768, count=552),\n",
       " (3896,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=3896, model='delphi-llama2-100k', logprob_sum=-317.6953511759639, count=104),\n",
       " (2425,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2425, model='delphi-llama2-100k', logprob_sum=-1340.520313501358, count=296),\n",
       " (3886,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=3886, model='delphi-llama2-100k', logprob_sum=-622.9744794368744, count=112),\n",
       " (3625,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=3625, model='delphi-llama2-100k', logprob_sum=-793.9453880190849, count=135),\n",
       " (854,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=854, model='delphi-llama2-100k', logprob_sum=-13787.14383277297, count=2689),\n",
       " (1971,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1971, model='delphi-llama2-100k', logprob_sum=-2613.779897212982, count=433),\n",
       " (934,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=934, model='delphi-llama2-100k', logprob_sum=-10020.419447422028, count=2115),\n",
       " (3467,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=3467, model='delphi-llama2-100k', logprob_sum=-832.205245256424, count=166),\n",
       " (1025,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1025, model='delphi-llama2-100k', logprob_sum=-6748.387411594391, count=1867),\n",
       " (4067,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=4067, model='delphi-llama2-100k', logprob_sum=-5691.560409426689, count=1699),\n",
       " (817,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=817, model='delphi-llama2-100k', logprob_sum=-718.4851450808346, count=311),\n",
       " (919,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=919, model='delphi-llama2-100k', logprob_sum=-7779.461500175297, count=2295),\n",
       " (4036,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=4036, model='delphi-llama2-100k', logprob_sum=-3042.7639462219086, count=3483),\n",
       " (3393,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=3393, model='delphi-llama2-100k', logprob_sum=-63.12376618385315, count=33),\n",
       " (260,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=260, model='delphi-llama2-100k', logprob_sum=-2237.152949373238, count=1635),\n",
       " (2577,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2577, model='delphi-llama2-100k', logprob_sum=-1190.8162422776222, count=292),\n",
       " (2414,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2414, model='delphi-llama2-100k', logprob_sum=-2101.602922439575, count=317),\n",
       " (925,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=925, model='delphi-llama2-100k', logprob_sum=-8929.880057513714, count=2307),\n",
       " (1231,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1231, model='delphi-llama2-100k', logprob_sum=-3485.825465172529, count=1318),\n",
       " (1262,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1262, model='delphi-llama2-100k', logprob_sum=-2008.7460739836097, count=1226),\n",
       " (2227,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2227, model='delphi-llama2-100k', logprob_sum=-1502.4472715854645, count=315),\n",
       " (1255,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1255, model='delphi-llama2-100k', logprob_sum=-5828.74217915535, count=1123),\n",
       " (2534,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2534, model='delphi-llama2-100k', logprob_sum=-1157.5705277323723, count=234),\n",
       " (527,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=527, model='delphi-llama2-100k', logprob_sum=-14920.721382945776, count=5725),\n",
       " (2122,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2122, model='delphi-llama2-100k', logprob_sum=-2049.694171965122, count=369),\n",
       " (1445,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1445, model='delphi-llama2-100k', logprob_sum=-6109.52938914299, count=893),\n",
       " (1539,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1539, model='delphi-llama2-100k', logprob_sum=-3975.8637095838785, count=814),\n",
       " (2903,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2903, model='delphi-llama2-100k', logprob_sum=-1250.7933735847473, count=225),\n",
       " (1796,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1796, model='delphi-llama2-100k', logprob_sum=-2930.637407064438, count=551),\n",
       " (1401,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1401, model='delphi-llama2-100k', logprob_sum=-3918.5795146524906, count=961),\n",
       " (1350,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1350, model='delphi-llama2-100k', logprob_sum=-3943.679187953472, count=1083),\n",
       " (4051,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=4051, model='delphi-llama2-100k', logprob_sum=-8569.308701179922, count=3038),\n",
       " (2031,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2031, model='delphi-llama2-100k', logprob_sum=-1221.6091777086258, count=435),\n",
       " (1418,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1418, model='delphi-llama2-100k', logprob_sum=-4086.8566849827766, count=790),\n",
       " (1534,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1534, model='delphi-llama2-100k', logprob_sum=-3682.366121530533, count=790),\n",
       " (1322,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1322, model='delphi-llama2-100k', logprob_sum=-5901.978536486626, count=1123),\n",
       " (2969,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2969, model='delphi-llama2-100k', logprob_sum=-1072.410718291998, count=189),\n",
       " (3036,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=3036, model='delphi-llama2-100k', logprob_sum=-612.3802275508642, count=157),\n",
       " (776,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=776, model='delphi-llama2-100k', logprob_sum=-8739.850937515497, count=1747),\n",
       " (1297,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1297, model='delphi-llama2-100k', logprob_sum=-4158.724821165204, count=1129),\n",
       " (4063,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=4063, model='delphi-llama2-100k', logprob_sum=-5085.183257818222, count=1520),\n",
       " (2551,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2551, model='delphi-llama2-100k', logprob_sum=-1118.4261207580566, count=238),\n",
       " (1139,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1139, model='delphi-llama2-100k', logprob_sum=-4098.408808872104, count=1209),\n",
       " (969,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=969, model='delphi-llama2-100k', logprob_sum=-9569.083818852901, count=2216),\n",
       " (1251,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1251, model='delphi-llama2-100k', logprob_sum=-4961.535601139069, count=955),\n",
       " (2650,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2650, model='delphi-llama2-100k', logprob_sum=-615.1631603240967, count=82),\n",
       " (344,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=344, model='delphi-llama2-100k', logprob_sum=-468.8390092179179, count=140),\n",
       " (3918,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=3918, model='delphi-llama2-100k', logprob_sum=-1092.8294200897217, count=149),\n",
       " (1419,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1419, model='delphi-llama2-100k', logprob_sum=-4761.063318014145, count=968),\n",
       " (2546,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2546, model='delphi-llama2-100k', logprob_sum=-1711.6575446128845, count=264),\n",
       " (2229,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2229, model='delphi-llama2-100k', logprob_sum=-1664.6700387001038, count=341),\n",
       " (2774,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2774, model='delphi-llama2-100k', logprob_sum=-1611.8533606529236, count=235),\n",
       " (3479,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=3479, model='delphi-llama2-100k', logprob_sum=-54.84346267580986, count=25),\n",
       " (2148,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2148, model='delphi-llama2-100k', logprob_sum=-1885.3939434289932, count=364),\n",
       " (2131,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2131, model='delphi-llama2-100k', logprob_sum=-2289.123886346817, count=381),\n",
       " (2482,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2482, model='delphi-llama2-100k', logprob_sum=-1275.31146723032, count=283),\n",
       " (1565,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1565, model='delphi-llama2-100k', logprob_sum=-3972.658970117569, count=717),\n",
       " (868,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=868, model='delphi-llama2-100k', logprob_sum=-6762.41019654274, count=2036),\n",
       " (1117,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1117, model='delphi-llama2-100k', logprob_sum=-4023.4197190999985, count=1480),\n",
       " (2378,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2378, model='delphi-llama2-100k', logprob_sum=-1613.5758415460587, count=333),\n",
       " (289,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=289, model='delphi-llama2-100k', logprob_sum=-1645.4619087772444, count=1195),\n",
       " (2132,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2132, model='delphi-llama2-100k', logprob_sum=-1018.8165489435196, count=391),\n",
       " (1949,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1949, model='delphi-llama2-100k', logprob_sum=-215.50829401046212, count=476),\n",
       " (2402,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2402, model='delphi-llama2-100k', logprob_sum=-1340.3531565666199, count=313),\n",
       " (2579,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2579, model='delphi-llama2-100k', logprob_sum=-1084.5682094097137, count=253),\n",
       " (520,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=520, model='delphi-llama2-100k', logprob_sum=-749.8141468446702, count=299),\n",
       " (1665,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1665, model='delphi-llama2-100k', logprob_sum=-2870.319121271372, count=687),\n",
       " (1661,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1661, model='delphi-llama2-100k', logprob_sum=-1773.2476501464844, count=226),\n",
       " (1762,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1762, model='delphi-llama2-100k', logprob_sum=-251.4471630535554, count=257),\n",
       " (1812,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1812, model='delphi-llama2-100k', logprob_sum=-55.87101041153073, count=67),\n",
       " (2280,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2280, model='delphi-llama2-100k', logprob_sum=-1941.882511138916, count=348),\n",
       " (1177,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1177, model='delphi-llama2-100k', logprob_sum=-4719.400824606419, count=1430),\n",
       " (2009,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2009, model='delphi-llama2-100k', logprob_sum=-1985.4529242515564, count=460),\n",
       " (1888,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1888, model='delphi-llama2-100k', logprob_sum=-2585.855229973793, count=516),\n",
       " (1195,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1195, model='delphi-llama2-100k', logprob_sum=-4001.1089654788375, count=1304),\n",
       " (550,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=550, model='delphi-llama2-100k', logprob_sum=-352.58738604094833, count=262),\n",
       " (1567,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1567, model='delphi-llama2-100k', logprob_sum=-3160.3667735755444, count=718),\n",
       " (3015,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=3015, model='delphi-llama2-100k', logprob_sum=-1252.8975239992142, count=230),\n",
       " (639,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=639, model='delphi-llama2-100k', logprob_sum=-11373.802259892225, count=2959),\n",
       " (1353,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1353, model='delphi-llama2-100k', logprob_sum=-3254.749791767448, count=1118),\n",
       " (986,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=986, model='delphi-llama2-100k', logprob_sum=-2857.7152042984962, count=437),\n",
       " (1837,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1837, model='delphi-llama2-100k', logprob_sum=-561.3821570724249, count=320),\n",
       " (312,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=312, model='delphi-llama2-100k', logprob_sum=-1710.9673932418227, count=691),\n",
       " (3747,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=3747, model='delphi-llama2-100k', logprob_sum=-439.3148742429912, count=182),\n",
       " (2120,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2120, model='delphi-llama2-100k', logprob_sum=-1874.3518734890968, count=371),\n",
       " (3536,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=3536, model='delphi-llama2-100k', logprob_sum=-1185.283503651619, count=182),\n",
       " (944,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=944, model='delphi-llama2-100k', logprob_sum=-5495.980260483921, count=1653),\n",
       " (275,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=275, model='delphi-llama2-100k', logprob_sum=-2953.0693417685106, count=1969),\n",
       " (1784,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1784, model='delphi-llama2-100k', logprob_sum=-1146.7985130436718, count=564),\n",
       " (1304,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1304, model='delphi-llama2-100k', logprob_sum=-2584.590323805809, count=516),\n",
       " (3924,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=3924, model='delphi-llama2-100k', logprob_sum=-818.9477114006877, count=141),\n",
       " (2463,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2463, model='delphi-llama2-100k', logprob_sum=-1107.7914681434631, count=154),\n",
       " (523,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=523, model='delphi-llama2-100k', logprob_sum=-17272.41136990674, count=8381),\n",
       " (3100,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=3100, model='delphi-llama2-100k', logprob_sum=-2109.9810562431812, count=1012),\n",
       " (1055,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1055, model='delphi-llama2-100k', logprob_sum=-8205.555271208286, count=1688),\n",
       " (1603,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1603, model='delphi-llama2-100k', logprob_sum=-2618.235779516399, count=729),\n",
       " (1745,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1745, model='delphi-llama2-100k', logprob_sum=-2650.4246648214757, count=572),\n",
       " (1396,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1396, model='delphi-llama2-100k', logprob_sum=-1004.8351697195321, count=970),\n",
       " (1951,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1951, model='delphi-llama2-100k', logprob_sum=-1534.6263655722141, count=430),\n",
       " (3003,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=3003, model='delphi-llama2-100k', logprob_sum=-862.1240981221199, count=175),\n",
       " (1352,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1352, model='delphi-llama2-100k', logprob_sum=-6243.733981847763, count=1027),\n",
       " (1785,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1785, model='delphi-llama2-100k', logprob_sum=-2579.4890991300344, count=552),\n",
       " (1236,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1236, model='delphi-llama2-100k', logprob_sum=-4755.726889371872, count=896),\n",
       " (2356,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2356, model='delphi-llama2-100k', logprob_sum=-1837.9476552009583, count=306),\n",
       " (1078,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1078, model='delphi-llama2-100k', logprob_sum=-5068.498323623091, count=1826),\n",
       " (3014,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=3014, model='delphi-llama2-100k', logprob_sum=-1046.254275918007, count=213),\n",
       " (717,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=717, model='delphi-llama2-100k', logprob_sum=-2828.646458506584, count=402),\n",
       " (637,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=637, model='delphi-llama2-100k', logprob_sum=-1252.027179221157, count=694),\n",
       " (3383,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=3383, model='delphi-llama2-100k', logprob_sum=-291.9034098908305, count=79),\n",
       " (1427,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1427, model='delphi-llama2-100k', logprob_sum=-1292.7214970588684, count=176),\n",
       " (2320,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2320, model='delphi-llama2-100k', logprob_sum=-2327.0620925426483, count=350),\n",
       " (1122,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1122, model='delphi-llama2-100k', logprob_sum=-4869.249618887901, count=986),\n",
       " (2072,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2072, model='delphi-llama2-100k', logprob_sum=-1914.4101070016623, count=439),\n",
       " (1185,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1185, model='delphi-llama2-100k', logprob_sum=-3376.3816760629416, count=935),\n",
       " (4042,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=4042, model='delphi-llama2-100k', logprob_sum=-3285.432432520436, count=1391),\n",
       " (795,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=795, model='delphi-llama2-100k', logprob_sum=-885.2167172133923, count=491),\n",
       " (305,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=305, model='delphi-llama2-100k', logprob_sum=-2424.4274205765687, count=1522),\n",
       " (497,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=497, model='delphi-llama2-100k', logprob_sum=-16322.40117973159, count=10174),\n",
       " (1606,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1606, model='delphi-llama2-100k', logprob_sum=-2322.169058263302, count=727),\n",
       " (1412,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1412, model='delphi-llama2-100k', logprob_sum=-3767.982646584511, count=743),\n",
       " (1054,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1054, model='delphi-llama2-100k', logprob_sum=-7151.610437273979, count=1772),\n",
       " (3712,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=3712, model='delphi-llama2-100k', logprob_sum=-1247.4711604118347, count=174),\n",
       " (1507,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1507, model='delphi-llama2-100k', logprob_sum=-2768.7684977650642, count=845),\n",
       " (1203,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1203, model='delphi-llama2-100k', logprob_sum=-3292.097253460437, count=1417),\n",
       " (1342,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1342, model='delphi-llama2-100k', logprob_sum=-6774.071478366852, count=1089),\n",
       " (1514,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1514, model='delphi-llama2-100k', logprob_sum=-4329.362399175763, count=842),\n",
       " (1493,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1493, model='delphi-llama2-100k', logprob_sum=-2939.8798898682, count=896),\n",
       " (2469,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2469, model='delphi-llama2-100k', logprob_sum=-2065.7390422821045, count=297),\n",
       " (1084,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1084, model='delphi-llama2-100k', logprob_sum=-4418.810594821349, count=1795),\n",
       " (2715,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2715, model='delphi-llama2-100k', logprob_sum=-448.83725152909756, count=191),\n",
       " (1756,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1756, model='delphi-llama2-100k', logprob_sum=-2621.5370077462867, count=652),\n",
       " (263,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=263, model='delphi-llama2-100k', logprob_sum=-3839.567806005478, count=542),\n",
       " (1157,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1157, model='delphi-llama2-100k', logprob_sum=-3968.772450789809, count=1470),\n",
       " (2359,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2359, model='delphi-llama2-100k', logprob_sum=-1733.0244124531746, count=293),\n",
       " (4034,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=4034, model='delphi-llama2-100k', logprob_sum=-3671.9034178070724, count=1903),\n",
       " (1023,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1023, model='delphi-llama2-100k', logprob_sum=-92.27816715557128, count=151),\n",
       " (897,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=897, model='delphi-llama2-100k', logprob_sum=-1012.1815930306911, count=1149),\n",
       " (4000,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=4000, model='delphi-llama2-100k', logprob_sum=-794.4496877193451, count=136),\n",
       " (879,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=879, model='delphi-llama2-100k', logprob_sum=-10086.804143175483, count=2646),\n",
       " (1266,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1266, model='delphi-llama2-100k', logprob_sum=-2925.764499440789, count=1249),\n",
       " (3950,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=3950, model='delphi-llama2-100k', logprob_sum=-1125.179313659668, count=148),\n",
       " (3812,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=3812, model='delphi-llama2-100k', logprob_sum=-424.5452315211296, count=128),\n",
       " (1180,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1180, model='delphi-llama2-100k', logprob_sum=-3318.9322514533997, count=984),\n",
       " (768,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=768, model='delphi-llama2-100k', logprob_sum=-7015.992581598461, count=3161),\n",
       " (3143,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=3143, model='delphi-llama2-100k', logprob_sum=-515.6958132460713, count=154),\n",
       " (3213,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=3213, model='delphi-llama2-100k', logprob_sum=-976.6178696155548, count=167),\n",
       " (483,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=483, model='delphi-llama2-100k', logprob_sum=-1086.5239062956534, count=1185),\n",
       " (1908,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1908, model='delphi-llama2-100k', logprob_sum=-2524.2980412244797, count=475),\n",
       " (3301,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=3301, model='delphi-llama2-100k', logprob_sum=-1097.0615097433329, count=197),\n",
       " (2336,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2336, model='delphi-llama2-100k', logprob_sum=-1093.6240509748459, count=149),\n",
       " (464,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=464, model='delphi-llama2-100k', logprob_sum=-1565.5670303252991, count=893),\n",
       " (1145,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1145, model='delphi-llama2-100k', logprob_sum=-4229.624355897307, count=987),\n",
       " (931,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=931, model='delphi-llama2-100k', logprob_sum=-8404.748440235853, count=1930),\n",
       " (2163,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2163, model='delphi-llama2-100k', logprob_sum=-2222.173759639263, count=391),\n",
       " (1616,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1616, model='delphi-llama2-100k', logprob_sum=-3011.9846782684326, count=717),\n",
       " (3413,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=3413, model='delphi-llama2-100k', logprob_sum=-706.3409936055541, count=182),\n",
       " (1653,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1653, model='delphi-llama2-100k', logprob_sum=-1885.3896531853825, count=599),\n",
       " (2124,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2124, model='delphi-llama2-100k', logprob_sum=-1928.5158296823502, count=320),\n",
       " (1359,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1359, model='delphi-llama2-100k', logprob_sum=-2607.070877790451, count=401),\n",
       " (1657,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1657, model='delphi-llama2-100k', logprob_sum=-1429.7026089169085, count=460),\n",
       " (1043,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1043, model='delphi-llama2-100k', logprob_sum=-8289.824522256851, count=1774),\n",
       " (1808,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1808, model='delphi-llama2-100k', logprob_sum=-1338.4259524345398, count=318),\n",
       " (1092,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1092, model='delphi-llama2-100k', logprob_sum=-1996.3766329288483, count=252),\n",
       " (1773,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1773, model='delphi-llama2-100k', logprob_sum=-100.66139401495457, count=98),\n",
       " (951,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=951, model='delphi-llama2-100k', logprob_sum=-12170.364004135132, count=2191),\n",
       " (901,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=901, model='delphi-llama2-100k', logprob_sum=-5008.020214878023, count=2549),\n",
       " (1194,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1194, model='delphi-llama2-100k', logprob_sum=-6458.378993213177, count=1401),\n",
       " (2678,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2678, model='delphi-llama2-100k', logprob_sum=-2216.334189891815, count=300),\n",
       " (3765,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=3765, model='delphi-llama2-100k', logprob_sum=-451.17283295467496, count=122),\n",
       " (1099,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1099, model='delphi-llama2-100k', logprob_sum=-5349.251591205597, count=1611),\n",
       " (3728,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=3728, model='delphi-llama2-100k', logprob_sum=-49.79694843292236, count=7),\n",
       " (1746,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1746, model='delphi-llama2-100k', logprob_sum=-595.7220533281798, count=399),\n",
       " (1171,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1171, model='delphi-llama2-100k', logprob_sum=-5511.400970831513, count=2242),\n",
       " (851,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=851, model='delphi-llama2-100k', logprob_sum=-1598.4527583122253, count=187),\n",
       " (4044,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=4044, model='delphi-llama2-100k', logprob_sum=-2990.820124514401, count=1070),\n",
       " (285,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=285, model='delphi-llama2-100k', logprob_sum=-6348.961098249361, count=4620),\n",
       " (2473,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2473, model='delphi-llama2-100k', logprob_sum=-969.943589925766, count=120),\n",
       " (343,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=343, model='delphi-llama2-100k', logprob_sum=-1267.7956639416516, count=744),\n",
       " (2873,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2873, model='delphi-llama2-100k', logprob_sum=-1068.0826598405838, count=164),\n",
       " (1556,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1556, model='delphi-llama2-100k', logprob_sum=-3198.7975351810455, count=804),\n",
       " (2237,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2237, model='delphi-llama2-100k', logprob_sum=-1914.7229276299477, count=352),\n",
       " (1281,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1281, model='delphi-llama2-100k', logprob_sum=-4086.691268801689, count=1045),\n",
       " (3525,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=3525, model='delphi-llama2-100k', logprob_sum=-900.7228845357895, count=151),\n",
       " (1651,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1651, model='delphi-llama2-100k', logprob_sum=-3594.756610006094, count=716),\n",
       " (1912,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1912, model='delphi-llama2-100k', logprob_sum=-2785.4322422742844, count=482),\n",
       " (1032,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1032, model='delphi-llama2-100k', logprob_sum=-8138.2120667696, count=1795),\n",
       " (1467,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1467, model='delphi-llama2-100k', logprob_sum=-2313.310262709856, count=823),\n",
       " (1421,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1421, model='delphi-llama2-100k', logprob_sum=-2200.518232518807, count=871),\n",
       " (875,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=875, model='delphi-llama2-100k', logprob_sum=-10022.86004716158, count=2531),\n",
       " (3689,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=3689, model='delphi-llama2-100k', logprob_sum=-604.6344243884087, count=124),\n",
       " (4023,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=4023, model='delphi-llama2-100k', logprob_sum=-23337.65578430891, count=8061),\n",
       " (1743,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1743, model='delphi-llama2-100k', logprob_sum=-1547.7341242432594, count=607),\n",
       " (3654,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=3654, model='delphi-llama2-100k', logprob_sum=-991.908890247345, count=129),\n",
       " (1602,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1602, model='delphi-llama2-100k', logprob_sum=-71.21290039410815, count=122),\n",
       " (3784,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=3784, model='delphi-llama2-100k', logprob_sum=-486.4117602184415, count=119),\n",
       " (1391,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1391, model='delphi-llama2-100k', logprob_sum=-2798.48297894001, count=940),\n",
       " (3296,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=3296, model='delphi-llama2-100k', logprob_sum=-1040.216522693634, count=150),\n",
       " (664,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=664, model='delphi-llama2-100k', logprob_sum=-7749.875435689464, count=3298),\n",
       " (2390,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2390, model='delphi-llama2-100k', logprob_sum=-2375.3181646466255, count=394),\n",
       " (2806,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2806, model='delphi-llama2-100k', logprob_sum=-1043.5283753871918, count=239),\n",
       " (1334,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1334, model='delphi-llama2-100k', logprob_sum=-5118.550177693367, count=995),\n",
       " (569,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=569, model='delphi-llama2-100k', logprob_sum=-598.1507956769783, count=1036),\n",
       " (1320,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1320, model='delphi-llama2-100k', logprob_sum=-1172.1384066343307, count=157),\n",
       " (465,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=465, model='delphi-llama2-100k', logprob_sum=-860.6489907000214, count=807),\n",
       " (1387,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1387, model='delphi-llama2-100k', logprob_sum=-3141.134966611862, count=615),\n",
       " (2548,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2548, model='delphi-llama2-100k', logprob_sum=-1074.4558466672897, count=275),\n",
       " (1650,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1650, model='delphi-llama2-100k', logprob_sum=-2255.308063149452, count=677),\n",
       " (1127,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1127, model='delphi-llama2-100k', logprob_sum=-4934.3832372538745, count=1667),\n",
       " (1214,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1214, model='delphi-llama2-100k', logprob_sum=-2688.8107880353928, count=501),\n",
       " (3636,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=3636, model='delphi-llama2-100k', logprob_sum=-396.44870825111866, count=133),\n",
       " (3934,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=3934, model='delphi-llama2-100k', logprob_sum=-720.2628893852234, count=114),\n",
       " (2073,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2073, model='delphi-llama2-100k', logprob_sum=-2513.9665438234806, count=414),\n",
       " (2621,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2621, model='delphi-llama2-100k', logprob_sum=-2027.8145859241486, count=270),\n",
       " (441,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=441, model='delphi-llama2-100k', logprob_sum=-1101.204241017811, count=955),\n",
       " (841,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=841, model='delphi-llama2-100k', logprob_sum=-7059.607044234872, count=2092),\n",
       " (1547,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1547, model='delphi-llama2-100k', logprob_sum=-4114.647475108504, count=863),\n",
       " (1249,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1249, model='delphi-llama2-100k', logprob_sum=-677.5602903366089, count=84),\n",
       " (4041,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=4041, model='delphi-llama2-100k', logprob_sum=-1675.2652716415469, count=700),\n",
       " (2802,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2802, model='delphi-llama2-100k', logprob_sum=-1257.358142375946, count=179),\n",
       " (1153,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1153, model='delphi-llama2-100k', logprob_sum=-4203.573433160782, count=853),\n",
       " (3349,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=3349, model='delphi-llama2-100k', logprob_sum=-609.5447022169828, count=135),\n",
       " (1471,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1471, model='delphi-llama2-100k', logprob_sum=-4990.864207625389, count=862),\n",
       " (1206,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1206, model='delphi-llama2-100k', logprob_sum=-4624.713850103319, count=1198),\n",
       " (1886,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1886, model='delphi-llama2-100k', logprob_sum=-2873.5859706401825, count=518),\n",
       " (1799,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1799, model='delphi-llama2-100k', logprob_sum=-2447.88187456131, count=524),\n",
       " (3868,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=3868, model='delphi-llama2-100k', logprob_sum=-516.2025147676468, count=115),\n",
       " (1028,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1028, model='delphi-llama2-100k', logprob_sum=-5493.152322474867, count=1712),\n",
       " (3366,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=3366, model='delphi-llama2-100k', logprob_sum=-993.2808421850204, count=175),\n",
       " (2350,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2350, model='delphi-llama2-100k', logprob_sum=-1939.2694764137268, count=313),\n",
       " (355,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=355, model='delphi-llama2-100k', logprob_sum=-3279.0274902042, count=1212),\n",
       " (2638,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2638, model='delphi-llama2-100k', logprob_sum=-92.70454104221426, count=134),\n",
       " (1586,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1586, model='delphi-llama2-100k', logprob_sum=-2685.1207731962204, count=703),\n",
       " (1863,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1863, model='delphi-llama2-100k', logprob_sum=-2749.2007596492767, count=472),\n",
       " (1442,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1442, model='delphi-llama2-100k', logprob_sum=-3141.955788999796, count=904),\n",
       " (1027,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1027, model='delphi-llama2-100k', logprob_sum=-8326.395050317049, count=1866),\n",
       " (1589,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1589, model='delphi-llama2-100k', logprob_sum=-3905.99582862854, count=710),\n",
       " (839,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=839, model='delphi-llama2-100k', logprob_sum=-780.5965974330902, count=114),\n",
       " (1679,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1679, model='delphi-llama2-100k', logprob_sum=-406.24210410937667, count=214),\n",
       " (1717,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1717, model='delphi-llama2-100k', logprob_sum=-3588.1562358140945, count=574),\n",
       " (2807,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2807, model='delphi-llama2-100k', logprob_sum=-1240.9644985198975, count=217),\n",
       " (596,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=596, model='delphi-llama2-100k', logprob_sum=-10538.791454925202, count=5439),\n",
       " (907,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=907, model='delphi-llama2-100k', logprob_sum=-6968.834281593561, count=2351),\n",
       " (1444,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1444, model='delphi-llama2-100k', logprob_sum=-2206.912948739715, count=787),\n",
       " (1826,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1826, model='delphi-llama2-100k', logprob_sum=-1805.4039708264172, count=508),\n",
       " (4059,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=4059, model='delphi-llama2-100k', logprob_sum=-5341.269323520362, count=2247),\n",
       " (573,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=573, model='delphi-llama2-100k', logprob_sum=-634.7761718495749, count=1074),\n",
       " (828,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=828, model='delphi-llama2-100k', logprob_sum=-10067.153622264042, count=2937),\n",
       " (1165,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1165, model='delphi-llama2-100k', logprob_sum=-3684.3238293463364, count=1439),\n",
       " (4055,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=4055, model='delphi-llama2-100k', logprob_sum=-5397.457067206502, count=1867),\n",
       " (1344,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1344, model='delphi-llama2-100k', logprob_sum=-889.4867964461446, count=543),\n",
       " (2655,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2655, model='delphi-llama2-100k', logprob_sum=-1080.1601141691208, count=262),\n",
       " (1386,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1386, model='delphi-llama2-100k', logprob_sum=-2043.595105022192, count=1039),\n",
       " (2302,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2302, model='delphi-llama2-100k', logprob_sum=-392.0792577266693, count=57),\n",
       " (338,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=338, model='delphi-llama2-100k', logprob_sum=-611.0846292602364, count=827),\n",
       " (487,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=487, model='delphi-llama2-100k', logprob_sum=-997.6185164451599, count=111),\n",
       " (2024,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2024, model='delphi-llama2-100k', logprob_sum=-110.983309045434, count=57),\n",
       " (686,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=686, model='delphi-llama2-100k', logprob_sum=-1867.2651544511318, count=1301),\n",
       " (1660,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1660, model='delphi-llama2-100k', logprob_sum=-3029.2839945852757, count=679),\n",
       " (267,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=267, model='delphi-llama2-100k', logprob_sum=-8347.15430176258, count=1168),\n",
       " (987,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=987, model='delphi-llama2-100k', logprob_sum=-571.2953593507409, count=310),\n",
       " (1639,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1639, model='delphi-llama2-100k', logprob_sum=-4579.499507427216, count=722),\n",
       " (3055,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=3055, model='delphi-llama2-100k', logprob_sum=-1083.404188632965, count=167),\n",
       " (1560,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1560, model='delphi-llama2-100k', logprob_sum=-3867.851443991065, count=792),\n",
       " (3354,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=3354, model='delphi-llama2-100k', logprob_sum=-577.1102785654366, count=148),\n",
       " (960,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=960, model='delphi-llama2-100k', logprob_sum=-585.2586116790771, count=69),\n",
       " (597,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=597, model='delphi-llama2-100k', logprob_sum=-2363.3694630842656, count=1516),\n",
       " (3490,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=3490, model='delphi-llama2-100k', logprob_sum=-1742.027198843658, count=1146),\n",
       " (1132,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1132, model='delphi-llama2-100k', logprob_sum=-7148.314822494984, count=1542),\n",
       " (2934,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2934, model='delphi-llama2-100k', logprob_sum=-1635.4573335647583, count=209),\n",
       " (1862,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1862, model='delphi-llama2-100k', logprob_sum=-1770.6414031982422, count=307),\n",
       " (1265,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1265, model='delphi-llama2-100k', logprob_sum=-308.25892279855907, count=174),\n",
       " (979,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=979, model='delphi-llama2-100k', logprob_sum=-4051.2449672222137, count=822),\n",
       " (1187,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1187, model='delphi-llama2-100k', logprob_sum=-4071.7378336787224, count=1269),\n",
       " (281,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=281, model='delphi-llama2-100k', logprob_sum=-8297.3967705369, count=1361),\n",
       " (1855,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1855, model='delphi-llama2-100k', logprob_sum=-390.02505215257406, count=186),\n",
       " (3471,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=3471, model='delphi-llama2-100k', logprob_sum=-487.4709407389164, count=157),\n",
       " (3071,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=3071, model='delphi-llama2-100k', logprob_sum=-1159.7198627591133, count=196),\n",
       " (1046,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1046, model='delphi-llama2-100k', logprob_sum=-7438.452930390835, count=1520),\n",
       " (3011,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=3011, model='delphi-llama2-100k', logprob_sum=-1143.9602987766266, count=168),\n",
       " (1431,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1431, model='delphi-llama2-100k', logprob_sum=-5053.209922611713, count=911),\n",
       " (278,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=278, model='delphi-llama2-100k', logprob_sum=-6098.452402561903, count=936),\n",
       " (1896,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1896, model='delphi-llama2-100k', logprob_sum=-178.51549424417317, count=166),\n",
       " (1335,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1335, model='delphi-llama2-100k', logprob_sum=-4724.1293196082115, count=1025),\n",
       " (1227,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1227, model='delphi-llama2-100k', logprob_sum=-6377.813080787659, count=1286),\n",
       " (2256,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2256, model='delphi-llama2-100k', logprob_sum=-1427.4736187458038, count=333),\n",
       " (1778,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1778, model='delphi-llama2-100k', logprob_sum=-3686.9905869960785, count=581),\n",
       " (456,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=456, model='delphi-llama2-100k', logprob_sum=-1708.135295715183, count=595),\n",
       " (1945,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1945, model='delphi-llama2-100k', logprob_sum=-1609.3125493973494, count=430),\n",
       " (339,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=339, model='delphi-llama2-100k', logprob_sum=-6704.642053604126, count=989),\n",
       " (1192,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1192, model='delphi-llama2-100k', logprob_sum=-1214.8747129142284, count=481),\n",
       " (570,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=570, model='delphi-llama2-100k', logprob_sum=-12408.502558949403, count=7116),\n",
       " (1824,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1824, model='delphi-llama2-100k', logprob_sum=-2123.7244272232056, count=261),\n",
       " (3227,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=3227, model='delphi-llama2-100k', logprob_sum=-1448.2362468242645, count=194),\n",
       " (1089,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1089, model='delphi-llama2-100k', logprob_sum=-3798.323500096798, count=893),\n",
       " (1173,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1173, model='delphi-llama2-100k', logprob_sum=-3289.412954659201, count=1387),\n",
       " (3785,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=3785, model='delphi-llama2-100k', logprob_sum=-1405.3413321189582, count=786),\n",
       " (900,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=900, model='delphi-llama2-100k', logprob_sum=-11096.467710614204, count=2506),\n",
       " (1731,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1731, model='delphi-llama2-100k', logprob_sum=-2546.2428892850876, count=529),\n",
       " (1348,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1348, model='delphi-llama2-100k', logprob_sum=-4604.947605192661, count=1049),\n",
       " (2403,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2403, model='delphi-llama2-100k', logprob_sum=-1754.7588422298431, count=312),\n",
       " (2235,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2235, model='delphi-llama2-100k', logprob_sum=-1366.152880936861, count=305),\n",
       " (2527,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2527, model='delphi-llama2-100k', logprob_sum=-1280.1128400713205, count=288),\n",
       " (2095,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2095, model='delphi-llama2-100k', logprob_sum=-1693.1915818452835, count=217),\n",
       " (3833,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=3833, model='delphi-llama2-100k', logprob_sum=-915.2295768260956, count=127),\n",
       " (1920,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1920, model='delphi-llama2-100k', logprob_sum=-421.35233427770436, count=308),\n",
       " (1697,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1697, model='delphi-llama2-100k', logprob_sum=-2962.1595393419266, count=603),\n",
       " (864,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=864, model='delphi-llama2-100k', logprob_sum=-5924.80203795433, count=1572),\n",
       " (1109,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1109, model='delphi-llama2-100k', logprob_sum=-355.1217526749242, count=179),\n",
       " (679,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=679, model='delphi-llama2-100k', logprob_sum=-3811.8727449290454, count=998),\n",
       " (1502,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1502, model='delphi-llama2-100k', logprob_sum=-5106.986915111542, count=866),\n",
       " (727,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=727, model='delphi-llama2-100k', logprob_sum=-16719.37145012617, count=3940),\n",
       " (1230,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1230, model='delphi-llama2-100k', logprob_sum=-2995.6691032350063, count=809),\n",
       " (1552,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1552, model='delphi-llama2-100k', logprob_sum=-1459.262725982815, count=335),\n",
       " (882,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=882, model='delphi-llama2-100k', logprob_sum=-4175.971992403269, count=1508),\n",
       " (3065,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=3065, model='delphi-llama2-100k', logprob_sum=-336.7222774550319, count=205),\n",
       " (1488,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1488, model='delphi-llama2-100k', logprob_sum=-1643.6780729293823, count=248),\n",
       " (1944,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1944, model='delphi-llama2-100k', logprob_sum=-2073.441962093115, count=458),\n",
       " (2128,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2128, model='delphi-llama2-100k', logprob_sum=-1841.401721417904, count=371),\n",
       " (3627,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=3627, model='delphi-llama2-100k', logprob_sum=-710.0667911022902, count=140),\n",
       " (2372,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2372, model='delphi-llama2-100k', logprob_sum=-1708.6292881965637, count=268),\n",
       " (2265,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2265, model='delphi-llama2-100k', logprob_sum=-2054.8821872472763, count=328),\n",
       " (2134,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2134, model='delphi-llama2-100k', logprob_sum=-1124.047482907772, count=388),\n",
       " (2057,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2057, model='delphi-llama2-100k', logprob_sum=-1797.3539779186249, count=385),\n",
       " (3343,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=3343, model='delphi-llama2-100k', logprob_sum=-838.2848196551204, count=170),\n",
       " (3438,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=3438, model='delphi-llama2-100k', logprob_sum=-1144.9556939601898, count=174),\n",
       " (914,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=914, model='delphi-llama2-100k', logprob_sum=-1692.7709555625916, count=210),\n",
       " (2589,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2589, model='delphi-llama2-100k', logprob_sum=-140.97477054595947, count=40),\n",
       " (3224,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=3224, model='delphi-llama2-100k', logprob_sum=-967.5885062217712, count=172),\n",
       " (2862,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2862, model='delphi-llama2-100k', logprob_sum=-961.847348690033, count=220),\n",
       " (956,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=956, model='delphi-llama2-100k', logprob_sum=-1141.0806809335481, count=1184),\n",
       " (287,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=287, model='delphi-llama2-100k', logprob_sum=-896.2839891588665, count=1233),\n",
       " (4077,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=4077, model='delphi-llama2-100k', logprob_sum=-4632.497534540482, count=1451),\n",
       " (295,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=295, model='delphi-llama2-100k', logprob_sum=-1862.435615960043, count=1044),\n",
       " (584,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=584, model='delphi-llama2-100k', logprob_sum=-145.04674738645554, count=44),\n",
       " (922,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=922, model='delphi-llama2-100k', logprob_sum=-8862.35280328989, count=2420),\n",
       " (1698,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1698, model='delphi-llama2-100k', logprob_sum=-3970.4810004234314, count=628),\n",
       " (1955,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1955, model='delphi-llama2-100k', logprob_sum=-1681.8016708493233, count=420),\n",
       " (1885,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1885, model='delphi-llama2-100k', logprob_sum=-3000.6017532348633, count=505),\n",
       " (703,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=703, model='delphi-llama2-100k', logprob_sum=-4394.24206328392, count=592),\n",
       " (1191,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1191, model='delphi-llama2-100k', logprob_sum=-87.18482914566994, count=77),\n",
       " (1392,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1392, model='delphi-llama2-100k', logprob_sum=-2741.982652425766, count=403),\n",
       " (3740,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=3740, model='delphi-llama2-100k', logprob_sum=-583.9839676618576, count=127),\n",
       " (863,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=863, model='delphi-llama2-100k', logprob_sum=-371.4106786251068, count=52),\n",
       " (382,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=382, model='delphi-llama2-100k', logprob_sum=-1175.2377057550475, count=722),\n",
       " (2998,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2998, model='delphi-llama2-100k', logprob_sum=-914.1990628242493, count=181),\n",
       " (1031,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1031, model='delphi-llama2-100k', logprob_sum=-8665.604760169983, count=1756),\n",
       " (1220,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1220, model='delphi-llama2-100k', logprob_sum=-4603.097181797028, count=1383),\n",
       " (3597,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=3597, model='delphi-llama2-100k', logprob_sum=-281.62703791819513, count=99),\n",
       " (1805,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1805, model='delphi-llama2-100k', logprob_sum=-1303.0068073123693, count=571),\n",
       " (1200,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1200, model='delphi-llama2-100k', logprob_sum=-5637.2945817783475, count=1475),\n",
       " (1375,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1375, model='delphi-llama2-100k', logprob_sum=-1245.7792933518067, count=1014),\n",
       " (2016,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2016, model='delphi-llama2-100k', logprob_sum=-1815.0382849127054, count=462),\n",
       " (2602,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2602, model='delphi-llama2-100k', logprob_sum=-1210.3735783398151, count=293),\n",
       " (1625,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1625, model='delphi-llama2-100k', logprob_sum=-2533.1443884968758, count=635),\n",
       " (3258,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=3258, model='delphi-llama2-100k', logprob_sum=-737.5374999046326, count=132),\n",
       " (2609,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2609, model='delphi-llama2-100k', logprob_sum=-550.9463510513306, count=64),\n",
       " (1527,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1527, model='delphi-llama2-100k', logprob_sum=-4041.8443641662598, count=821),\n",
       " (3331,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=3331, model='delphi-llama2-100k', logprob_sum=-701.8182585835457, count=124),\n",
       " (609,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=609, model='delphi-llama2-100k', logprob_sum=-967.5907943500206, count=422),\n",
       " (2512,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2512, model='delphi-llama2-100k', logprob_sum=-1719.9307672977448, count=272),\n",
       " (1750,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1750, model='delphi-llama2-100k', logprob_sum=-1470.8066062126309, count=372),\n",
       " (2699,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2699, model='delphi-llama2-100k', logprob_sum=-61.93770158290863, count=111),\n",
       " (3982,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=3982, model='delphi-llama2-100k', logprob_sum=-964.7867705821991, count=126),\n",
       " (629,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=629, model='delphi-llama2-100k', logprob_sum=-1064.1186320334673, count=379),\n",
       " (365,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=365, model='delphi-llama2-100k', logprob_sum=-303.8342600171454, count=216),\n",
       " (1932,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1932, model='delphi-llama2-100k', logprob_sum=-3382.9536044597626, count=449),\n",
       " (1330,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1330, model='delphi-llama2-100k', logprob_sum=-5772.709188342094, count=1126),\n",
       " (2683,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2683, model='delphi-llama2-100k', logprob_sum=-1352.1042934656143, count=242),\n",
       " (958,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=958, model='delphi-llama2-100k', logprob_sum=-6388.08905506134, count=1298),\n",
       " (1783,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1783, model='delphi-llama2-100k', logprob_sum=-3560.6147129535675, count=577),\n",
       " (865,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=865, model='delphi-llama2-100k', logprob_sum=-316.8978683874011, count=220),\n",
       " (361,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=361, model='delphi-llama2-100k', logprob_sum=-968.9530051313341, count=302),\n",
       " (3999,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=3999, model='delphi-llama2-100k', logprob_sum=-103.31581072509289, count=132),\n",
       " (1655,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1655, model='delphi-llama2-100k', logprob_sum=-3779.8852033615112, count=626),\n",
       " (3580,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=3580, model='delphi-llama2-100k', logprob_sum=-925.0357971191406, count=156),\n",
       " (265,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=265, model='delphi-llama2-100k', logprob_sum=-1369.0522428031545, count=782),\n",
       " ...}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_model_stats[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('Capitalized', 'delphi-llama2-100k'): -2.046864688876206,\n",
       " ('Is Adjective', 'delphi-llama2-100k'): -3.4470707012948107,\n",
       " ('Is Adposition', 'delphi-llama2-100k'): -2.5054444217720895,\n",
       " ('Is Adverb', 'delphi-llama2-100k'): -3.041814374148337,\n",
       " ('Is Auxiliary', 'delphi-llama2-100k'): -1.5029872011356107,\n",
       " ('Is Coordinating conjuction', 'delphi-llama2-100k'): -1.4905235418156169,\n",
       " ('Is Interjunction', 'delphi-llama2-100k'): -1.6035190641883796,\n",
       " ('Is Noun', 'delphi-llama2-100k'): -2.7970957412390938,\n",
       " ('Is Numeral', 'delphi-llama2-100k'): -2.401989014993226,\n",
       " ('Is Particle', 'delphi-llama2-100k'): -0.9790793063799712,\n",
       " ('Is Pronoun', 'delphi-llama2-100k'): -1.6812808827511345,\n",
       " ('Is Proper Noun', 'delphi-llama2-100k'): -2.8902006726267606,\n",
       " ('Is Punctuation', 'delphi-llama2-100k'): -0.8806130811295786,\n",
       " ('Is Subordinating conjuction', 'delphi-llama2-100k'): -2.3118651218141735,\n",
       " ('Is Verb', 'delphi-llama2-100k'): -3.116768158262923,\n",
       " ('Is Other', 'delphi-llama2-100k'): -1.8515646689277523,\n",
       " ('Capitalized', 'delphi-llama2-200k'): -1.8235458718526685,\n",
       " ('Is Adjective', 'delphi-llama2-200k'): -3.132289723401814,\n",
       " ('Is Adposition', 'delphi-llama2-200k'): -2.2835068499475724,\n",
       " ('Is Adverb', 'delphi-llama2-200k'): -2.76064780744662,\n",
       " ('Is Auxiliary', 'delphi-llama2-200k'): -1.3864030996901606,\n",
       " ('Is Coordinating conjuction', 'delphi-llama2-200k'): -1.3720400950057705,\n",
       " ('Is Interjunction', 'delphi-llama2-200k'): -1.3918437142415578,\n",
       " ('Is Noun', 'delphi-llama2-200k'): -2.3746086457963833,\n",
       " ('Is Numeral', 'delphi-llama2-200k'): -2.1754139619017345,\n",
       " ('Is Particle', 'delphi-llama2-200k'): -0.8888699588985527,\n",
       " ('Is Pronoun', 'delphi-llama2-200k'): -1.5026616489934475,\n",
       " ('Is Proper Noun', 'delphi-llama2-200k'): -2.4807834248304608,\n",
       " ('Is Punctuation', 'delphi-llama2-200k'): -0.7919200751161568,\n",
       " ('Is Subordinating conjuction', 'delphi-llama2-200k'): -2.1111773973965553,\n",
       " ('Is Verb', 'delphi-llama2-200k'): -2.8411149494381034,\n",
       " ('Is Other', 'delphi-llama2-200k'): -1.5740345756656295,\n",
       " ('Capitalized', 'delphi-llama2-400k'): -1.6356975973700658,\n",
       " ('Is Adjective', 'delphi-llama2-400k'): -2.7420037359977076,\n",
       " ('Is Adposition', 'delphi-llama2-400k'): -2.024667821035853,\n",
       " ('Is Adverb', 'delphi-llama2-400k'): -2.451075208124139,\n",
       " ('Is Auxiliary', 'delphi-llama2-400k'): -1.2501980683731375,\n",
       " ('Is Coordinating conjuction', 'delphi-llama2-400k'): -1.2419105436567874,\n",
       " ('Is Interjunction', 'delphi-llama2-400k'): -1.196836152039155,\n",
       " ('Is Noun', 'delphi-llama2-400k'): -2.023067028598839,\n",
       " ('Is Numeral', 'delphi-llama2-400k'): -1.9777726931651136,\n",
       " ('Is Particle', 'delphi-llama2-400k'): -0.7928602635895385,\n",
       " ('Is Pronoun', 'delphi-llama2-400k'): -1.3444136511106355,\n",
       " ('Is Proper Noun', 'delphi-llama2-400k'): -2.136282052648478,\n",
       " ('Is Punctuation', 'delphi-llama2-400k'): -0.7089908782860862,\n",
       " ('Is Subordinating conjuction', 'delphi-llama2-400k'): -1.921911769385312,\n",
       " ('Is Verb', 'delphi-llama2-400k'): -2.5451601058316933,\n",
       " ('Is Other', 'delphi-llama2-400k'): -1.3104049686804469,\n",
       " ('Capitalized', 'delphi-llama2-800k'): -1.4736162006587463,\n",
       " ('Is Adjective', 'delphi-llama2-800k'): -2.4558533314618587,\n",
       " ('Is Adposition', 'delphi-llama2-800k'): -1.7950187136006706,\n",
       " ('Is Adverb', 'delphi-llama2-800k'): -2.170279853399201,\n",
       " ('Is Auxiliary', 'delphi-llama2-800k'): -1.1316648720084332,\n",
       " ('Is Coordinating conjuction', 'delphi-llama2-800k'): -1.115088907028389,\n",
       " ('Is Interjunction', 'delphi-llama2-800k'): -1.0480683756920472,\n",
       " ('Is Noun', 'delphi-llama2-800k'): -1.7610821126786464,\n",
       " ('Is Numeral', 'delphi-llama2-800k'): -1.7958960992479562,\n",
       " ('Is Particle', 'delphi-llama2-800k'): -0.7009348621407638,\n",
       " ('Is Pronoun', 'delphi-llama2-800k'): -1.1790975359301559,\n",
       " ('Is Proper Noun', 'delphi-llama2-800k'): -1.8805085938979762,\n",
       " ('Is Punctuation', 'delphi-llama2-800k'): -0.6323230954914143,\n",
       " ('Is Subordinating conjuction', 'delphi-llama2-800k'): -1.7212002441544776,\n",
       " ('Is Verb', 'delphi-llama2-800k'): -2.28302766660105,\n",
       " ('Is Other', 'delphi-llama2-800k'): -1.1267227665149093,\n",
       " ('Capitalized', 'delphi-llama2-1.6m'): -1.3610698483570876,\n",
       " ('Is Adjective', 'delphi-llama2-1.6m'): -2.2029349226412407,\n",
       " ('Is Adposition', 'delphi-llama2-1.6m'): -1.6046753182900426,\n",
       " ('Is Adverb', 'delphi-llama2-1.6m'): -1.9316411693226438,\n",
       " ('Is Auxiliary', 'delphi-llama2-1.6m'): -1.0345865640020637,\n",
       " ('Is Coordinating conjuction', 'delphi-llama2-1.6m'): -1.0206435605615192,\n",
       " ('Is Interjunction', 'delphi-llama2-1.6m'): -0.9211523283681858,\n",
       " ('Is Noun', 'delphi-llama2-1.6m'): -1.5389766320698754,\n",
       " ('Is Numeral', 'delphi-llama2-1.6m'): -1.6553907189296897,\n",
       " ('Is Particle', 'delphi-llama2-1.6m'): -0.6335924811976049,\n",
       " ('Is Pronoun', 'delphi-llama2-1.6m'): -1.0652854069539708,\n",
       " ('Is Proper Noun', 'delphi-llama2-1.6m'): -1.6837111384880779,\n",
       " ('Is Punctuation', 'delphi-llama2-1.6m'): -0.5791595552355734,\n",
       " ('Is Subordinating conjuction', 'delphi-llama2-1.6m'): -1.5661853243109325,\n",
       " ('Is Verb', 'delphi-llama2-1.6m'): -2.0590816737481457,\n",
       " ('Is Other', 'delphi-llama2-1.6m'): -0.9525987599050318,\n",
       " ('Capitalized', 'delphi-llama2-3.2m'): -1.286416511805987,\n",
       " ('Is Adjective', 'delphi-llama2-3.2m'): -2.0683485120753877,\n",
       " ('Is Adposition', 'delphi-llama2-3.2m'): -1.488558519416164,\n",
       " ('Is Adverb', 'delphi-llama2-3.2m'): -1.79180775991581,\n",
       " ('Is Auxiliary', 'delphi-llama2-3.2m'): -0.9774983875308673,\n",
       " ('Is Coordinating conjuction', 'delphi-llama2-3.2m'): -0.9626705190267114,\n",
       " ('Is Interjunction', 'delphi-llama2-3.2m'): -0.8485386312350832,\n",
       " ('Is Noun', 'delphi-llama2-3.2m'): -1.4108094483401954,\n",
       " ('Is Numeral', 'delphi-llama2-3.2m'): -1.5668183049913085,\n",
       " ('Is Particle', 'delphi-llama2-3.2m'): -0.5910980805837756,\n",
       " ('Is Pronoun', 'delphi-llama2-3.2m'): -0.9915043336409837,\n",
       " ('Is Proper Noun', 'delphi-llama2-3.2m'): -1.5633728176169763,\n",
       " ('Is Punctuation', 'delphi-llama2-3.2m'): -0.5461574270855881,\n",
       " ('Is Subordinating conjuction', 'delphi-llama2-3.2m'): -1.468335683571395,\n",
       " ('Is Verb', 'delphi-llama2-3.2m'): -1.9198452060159805,\n",
       " ('Is Other', 'delphi-llama2-3.2m'): -0.8552034928917498,\n",
       " ('Capitalized', 'delphi-llama2-6.4m'): -1.2113056687398684,\n",
       " ('Is Adjective', 'delphi-llama2-6.4m'): -1.9161696959914416,\n",
       " ('Is Adposition', 'delphi-llama2-6.4m'): -1.3653814915444393,\n",
       " ('Is Adverb', 'delphi-llama2-6.4m'): -1.6491427718753426,\n",
       " ('Is Auxiliary', 'delphi-llama2-6.4m'): -0.915216082578819,\n",
       " ('Is Coordinating conjuction', 'delphi-llama2-6.4m'): -0.9009504424539347,\n",
       " ('Is Interjunction', 'delphi-llama2-6.4m'): -0.7746677382095681,\n",
       " ('Is Noun', 'delphi-llama2-6.4m'): -1.29202556866188,\n",
       " ('Is Numeral', 'delphi-llama2-6.4m'): -1.4900708560392226,\n",
       " ('Is Particle', 'delphi-llama2-6.4m'): -0.543088564230333,\n",
       " ('Is Pronoun', 'delphi-llama2-6.4m'): -0.9157125103810166,\n",
       " ('Is Proper Noun', 'delphi-llama2-6.4m'): -1.4475443463378965,\n",
       " ('Is Punctuation', 'delphi-llama2-6.4m'): -0.5114281252923611,\n",
       " ('Is Subordinating conjuction', 'delphi-llama2-6.4m'): -1.3621447994250142,\n",
       " ('Is Verb', 'delphi-llama2-6.4m'): -1.771994157103309,\n",
       " ('Is Other', 'delphi-llama2-6.4m'): -0.762933156991657,\n",
       " ('Capitalized', 'delphi-llama2-12.8m'): -1.1350579486629704,\n",
       " ('Is Adjective', 'delphi-llama2-12.8m'): -1.7558728658762974,\n",
       " ('Is Adposition', 'delphi-llama2-12.8m'): -1.2429672500751667,\n",
       " ('Is Adverb', 'delphi-llama2-12.8m'): -1.4942471860243225,\n",
       " ('Is Auxiliary', 'delphi-llama2-12.8m'): -0.8473544536702423,\n",
       " ('Is Coordinating conjuction', 'delphi-llama2-12.8m'): -0.8357455859902575,\n",
       " ('Is Interjunction', 'delphi-llama2-12.8m'): -0.6994657616868973,\n",
       " ('Is Noun', 'delphi-llama2-12.8m'): -1.1605183873358302,\n",
       " ('Is Numeral', 'delphi-llama2-12.8m'): -1.4022164241399775,\n",
       " ('Is Particle', 'delphi-llama2-12.8m'): -0.49500265348175243,\n",
       " ('Is Pronoun', 'delphi-llama2-12.8m'): -0.8388493562153533,\n",
       " ('Is Proper Noun', 'delphi-llama2-12.8m'): -1.3282172122740412,\n",
       " ('Is Punctuation', 'delphi-llama2-12.8m'): -0.47687713549470606,\n",
       " ('Is Subordinating conjuction', 'delphi-llama2-12.8m'): -1.2495820563060485,\n",
       " ('Is Verb', 'delphi-llama2-12.8m'): -1.6127642420056925,\n",
       " ('Is Other', 'delphi-llama2-12.8m'): -0.6600910571763848,\n",
       " ('Capitalized', 'delphi-llama2-25.6m'): -1.103573968265206,\n",
       " ('Is Adjective', 'delphi-llama2-25.6m'): -1.6915034418064891,\n",
       " ('Is Adposition', 'delphi-llama2-25.6m'): -1.1912526422242409,\n",
       " ('Is Adverb', 'delphi-llama2-25.6m'): -1.4343104912147209,\n",
       " ('Is Auxiliary', 'delphi-llama2-25.6m'): -0.8213457744514149,\n",
       " ('Is Coordinating conjuction', 'delphi-llama2-25.6m'): -0.8076313379761278,\n",
       " ('Is Interjunction', 'delphi-llama2-25.6m'): -0.6706861707252683,\n",
       " ('Is Noun', 'delphi-llama2-25.6m'): -1.1092909469095857,\n",
       " ('Is Numeral', 'delphi-llama2-25.6m'): -1.3636281143086386,\n",
       " ('Is Particle', 'delphi-llama2-25.6m'): -0.4775492743469723,\n",
       " ('Is Pronoun', 'delphi-llama2-25.6m'): -0.8081966485478549,\n",
       " ('Is Proper Noun', 'delphi-llama2-25.6m'): -1.2830737171730644,\n",
       " ('Is Punctuation', 'delphi-llama2-25.6m'): -0.46419824090306816,\n",
       " ('Is Subordinating conjuction', 'delphi-llama2-25.6m'): -1.2071330412984285,\n",
       " ('Is Verb', 'delphi-llama2-25.6m'): -1.545826218890734,\n",
       " ('Is Other', 'delphi-llama2-25.6m'): -0.6221255054532343}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_token_group_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/model_token_group_stats.pkl\", \"wb\") as f:\n",
    "    pickle.dump(model_token_group_stats, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "mtgs_df = pd.DataFrame(\n",
    "    [key + ( value, ) for key, value in model_token_group_stats.items()],\n",
    "    columns=[\"token_group\", \"model\", \"mean_logprob\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token_group</th>\n",
       "      <th>model</th>\n",
       "      <th>mean_logprob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Capitalized</td>\n",
       "      <td>delphi-llama2-100k</td>\n",
       "      <td>-2.046865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Is Adjective</td>\n",
       "      <td>delphi-llama2-100k</td>\n",
       "      <td>-3.447071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Is Adposition</td>\n",
       "      <td>delphi-llama2-100k</td>\n",
       "      <td>-2.505444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Is Adverb</td>\n",
       "      <td>delphi-llama2-100k</td>\n",
       "      <td>-3.041814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Is Auxiliary</td>\n",
       "      <td>delphi-llama2-100k</td>\n",
       "      <td>-1.502987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>Is Proper Noun</td>\n",
       "      <td>delphi-llama2-25.6m</td>\n",
       "      <td>-1.283074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>Is Punctuation</td>\n",
       "      <td>delphi-llama2-25.6m</td>\n",
       "      <td>-0.464198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>Is Subordinating conjuction</td>\n",
       "      <td>delphi-llama2-25.6m</td>\n",
       "      <td>-1.207133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>Is Verb</td>\n",
       "      <td>delphi-llama2-25.6m</td>\n",
       "      <td>-1.545826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>Is Other</td>\n",
       "      <td>delphi-llama2-25.6m</td>\n",
       "      <td>-0.622126</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>144 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     token_group                model  mean_logprob\n",
       "0                    Capitalized   delphi-llama2-100k     -2.046865\n",
       "1                   Is Adjective   delphi-llama2-100k     -3.447071\n",
       "2                  Is Adposition   delphi-llama2-100k     -2.505444\n",
       "3                      Is Adverb   delphi-llama2-100k     -3.041814\n",
       "4                   Is Auxiliary   delphi-llama2-100k     -1.502987\n",
       "..                           ...                  ...           ...\n",
       "139               Is Proper Noun  delphi-llama2-25.6m     -1.283074\n",
       "140               Is Punctuation  delphi-llama2-25.6m     -0.464198\n",
       "141  Is Subordinating conjuction  delphi-llama2-25.6m     -1.207133\n",
       "142                      Is Verb  delphi-llama2-25.6m     -1.545826\n",
       "143                     Is Other  delphi-llama2-25.6m     -0.622126\n",
       "\n",
       "[144 rows x 3 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtgs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Starts with space': set(),\n",
       " 'Capitalized': {68,\n",
       "  69,\n",
       "  70,\n",
       "  71,\n",
       "  72,\n",
       "  73,\n",
       "  74,\n",
       "  75,\n",
       "  76,\n",
       "  77,\n",
       "  78,\n",
       "  79,\n",
       "  80,\n",
       "  81,\n",
       "  82,\n",
       "  83,\n",
       "  84,\n",
       "  85,\n",
       "  86,\n",
       "  87,\n",
       "  88,\n",
       "  89,\n",
       "  90,\n",
       "  91,\n",
       "  92,\n",
       "  93,\n",
       "  270,\n",
       "  282,\n",
       "  297,\n",
       "  309,\n",
       "  311,\n",
       "  316,\n",
       "  328,\n",
       "  330,\n",
       "  334,\n",
       "  340,\n",
       "  341,\n",
       "  349,\n",
       "  357,\n",
       "  367,\n",
       "  385,\n",
       "  387,\n",
       "  388,\n",
       "  396,\n",
       "  424,\n",
       "  432,\n",
       "  489,\n",
       "  496,\n",
       "  497,\n",
       "  504,\n",
       "  517,\n",
       "  523,\n",
       "  532,\n",
       "  539,\n",
       "  556,\n",
       "  563,\n",
       "  570,\n",
       "  596,\n",
       "  617,\n",
       "  636,\n",
       "  639,\n",
       "  650,\n",
       "  652,\n",
       "  659,\n",
       "  664,\n",
       "  692,\n",
       "  699,\n",
       "  718,\n",
       "  724,\n",
       "  732,\n",
       "  734,\n",
       "  746,\n",
       "  750,\n",
       "  753,\n",
       "  768,\n",
       "  773,\n",
       "  775,\n",
       "  787,\n",
       "  798,\n",
       "  806,\n",
       "  810,\n",
       "  821,\n",
       "  840,\n",
       "  864,\n",
       "  873,\n",
       "  895,\n",
       "  928,\n",
       "  930,\n",
       "  953,\n",
       "  959,\n",
       "  978,\n",
       "  979,\n",
       "  982,\n",
       "  983,\n",
       "  1004,\n",
       "  1015,\n",
       "  1022,\n",
       "  1024,\n",
       "  1036,\n",
       "  1037,\n",
       "  1050,\n",
       "  1051,\n",
       "  1059,\n",
       "  1071,\n",
       "  1084,\n",
       "  1085,\n",
       "  1088,\n",
       "  1094,\n",
       "  1100,\n",
       "  1117,\n",
       "  1137,\n",
       "  1141,\n",
       "  1169,\n",
       "  1171,\n",
       "  1176,\n",
       "  1177,\n",
       "  1218,\n",
       "  1221,\n",
       "  1231,\n",
       "  1235,\n",
       "  1245,\n",
       "  1269,\n",
       "  1274,\n",
       "  1281,\n",
       "  1290,\n",
       "  1295,\n",
       "  1299,\n",
       "  1333,\n",
       "  1334,\n",
       "  1365,\n",
       "  1370,\n",
       "  1405,\n",
       "  1413,\n",
       "  1427,\n",
       "  1437,\n",
       "  1490,\n",
       "  1495,\n",
       "  1507,\n",
       "  1515,\n",
       "  1520,\n",
       "  1522,\n",
       "  1524,\n",
       "  1556,\n",
       "  1563,\n",
       "  1566,\n",
       "  1586,\n",
       "  1601,\n",
       "  1606,\n",
       "  1617,\n",
       "  1640,\n",
       "  1648,\n",
       "  1672,\n",
       "  1676,\n",
       "  1712,\n",
       "  1722,\n",
       "  1751,\n",
       "  1761,\n",
       "  1768,\n",
       "  1772,\n",
       "  1836,\n",
       "  1844,\n",
       "  1862,\n",
       "  1865,\n",
       "  1871,\n",
       "  1891,\n",
       "  1899,\n",
       "  1901,\n",
       "  1905,\n",
       "  1924,\n",
       "  1928,\n",
       "  1934,\n",
       "  1941,\n",
       "  1942,\n",
       "  1957,\n",
       "  1959,\n",
       "  1960,\n",
       "  1968,\n",
       "  1980,\n",
       "  1991,\n",
       "  1995,\n",
       "  2009,\n",
       "  2040,\n",
       "  2058,\n",
       "  2082,\n",
       "  2091,\n",
       "  2112,\n",
       "  2132,\n",
       "  2134,\n",
       "  2137,\n",
       "  2152,\n",
       "  2160,\n",
       "  2162,\n",
       "  2169,\n",
       "  2170,\n",
       "  2184,\n",
       "  2194,\n",
       "  2212,\n",
       "  2227,\n",
       "  2245,\n",
       "  2262,\n",
       "  2272,\n",
       "  2289,\n",
       "  2294,\n",
       "  2304,\n",
       "  2319,\n",
       "  2333,\n",
       "  2364,\n",
       "  2370,\n",
       "  2393,\n",
       "  2407,\n",
       "  2423,\n",
       "  2425,\n",
       "  2431,\n",
       "  2437,\n",
       "  2450,\n",
       "  2465,\n",
       "  2478,\n",
       "  2484,\n",
       "  2497,\n",
       "  2500,\n",
       "  2506,\n",
       "  2511,\n",
       "  2533,\n",
       "  2539,\n",
       "  2548,\n",
       "  2551,\n",
       "  2557,\n",
       "  2559,\n",
       "  2572,\n",
       "  2573,\n",
       "  2586,\n",
       "  2594,\n",
       "  2627,\n",
       "  2631,\n",
       "  2671,\n",
       "  2682,\n",
       "  2689,\n",
       "  2692,\n",
       "  2710,\n",
       "  2742,\n",
       "  2744,\n",
       "  2745,\n",
       "  2746,\n",
       "  2749,\n",
       "  2786,\n",
       "  2809,\n",
       "  2844,\n",
       "  2862,\n",
       "  2878,\n",
       "  2884,\n",
       "  2935,\n",
       "  2947,\n",
       "  2952,\n",
       "  2959,\n",
       "  2986,\n",
       "  2998,\n",
       "  3007,\n",
       "  3013,\n",
       "  3017,\n",
       "  3029,\n",
       "  3055,\n",
       "  3069,\n",
       "  3088,\n",
       "  3090,\n",
       "  3100,\n",
       "  3134,\n",
       "  3149,\n",
       "  3203,\n",
       "  3245,\n",
       "  3269,\n",
       "  3290,\n",
       "  3329,\n",
       "  3331,\n",
       "  3372,\n",
       "  3409,\n",
       "  3417,\n",
       "  3439,\n",
       "  3441,\n",
       "  3460,\n",
       "  3467,\n",
       "  3470,\n",
       "  3490,\n",
       "  3491,\n",
       "  3512,\n",
       "  3518,\n",
       "  3526,\n",
       "  3551,\n",
       "  3567,\n",
       "  3588,\n",
       "  3600,\n",
       "  3618,\n",
       "  3641,\n",
       "  3643,\n",
       "  3652,\n",
       "  3679,\n",
       "  3683,\n",
       "  3686,\n",
       "  3687,\n",
       "  3718,\n",
       "  3739,\n",
       "  3759,\n",
       "  3767,\n",
       "  3779,\n",
       "  3785,\n",
       "  3800,\n",
       "  3810,\n",
       "  3822,\n",
       "  3825,\n",
       "  3828,\n",
       "  3870,\n",
       "  3886,\n",
       "  3903,\n",
       "  3909,\n",
       "  3910,\n",
       "  3921,\n",
       "  3926,\n",
       "  3936,\n",
       "  3940,\n",
       "  4003,\n",
       "  4015,\n",
       "  4047,\n",
       "  4050,\n",
       "  4051,\n",
       "  4052,\n",
       "  4053,\n",
       "  4055,\n",
       "  4057,\n",
       "  4059,\n",
       "  4060,\n",
       "  4061,\n",
       "  4064,\n",
       "  4066,\n",
       "  4067,\n",
       "  4068,\n",
       "  4069,\n",
       "  4071,\n",
       "  4072,\n",
       "  4073,\n",
       "  4074,\n",
       "  4075,\n",
       "  4076,\n",
       "  4079,\n",
       "  4080,\n",
       "  4081,\n",
       "  4084,\n",
       "  4085},\n",
       " 'Is Adjective': {319,\n",
       "  350,\n",
       "  380,\n",
       "  393,\n",
       "  394,\n",
       "  418,\n",
       "  443,\n",
       "  495,\n",
       "  501,\n",
       "  516,\n",
       "  520,\n",
       "  544,\n",
       "  552,\n",
       "  559,\n",
       "  560,\n",
       "  607,\n",
       "  626,\n",
       "  630,\n",
       "  663,\n",
       "  675,\n",
       "  689,\n",
       "  725,\n",
       "  727,\n",
       "  729,\n",
       "  733,\n",
       "  745,\n",
       "  757,\n",
       "  763,\n",
       "  780,\n",
       "  826,\n",
       "  835,\n",
       "  837,\n",
       "  843,\n",
       "  852,\n",
       "  862,\n",
       "  875,\n",
       "  876,\n",
       "  886,\n",
       "  887,\n",
       "  892,\n",
       "  894,\n",
       "  904,\n",
       "  910,\n",
       "  916,\n",
       "  921,\n",
       "  949,\n",
       "  955,\n",
       "  964,\n",
       "  971,\n",
       "  991,\n",
       "  992,\n",
       "  995,\n",
       "  1023,\n",
       "  1025,\n",
       "  1029,\n",
       "  1030,\n",
       "  1038,\n",
       "  1057,\n",
       "  1104,\n",
       "  1125,\n",
       "  1146,\n",
       "  1166,\n",
       "  1182,\n",
       "  1188,\n",
       "  1195,\n",
       "  1196,\n",
       "  1209,\n",
       "  1211,\n",
       "  1212,\n",
       "  1213,\n",
       "  1220,\n",
       "  1255,\n",
       "  1264,\n",
       "  1276,\n",
       "  1282,\n",
       "  1303,\n",
       "  1308,\n",
       "  1316,\n",
       "  1318,\n",
       "  1322,\n",
       "  1323,\n",
       "  1330,\n",
       "  1335,\n",
       "  1367,\n",
       "  1379,\n",
       "  1382,\n",
       "  1383,\n",
       "  1384,\n",
       "  1392,\n",
       "  1399,\n",
       "  1411,\n",
       "  1423,\n",
       "  1428,\n",
       "  1430,\n",
       "  1435,\n",
       "  1440,\n",
       "  1449,\n",
       "  1489,\n",
       "  1493,\n",
       "  1516,\n",
       "  1521,\n",
       "  1525,\n",
       "  1534,\n",
       "  1560,\n",
       "  1575,\n",
       "  1583,\n",
       "  1587,\n",
       "  1588,\n",
       "  1595,\n",
       "  1596,\n",
       "  1613,\n",
       "  1632,\n",
       "  1643,\n",
       "  1670,\n",
       "  1678,\n",
       "  1679,\n",
       "  1685,\n",
       "  1687,\n",
       "  1710,\n",
       "  1724,\n",
       "  1726,\n",
       "  1745,\n",
       "  1752,\n",
       "  1755,\n",
       "  1763,\n",
       "  1774,\n",
       "  1793,\n",
       "  1796,\n",
       "  1797,\n",
       "  1812,\n",
       "  1814,\n",
       "  1818,\n",
       "  1820,\n",
       "  1850,\n",
       "  1857,\n",
       "  1867,\n",
       "  1881,\n",
       "  1886,\n",
       "  1907,\n",
       "  1912,\n",
       "  1965,\n",
       "  1980,\n",
       "  1998,\n",
       "  2002,\n",
       "  2006,\n",
       "  2011,\n",
       "  2014,\n",
       "  2019,\n",
       "  2028,\n",
       "  2029,\n",
       "  2033,\n",
       "  2038,\n",
       "  2041,\n",
       "  2044,\n",
       "  2048,\n",
       "  2052,\n",
       "  2060,\n",
       "  2062,\n",
       "  2068,\n",
       "  2085,\n",
       "  2088,\n",
       "  2094,\n",
       "  2098,\n",
       "  2103,\n",
       "  2124,\n",
       "  2131,\n",
       "  2133,\n",
       "  2148,\n",
       "  2157,\n",
       "  2168,\n",
       "  2174,\n",
       "  2177,\n",
       "  2179,\n",
       "  2187,\n",
       "  2193,\n",
       "  2196,\n",
       "  2197,\n",
       "  2210,\n",
       "  2211,\n",
       "  2228,\n",
       "  2229,\n",
       "  2265,\n",
       "  2267,\n",
       "  2280,\n",
       "  2282,\n",
       "  2283,\n",
       "  2291,\n",
       "  2315,\n",
       "  2317,\n",
       "  2320,\n",
       "  2330,\n",
       "  2335,\n",
       "  2343,\n",
       "  2353,\n",
       "  2356,\n",
       "  2362,\n",
       "  2368,\n",
       "  2374,\n",
       "  2375,\n",
       "  2388,\n",
       "  2418,\n",
       "  2428,\n",
       "  2447,\n",
       "  2452,\n",
       "  2457,\n",
       "  2472,\n",
       "  2477,\n",
       "  2486,\n",
       "  2498,\n",
       "  2505,\n",
       "  2507,\n",
       "  2522,\n",
       "  2543,\n",
       "  2547,\n",
       "  2556,\n",
       "  2565,\n",
       "  2567,\n",
       "  2571,\n",
       "  2578,\n",
       "  2581,\n",
       "  2582,\n",
       "  2588,\n",
       "  2590,\n",
       "  2592,\n",
       "  2595,\n",
       "  2597,\n",
       "  2600,\n",
       "  2604,\n",
       "  2614,\n",
       "  2628,\n",
       "  2652,\n",
       "  2661,\n",
       "  2663,\n",
       "  2670,\n",
       "  2678,\n",
       "  2679,\n",
       "  2684,\n",
       "  2685,\n",
       "  2695,\n",
       "  2696,\n",
       "  2697,\n",
       "  2700,\n",
       "  2708,\n",
       "  2723,\n",
       "  2724,\n",
       "  2728,\n",
       "  2736,\n",
       "  2737,\n",
       "  2739,\n",
       "  2748,\n",
       "  2751,\n",
       "  2754,\n",
       "  2759,\n",
       "  2764,\n",
       "  2767,\n",
       "  2772,\n",
       "  2774,\n",
       "  2775,\n",
       "  2779,\n",
       "  2785,\n",
       "  2789,\n",
       "  2790,\n",
       "  2797,\n",
       "  2816,\n",
       "  2819,\n",
       "  2822,\n",
       "  2828,\n",
       "  2830,\n",
       "  2838,\n",
       "  2842,\n",
       "  2844,\n",
       "  2848,\n",
       "  2850,\n",
       "  2863,\n",
       "  2865,\n",
       "  2880,\n",
       "  2883,\n",
       "  2889,\n",
       "  2891,\n",
       "  2894,\n",
       "  2900,\n",
       "  2901,\n",
       "  2909,\n",
       "  2911,\n",
       "  2917,\n",
       "  2918,\n",
       "  2930,\n",
       "  2934,\n",
       "  2936,\n",
       "  2950,\n",
       "  2965,\n",
       "  2970,\n",
       "  2978,\n",
       "  2982,\n",
       "  2994,\n",
       "  3000,\n",
       "  3007,\n",
       "  3010,\n",
       "  3011,\n",
       "  3015,\n",
       "  3020,\n",
       "  3021,\n",
       "  3023,\n",
       "  3037,\n",
       "  3040,\n",
       "  3045,\n",
       "  3049,\n",
       "  3056,\n",
       "  3062,\n",
       "  3066,\n",
       "  3073,\n",
       "  3081,\n",
       "  3082,\n",
       "  3090,\n",
       "  3109,\n",
       "  3119,\n",
       "  3124,\n",
       "  3129,\n",
       "  3144,\n",
       "  3148,\n",
       "  3156,\n",
       "  3166,\n",
       "  3167,\n",
       "  3169,\n",
       "  3172,\n",
       "  3174,\n",
       "  3193,\n",
       "  3206,\n",
       "  3212,\n",
       "  3213,\n",
       "  3224,\n",
       "  3227,\n",
       "  3235,\n",
       "  3240,\n",
       "  3243,\n",
       "  3250,\n",
       "  3285,\n",
       "  3289,\n",
       "  3294,\n",
       "  3302,\n",
       "  3309,\n",
       "  3314,\n",
       "  3326,\n",
       "  3340,\n",
       "  3347,\n",
       "  3352,\n",
       "  3356,\n",
       "  3357,\n",
       "  3362,\n",
       "  3368,\n",
       "  3410,\n",
       "  3411,\n",
       "  3422,\n",
       "  3438,\n",
       "  3455,\n",
       "  3457,\n",
       "  3499,\n",
       "  3500,\n",
       "  3518,\n",
       "  3522,\n",
       "  3541,\n",
       "  3562,\n",
       "  3568,\n",
       "  3596,\n",
       "  3611,\n",
       "  3613,\n",
       "  3637,\n",
       "  3638,\n",
       "  3663,\n",
       "  3679,\n",
       "  3695,\n",
       "  3710,\n",
       "  3776,\n",
       "  3809,\n",
       "  3813,\n",
       "  3839,\n",
       "  3852,\n",
       "  3864,\n",
       "  3870,\n",
       "  3915,\n",
       "  3927,\n",
       "  3942,\n",
       "  3980,\n",
       "  3982,\n",
       "  3991,\n",
       "  4011,\n",
       "  4017,\n",
       "  4021},\n",
       " 'Is Adposition': {273,\n",
       "  275,\n",
       "  293,\n",
       "  300,\n",
       "  317,\n",
       "  332,\n",
       "  334,\n",
       "  359,\n",
       "  375,\n",
       "  391,\n",
       "  449,\n",
       "  450,\n",
       "  455,\n",
       "  581,\n",
       "  624,\n",
       "  637,\n",
       "  667,\n",
       "  713,\n",
       "  775,\n",
       "  777,\n",
       "  810,\n",
       "  821,\n",
       "  854,\n",
       "  879,\n",
       "  888,\n",
       "  969,\n",
       "  979,\n",
       "  1004,\n",
       "  1041,\n",
       "  1086,\n",
       "  1256,\n",
       "  1326,\n",
       "  1427,\n",
       "  1757,\n",
       "  1871,\n",
       "  2132,\n",
       "  2184,\n",
       "  3739,\n",
       "  3819},\n",
       " 'Is Adverb': {353,\n",
       "  372,\n",
       "  381,\n",
       "  395,\n",
       "  406,\n",
       "  414,\n",
       "  425,\n",
       "  457,\n",
       "  462,\n",
       "  486,\n",
       "  515,\n",
       "  537,\n",
       "  575,\n",
       "  599,\n",
       "  604,\n",
       "  635,\n",
       "  636,\n",
       "  681,\n",
       "  698,\n",
       "  702,\n",
       "  718,\n",
       "  739,\n",
       "  770,\n",
       "  772,\n",
       "  791,\n",
       "  799,\n",
       "  805,\n",
       "  811,\n",
       "  824,\n",
       "  853,\n",
       "  872,\n",
       "  877,\n",
       "  897,\n",
       "  923,\n",
       "  926,\n",
       "  934,\n",
       "  959,\n",
       "  976,\n",
       "  981,\n",
       "  1048,\n",
       "  1052,\n",
       "  1055,\n",
       "  1056,\n",
       "  1076,\n",
       "  1164,\n",
       "  1237,\n",
       "  1293,\n",
       "  1352,\n",
       "  1360,\n",
       "  1405,\n",
       "  1413,\n",
       "  1414,\n",
       "  1437,\n",
       "  1445,\n",
       "  1461,\n",
       "  1463,\n",
       "  1475,\n",
       "  1490,\n",
       "  1524,\n",
       "  1526,\n",
       "  1539,\n",
       "  1561,\n",
       "  1615,\n",
       "  1635,\n",
       "  1642,\n",
       "  1666,\n",
       "  1676,\n",
       "  1702,\n",
       "  1722,\n",
       "  1727,\n",
       "  1815,\n",
       "  1862,\n",
       "  1882,\n",
       "  1977,\n",
       "  2043,\n",
       "  2053,\n",
       "  2058,\n",
       "  2117,\n",
       "  2143,\n",
       "  2219,\n",
       "  2224,\n",
       "  2244,\n",
       "  2248,\n",
       "  2336,\n",
       "  2339,\n",
       "  2340,\n",
       "  2345,\n",
       "  2380,\n",
       "  2392,\n",
       "  2509,\n",
       "  2594,\n",
       "  2630,\n",
       "  2683,\n",
       "  2817,\n",
       "  2862,\n",
       "  2884,\n",
       "  3038,\n",
       "  3134,\n",
       "  3358,\n",
       "  3431,\n",
       "  3437,\n",
       "  3463,\n",
       "  3533,\n",
       "  3615,\n",
       "  3661,\n",
       "  3843,\n",
       "  3868,\n",
       "  3882,\n",
       "  3902,\n",
       "  3999,\n",
       "  4003,\n",
       "  4008,\n",
       "  4015},\n",
       " 'Is Auxiliary': {286,\n",
       "  289,\n",
       "  324,\n",
       "  410,\n",
       "  433,\n",
       "  467,\n",
       "  484,\n",
       "  518,\n",
       "  939,\n",
       "  998,\n",
       "  1009,\n",
       "  1391,\n",
       "  2082,\n",
       "  2431,\n",
       "  2986,\n",
       "  3846,\n",
       "  3948},\n",
       " 'Is Coordinating conjuction': {41,\n",
       "  269,\n",
       "  306,\n",
       "  413,\n",
       "  489,\n",
       "  692,\n",
       "  776,\n",
       "  790,\n",
       "  1844,\n",
       "  3667},\n",
       " 'Is Determiner': set(),\n",
       " 'Is Interjunction': {39,\n",
       "  82,\n",
       "  100,\n",
       "  104,\n",
       "  107,\n",
       "  112,\n",
       "  114,\n",
       "  123,\n",
       "  124,\n",
       "  261,\n",
       "  265,\n",
       "  271,\n",
       "  277,\n",
       "  283,\n",
       "  284,\n",
       "  285,\n",
       "  287,\n",
       "  291,\n",
       "  295,\n",
       "  296,\n",
       "  298,\n",
       "  302,\n",
       "  303,\n",
       "  308,\n",
       "  310,\n",
       "  312,\n",
       "  315,\n",
       "  320,\n",
       "  328,\n",
       "  329,\n",
       "  335,\n",
       "  336,\n",
       "  337,\n",
       "  348,\n",
       "  351,\n",
       "  352,\n",
       "  383,\n",
       "  426,\n",
       "  427,\n",
       "  432,\n",
       "  436,\n",
       "  437,\n",
       "  441,\n",
       "  442,\n",
       "  459,\n",
       "  463,\n",
       "  481,\n",
       "  488,\n",
       "  493,\n",
       "  508,\n",
       "  519,\n",
       "  526,\n",
       "  528,\n",
       "  547,\n",
       "  569,\n",
       "  573,\n",
       "  574,\n",
       "  578,\n",
       "  588,\n",
       "  591,\n",
       "  592,\n",
       "  593,\n",
       "  597,\n",
       "  603,\n",
       "  613,\n",
       "  619,\n",
       "  621,\n",
       "  629,\n",
       "  651,\n",
       "  670,\n",
       "  676,\n",
       "  677,\n",
       "  688,\n",
       "  691,\n",
       "  696,\n",
       "  700,\n",
       "  708,\n",
       "  710,\n",
       "  722,\n",
       "  726,\n",
       "  732,\n",
       "  737,\n",
       "  751,\n",
       "  771,\n",
       "  778,\n",
       "  779,\n",
       "  784,\n",
       "  794,\n",
       "  808,\n",
       "  813,\n",
       "  825,\n",
       "  834,\n",
       "  839,\n",
       "  844,\n",
       "  859,\n",
       "  865,\n",
       "  867,\n",
       "  912,\n",
       "  924,\n",
       "  930,\n",
       "  933,\n",
       "  935,\n",
       "  936,\n",
       "  941,\n",
       "  947,\n",
       "  951,\n",
       "  954,\n",
       "  963,\n",
       "  968,\n",
       "  974,\n",
       "  988,\n",
       "  1008,\n",
       "  1011,\n",
       "  1016,\n",
       "  1033,\n",
       "  1042,\n",
       "  1047,\n",
       "  1088,\n",
       "  1094,\n",
       "  1095,\n",
       "  1111,\n",
       "  1118,\n",
       "  1120,\n",
       "  1133,\n",
       "  1138,\n",
       "  1169,\n",
       "  1183,\n",
       "  1190,\n",
       "  1193,\n",
       "  1199,\n",
       "  1203,\n",
       "  1210,\n",
       "  1221,\n",
       "  1225,\n",
       "  1234,\n",
       "  1246,\n",
       "  1253,\n",
       "  1265,\n",
       "  1275,\n",
       "  1278,\n",
       "  1324,\n",
       "  1336,\n",
       "  1339,\n",
       "  1344,\n",
       "  1355,\n",
       "  1377,\n",
       "  1380,\n",
       "  1386,\n",
       "  1390,\n",
       "  1406,\n",
       "  1479,\n",
       "  1495,\n",
       "  1499,\n",
       "  1507,\n",
       "  1512,\n",
       "  1536,\n",
       "  1571,\n",
       "  1574,\n",
       "  1591,\n",
       "  1604,\n",
       "  1611,\n",
       "  1626,\n",
       "  1629,\n",
       "  1651,\n",
       "  1656,\n",
       "  1664,\n",
       "  1743,\n",
       "  1782,\n",
       "  1784,\n",
       "  1787,\n",
       "  1803,\n",
       "  1825,\n",
       "  1835,\n",
       "  1868,\n",
       "  1889,\n",
       "  1895,\n",
       "  1901,\n",
       "  1958,\n",
       "  1959,\n",
       "  1985,\n",
       "  1986,\n",
       "  2005,\n",
       "  2027,\n",
       "  2032,\n",
       "  2039,\n",
       "  2057,\n",
       "  2061,\n",
       "  2086,\n",
       "  2110,\n",
       "  2134,\n",
       "  2137,\n",
       "  2160,\n",
       "  2171,\n",
       "  2208,\n",
       "  2216,\n",
       "  2222,\n",
       "  2255,\n",
       "  2260,\n",
       "  2275,\n",
       "  2281,\n",
       "  2310,\n",
       "  2327,\n",
       "  2344,\n",
       "  2347,\n",
       "  2355,\n",
       "  2391,\n",
       "  2395,\n",
       "  2413,\n",
       "  2427,\n",
       "  2434,\n",
       "  2441,\n",
       "  2454,\n",
       "  2456,\n",
       "  2491,\n",
       "  2495,\n",
       "  2502,\n",
       "  2513,\n",
       "  2514,\n",
       "  2517,\n",
       "  2533,\n",
       "  2551,\n",
       "  2589,\n",
       "  2617,\n",
       "  2621,\n",
       "  2639,\n",
       "  2677,\n",
       "  2694,\n",
       "  2711,\n",
       "  2713,\n",
       "  2731,\n",
       "  2750,\n",
       "  2833,\n",
       "  2840,\n",
       "  2895,\n",
       "  2935,\n",
       "  2977,\n",
       "  2999,\n",
       "  3006,\n",
       "  3029,\n",
       "  3048,\n",
       "  3058,\n",
       "  3086,\n",
       "  3110,\n",
       "  3114,\n",
       "  3136,\n",
       "  3185,\n",
       "  3225,\n",
       "  3266,\n",
       "  3319,\n",
       "  3320,\n",
       "  3393,\n",
       "  3428,\n",
       "  3436,\n",
       "  3439,\n",
       "  3482,\n",
       "  3495,\n",
       "  3556,\n",
       "  3569,\n",
       "  3579,\n",
       "  3601,\n",
       "  3628,\n",
       "  3640,\n",
       "  3656,\n",
       "  3670,\n",
       "  3673,\n",
       "  3681,\n",
       "  3684,\n",
       "  3691,\n",
       "  3711,\n",
       "  3767,\n",
       "  3798,\n",
       "  3810,\n",
       "  3835,\n",
       "  3847,\n",
       "  3862,\n",
       "  3895,\n",
       "  3917,\n",
       "  3959,\n",
       "  4024,\n",
       "  4025,\n",
       "  4027,\n",
       "  4028,\n",
       "  4035,\n",
       "  4036,\n",
       "  4053,\n",
       "  4058,\n",
       "  4095},\n",
       " 'Is Noun': {29,\n",
       "  68,\n",
       "  69,\n",
       "  70,\n",
       "  71,\n",
       "  72,\n",
       "  73,\n",
       "  74,\n",
       "  75,\n",
       "  78,\n",
       "  79,\n",
       "  80,\n",
       "  81,\n",
       "  83,\n",
       "  84,\n",
       "  85,\n",
       "  87,\n",
       "  88,\n",
       "  89,\n",
       "  90,\n",
       "  91,\n",
       "  92,\n",
       "  93,\n",
       "  101,\n",
       "  102,\n",
       "  103,\n",
       "  105,\n",
       "  106,\n",
       "  109,\n",
       "  110,\n",
       "  111,\n",
       "  113,\n",
       "  115,\n",
       "  116,\n",
       "  117,\n",
       "  118,\n",
       "  119,\n",
       "  121,\n",
       "  259,\n",
       "  262,\n",
       "  267,\n",
       "  270,\n",
       "  272,\n",
       "  278,\n",
       "  279,\n",
       "  280,\n",
       "  281,\n",
       "  290,\n",
       "  299,\n",
       "  309,\n",
       "  314,\n",
       "  331,\n",
       "  333,\n",
       "  339,\n",
       "  346,\n",
       "  349,\n",
       "  355,\n",
       "  357,\n",
       "  358,\n",
       "  363,\n",
       "  367,\n",
       "  376,\n",
       "  388,\n",
       "  390,\n",
       "  400,\n",
       "  403,\n",
       "  404,\n",
       "  415,\n",
       "  420,\n",
       "  439,\n",
       "  444,\n",
       "  452,\n",
       "  460,\n",
       "  466,\n",
       "  472,\n",
       "  476,\n",
       "  478,\n",
       "  479,\n",
       "  496,\n",
       "  498,\n",
       "  500,\n",
       "  503,\n",
       "  506,\n",
       "  510,\n",
       "  511,\n",
       "  513,\n",
       "  521,\n",
       "  525,\n",
       "  527,\n",
       "  529,\n",
       "  548,\n",
       "  556,\n",
       "  562,\n",
       "  568,\n",
       "  576,\n",
       "  585,\n",
       "  602,\n",
       "  605,\n",
       "  608,\n",
       "  610,\n",
       "  611,\n",
       "  614,\n",
       "  622,\n",
       "  639,\n",
       "  640,\n",
       "  647,\n",
       "  648,\n",
       "  652,\n",
       "  654,\n",
       "  666,\n",
       "  671,\n",
       "  678,\n",
       "  679,\n",
       "  685,\n",
       "  690,\n",
       "  694,\n",
       "  695,\n",
       "  699,\n",
       "  707,\n",
       "  715,\n",
       "  719,\n",
       "  720,\n",
       "  736,\n",
       "  741,\n",
       "  742,\n",
       "  748,\n",
       "  753,\n",
       "  755,\n",
       "  759,\n",
       "  762,\n",
       "  765,\n",
       "  785,\n",
       "  786,\n",
       "  792,\n",
       "  793,\n",
       "  796,\n",
       "  802,\n",
       "  803,\n",
       "  804,\n",
       "  807,\n",
       "  814,\n",
       "  816,\n",
       "  823,\n",
       "  830,\n",
       "  831,\n",
       "  836,\n",
       "  848,\n",
       "  849,\n",
       "  850,\n",
       "  856,\n",
       "  858,\n",
       "  869,\n",
       "  873,\n",
       "  874,\n",
       "  878,\n",
       "  882,\n",
       "  883,\n",
       "  885,\n",
       "  889,\n",
       "  901,\n",
       "  905,\n",
       "  908,\n",
       "  919,\n",
       "  920,\n",
       "  927,\n",
       "  928,\n",
       "  931,\n",
       "  932,\n",
       "  940,\n",
       "  942,\n",
       "  946,\n",
       "  950,\n",
       "  956,\n",
       "  962,\n",
       "  966,\n",
       "  970,\n",
       "  972,\n",
       "  973,\n",
       "  982,\n",
       "  985,\n",
       "  986,\n",
       "  990,\n",
       "  997,\n",
       "  1000,\n",
       "  1003,\n",
       "  1005,\n",
       "  1007,\n",
       "  1015,\n",
       "  1020,\n",
       "  1021,\n",
       "  1028,\n",
       "  1035,\n",
       "  1040,\n",
       "  1060,\n",
       "  1061,\n",
       "  1065,\n",
       "  1067,\n",
       "  1075,\n",
       "  1077,\n",
       "  1079,\n",
       "  1085,\n",
       "  1091,\n",
       "  1098,\n",
       "  1099,\n",
       "  1101,\n",
       "  1102,\n",
       "  1103,\n",
       "  1109,\n",
       "  1110,\n",
       "  1113,\n",
       "  1115,\n",
       "  1128,\n",
       "  1129,\n",
       "  1131,\n",
       "  1136,\n",
       "  1140,\n",
       "  1144,\n",
       "  1145,\n",
       "  1147,\n",
       "  1149,\n",
       "  1157,\n",
       "  1161,\n",
       "  1165,\n",
       "  1170,\n",
       "  1171,\n",
       "  1172,\n",
       "  1173,\n",
       "  1174,\n",
       "  1178,\n",
       "  1179,\n",
       "  1180,\n",
       "  1184,\n",
       "  1185,\n",
       "  1187,\n",
       "  1189,\n",
       "  1192,\n",
       "  1200,\n",
       "  1201,\n",
       "  1205,\n",
       "  1206,\n",
       "  1214,\n",
       "  1215,\n",
       "  1219,\n",
       "  1223,\n",
       "  1224,\n",
       "  1232,\n",
       "  1233,\n",
       "  1242,\n",
       "  1247,\n",
       "  1250,\n",
       "  1259,\n",
       "  1261,\n",
       "  1262,\n",
       "  1263,\n",
       "  1266,\n",
       "  1267,\n",
       "  1271,\n",
       "  1272,\n",
       "  1273,\n",
       "  1277,\n",
       "  1280,\n",
       "  1284,\n",
       "  1288,\n",
       "  1292,\n",
       "  1298,\n",
       "  1304,\n",
       "  1305,\n",
       "  1307,\n",
       "  1312,\n",
       "  1313,\n",
       "  1314,\n",
       "  1315,\n",
       "  1327,\n",
       "  1328,\n",
       "  1338,\n",
       "  1340,\n",
       "  1343,\n",
       "  1349,\n",
       "  1351,\n",
       "  1353,\n",
       "  1359,\n",
       "  1361,\n",
       "  1363,\n",
       "  1368,\n",
       "  1371,\n",
       "  1373,\n",
       "  1375,\n",
       "  1387,\n",
       "  1389,\n",
       "  1395,\n",
       "  1396,\n",
       "  1398,\n",
       "  1403,\n",
       "  1409,\n",
       "  1410,\n",
       "  1416,\n",
       "  1417,\n",
       "  1418,\n",
       "  1421,\n",
       "  1424,\n",
       "  1433,\n",
       "  1441,\n",
       "  1442,\n",
       "  1454,\n",
       "  1455,\n",
       "  1456,\n",
       "  1458,\n",
       "  1462,\n",
       "  1464,\n",
       "  1466,\n",
       "  1467,\n",
       "  1468,\n",
       "  1471,\n",
       "  1476,\n",
       "  1477,\n",
       "  1478,\n",
       "  1480,\n",
       "  1486,\n",
       "  1487,\n",
       "  1492,\n",
       "  1498,\n",
       "  1501,\n",
       "  1505,\n",
       "  1506,\n",
       "  1508,\n",
       "  1513,\n",
       "  1517,\n",
       "  1518,\n",
       "  1523,\n",
       "  1528,\n",
       "  1529,\n",
       "  1530,\n",
       "  1531,\n",
       "  1532,\n",
       "  1533,\n",
       "  1535,\n",
       "  1540,\n",
       "  1544,\n",
       "  1545,\n",
       "  1549,\n",
       "  1550,\n",
       "  1552,\n",
       "  1554,\n",
       "  1555,\n",
       "  1557,\n",
       "  1558,\n",
       "  1559,\n",
       "  1562,\n",
       "  1570,\n",
       "  1579,\n",
       "  1580,\n",
       "  1582,\n",
       "  1589,\n",
       "  1592,\n",
       "  1594,\n",
       "  1600,\n",
       "  1603,\n",
       "  1605,\n",
       "  1610,\n",
       "  1619,\n",
       "  1621,\n",
       "  1623,\n",
       "  1624,\n",
       "  1625,\n",
       "  1633,\n",
       "  1634,\n",
       "  1638,\n",
       "  1645,\n",
       "  1649,\n",
       "  1652,\n",
       "  1653,\n",
       "  1661,\n",
       "  1662,\n",
       "  1665,\n",
       "  1668,\n",
       "  1671,\n",
       "  1672,\n",
       "  1674,\n",
       "  1677,\n",
       "  1680,\n",
       "  1681,\n",
       "  1683,\n",
       "  1689,\n",
       "  1690,\n",
       "  1691,\n",
       "  1693,\n",
       "  1695,\n",
       "  1703,\n",
       "  1705,\n",
       "  1709,\n",
       "  1712,\n",
       "  1714,\n",
       "  1716,\n",
       "  1728,\n",
       "  1729,\n",
       "  1733,\n",
       "  1738,\n",
       "  1740,\n",
       "  1741,\n",
       "  1744,\n",
       "  1746,\n",
       "  1750,\n",
       "  1753,\n",
       "  1754,\n",
       "  1756,\n",
       "  1760,\n",
       "  1762,\n",
       "  1767,\n",
       "  1770,\n",
       "  1771,\n",
       "  1775,\n",
       "  1776,\n",
       "  1779,\n",
       "  1780,\n",
       "  1781,\n",
       "  1785,\n",
       "  1788,\n",
       "  1790,\n",
       "  1794,\n",
       "  1798,\n",
       "  1799,\n",
       "  1804,\n",
       "  1806,\n",
       "  1808,\n",
       "  1809,\n",
       "  1811,\n",
       "  1819,\n",
       "  1821,\n",
       "  1822,\n",
       "  1824,\n",
       "  1826,\n",
       "  1828,\n",
       "  1829,\n",
       "  1832,\n",
       "  1834,\n",
       "  1837,\n",
       "  1841,\n",
       "  1842,\n",
       "  1843,\n",
       "  1847,\n",
       "  1848,\n",
       "  1849,\n",
       "  1854,\n",
       "  1855,\n",
       "  1858,\n",
       "  1860,\n",
       "  1861,\n",
       "  1870,\n",
       "  1872,\n",
       "  1873,\n",
       "  1876,\n",
       "  1877,\n",
       "  1878,\n",
       "  1885,\n",
       "  1890,\n",
       "  1892,\n",
       "  1909,\n",
       "  1914,\n",
       "  1918,\n",
       "  1919,\n",
       "  1923,\n",
       "  1932,\n",
       "  1935,\n",
       "  1936,\n",
       "  1937,\n",
       "  1938,\n",
       "  1940,\n",
       "  1944,\n",
       "  1946,\n",
       "  1947,\n",
       "  1949,\n",
       "  1950,\n",
       "  1951,\n",
       "  1954,\n",
       "  1962,\n",
       "  1963,\n",
       "  1964,\n",
       "  1967,\n",
       "  1969,\n",
       "  1971,\n",
       "  1972,\n",
       "  1975,\n",
       "  1976,\n",
       "  1979,\n",
       "  1981,\n",
       "  1982,\n",
       "  1984,\n",
       "  1987,\n",
       "  1989,\n",
       "  1990,\n",
       "  1992,\n",
       "  1994,\n",
       "  1997,\n",
       "  2000,\n",
       "  2001,\n",
       "  2008,\n",
       "  2015,\n",
       "  2018,\n",
       "  2020,\n",
       "  2021,\n",
       "  2022,\n",
       "  2023,\n",
       "  2031,\n",
       "  2034,\n",
       "  2035,\n",
       "  2036,\n",
       "  2042,\n",
       "  2045,\n",
       "  2049,\n",
       "  2051,\n",
       "  2055,\n",
       "  2056,\n",
       "  2059,\n",
       "  2063,\n",
       "  2065,\n",
       "  2069,\n",
       "  2070,\n",
       "  2071,\n",
       "  2072,\n",
       "  2073,\n",
       "  2077,\n",
       "  2079,\n",
       "  2081,\n",
       "  2089,\n",
       "  2093,\n",
       "  2101,\n",
       "  2105,\n",
       "  2106,\n",
       "  2109,\n",
       "  2111,\n",
       "  2119,\n",
       "  2125,\n",
       "  2127,\n",
       "  2128,\n",
       "  2129,\n",
       "  2139,\n",
       "  2140,\n",
       "  2146,\n",
       "  2149,\n",
       "  2151,\n",
       "  2153,\n",
       "  2156,\n",
       "  2158,\n",
       "  2159,\n",
       "  2163,\n",
       "  2165,\n",
       "  2167,\n",
       "  2175,\n",
       "  2176,\n",
       "  2178,\n",
       "  2180,\n",
       "  2183,\n",
       "  2190,\n",
       "  2191,\n",
       "  2199,\n",
       "  2201,\n",
       "  2202,\n",
       "  2203,\n",
       "  2214,\n",
       "  2221,\n",
       "  2223,\n",
       "  2230,\n",
       "  2234,\n",
       "  2236,\n",
       "  2241,\n",
       "  2242,\n",
       "  2246,\n",
       "  2253,\n",
       "  2254,\n",
       "  2256,\n",
       "  2259,\n",
       "  2264,\n",
       "  2268,\n",
       "  2271,\n",
       "  2273,\n",
       "  2274,\n",
       "  2279,\n",
       "  2284,\n",
       "  2286,\n",
       "  2288,\n",
       "  2290,\n",
       "  2292,\n",
       "  2295,\n",
       "  2299,\n",
       "  2300,\n",
       "  2303,\n",
       "  2305,\n",
       "  2306,\n",
       "  2307,\n",
       "  2308,\n",
       "  2309,\n",
       "  2313,\n",
       "  2318,\n",
       "  2321,\n",
       "  2322,\n",
       "  2323,\n",
       "  2325,\n",
       "  2326,\n",
       "  2337,\n",
       "  2338,\n",
       "  2341,\n",
       "  2342,\n",
       "  2346,\n",
       "  2354,\n",
       "  2361,\n",
       "  2364,\n",
       "  2369,\n",
       "  2370,\n",
       "  2373,\n",
       "  2379,\n",
       "  2381,\n",
       "  2384,\n",
       "  2385,\n",
       "  2387,\n",
       "  2390,\n",
       "  2397,\n",
       "  2398,\n",
       "  2402,\n",
       "  2404,\n",
       "  2406,\n",
       "  2408,\n",
       "  2412,\n",
       "  2417,\n",
       "  2420,\n",
       "  2421,\n",
       "  2430,\n",
       "  2435,\n",
       "  2436,\n",
       "  2449,\n",
       "  2451,\n",
       "  2453,\n",
       "  2460,\n",
       "  2461,\n",
       "  2465,\n",
       "  2466,\n",
       "  2467,\n",
       "  2471,\n",
       "  2474,\n",
       "  2476,\n",
       "  2479,\n",
       "  2480,\n",
       "  2481,\n",
       "  2485,\n",
       "  2487,\n",
       "  2489,\n",
       "  2490,\n",
       "  2493,\n",
       "  2500,\n",
       "  2503,\n",
       "  2504,\n",
       "  2510,\n",
       "  2515,\n",
       "  2516,\n",
       "  2521,\n",
       "  2527,\n",
       "  2529,\n",
       "  2531,\n",
       "  2532,\n",
       "  2534,\n",
       "  2535,\n",
       "  2536,\n",
       "  2541,\n",
       "  2542,\n",
       "  2550,\n",
       "  2552,\n",
       "  2561,\n",
       "  2562,\n",
       "  2563,\n",
       "  2569,\n",
       "  2570,\n",
       "  2572,\n",
       "  2574,\n",
       "  2577,\n",
       "  2579,\n",
       "  2583,\n",
       "  2591,\n",
       "  2596,\n",
       "  2599,\n",
       "  2602,\n",
       "  2603,\n",
       "  2605,\n",
       "  2611,\n",
       "  2612,\n",
       "  2613,\n",
       "  2615,\n",
       "  2616,\n",
       "  2618,\n",
       "  2619,\n",
       "  2622,\n",
       "  2623,\n",
       "  2625,\n",
       "  2626,\n",
       "  2633,\n",
       "  2634,\n",
       "  2636,\n",
       "  2638,\n",
       "  2646,\n",
       "  2648,\n",
       "  2653,\n",
       "  2654,\n",
       "  2656,\n",
       "  2662,\n",
       "  2666,\n",
       "  2668,\n",
       "  2672,\n",
       "  2675,\n",
       "  2686,\n",
       "  2687,\n",
       "  2690,\n",
       "  2691,\n",
       "  2693,\n",
       "  2698,\n",
       "  2699,\n",
       "  2701,\n",
       "  2704,\n",
       "  2707,\n",
       "  2709,\n",
       "  2712,\n",
       "  2714,\n",
       "  2716,\n",
       "  2718,\n",
       "  2721,\n",
       "  2726,\n",
       "  2729,\n",
       "  2732,\n",
       "  2733,\n",
       "  2740,\n",
       "  2752,\n",
       "  2756,\n",
       "  2757,\n",
       "  2762,\n",
       "  2769,\n",
       "  2771,\n",
       "  2773,\n",
       "  2777,\n",
       "  2783,\n",
       "  2784,\n",
       "  2787,\n",
       "  2788,\n",
       "  2794,\n",
       "  2796,\n",
       "  2799,\n",
       "  2804,\n",
       "  2805,\n",
       "  2806,\n",
       "  2810,\n",
       "  2815,\n",
       "  2821,\n",
       "  2829,\n",
       "  2835,\n",
       "  2837,\n",
       "  2839,\n",
       "  2849,\n",
       "  2853,\n",
       "  2854,\n",
       "  2856,\n",
       "  2860,\n",
       "  2864,\n",
       "  2866,\n",
       "  2867,\n",
       "  2869,\n",
       "  2871,\n",
       "  2873,\n",
       "  2874,\n",
       "  2876,\n",
       "  2882,\n",
       "  2885,\n",
       "  2887,\n",
       "  2888,\n",
       "  2890,\n",
       "  2892,\n",
       "  2897,\n",
       "  2898,\n",
       "  2904,\n",
       "  2906,\n",
       "  2913,\n",
       "  2914,\n",
       "  2916,\n",
       "  2919,\n",
       "  2920,\n",
       "  2921,\n",
       "  2922,\n",
       "  2923,\n",
       "  2931,\n",
       "  2932,\n",
       "  2933,\n",
       "  2938,\n",
       "  2939,\n",
       "  2940,\n",
       "  2942,\n",
       "  2943,\n",
       "  2944,\n",
       "  2946,\n",
       "  2948,\n",
       "  2954,\n",
       "  2955,\n",
       "  2957,\n",
       "  2960,\n",
       "  2961,\n",
       "  2964,\n",
       "  2972,\n",
       "  2973,\n",
       "  2974,\n",
       "  2975,\n",
       "  2976,\n",
       "  2979,\n",
       "  2981,\n",
       "  2983,\n",
       "  2988,\n",
       "  2989,\n",
       "  2990,\n",
       "  2991,\n",
       "  2997,\n",
       "  3001,\n",
       "  3002,\n",
       "  3003,\n",
       "  3005,\n",
       "  3009,\n",
       "  3012,\n",
       "  3014,\n",
       "  3018,\n",
       "  3027,\n",
       "  3030,\n",
       "  3032,\n",
       "  3033,\n",
       "  3036,\n",
       "  3046,\n",
       "  3047,\n",
       "  3050,\n",
       "  3051,\n",
       "  3053,\n",
       "  3055,\n",
       "  3057,\n",
       "  3059,\n",
       "  3060,\n",
       "  3064,\n",
       "  3065,\n",
       "  3067,\n",
       "  3070,\n",
       "  3074,\n",
       "  3077,\n",
       "  3080,\n",
       "  3083,\n",
       "  3092,\n",
       "  3093,\n",
       "  3094,\n",
       "  3096,\n",
       "  3097,\n",
       "  3101,\n",
       "  3102,\n",
       "  3104,\n",
       "  3106,\n",
       "  3111,\n",
       "  3113,\n",
       "  3115,\n",
       "  3116,\n",
       "  3117,\n",
       "  3120,\n",
       "  3121,\n",
       "  3122,\n",
       "  3123,\n",
       "  3127,\n",
       "  3131,\n",
       "  3132,\n",
       "  3133,\n",
       "  3135,\n",
       "  3137,\n",
       "  3138,\n",
       "  3139,\n",
       "  3141,\n",
       "  3142,\n",
       "  3143,\n",
       "  3146,\n",
       "  3150,\n",
       "  3152,\n",
       "  3154,\n",
       "  3155,\n",
       "  3157,\n",
       "  3158,\n",
       "  3162,\n",
       "  3163,\n",
       "  3168,\n",
       "  3170,\n",
       "  3173,\n",
       "  3176,\n",
       "  3184,\n",
       "  3192,\n",
       "  3194,\n",
       "  3195,\n",
       "  3197,\n",
       "  3198,\n",
       "  3202,\n",
       "  3211,\n",
       "  3214,\n",
       "  3216,\n",
       "  3217,\n",
       "  3218,\n",
       "  3220,\n",
       "  3221,\n",
       "  3223,\n",
       "  3226,\n",
       "  3228,\n",
       "  3230,\n",
       "  3233,\n",
       "  3237,\n",
       "  3238,\n",
       "  3242,\n",
       "  3244,\n",
       "  3247,\n",
       "  3252,\n",
       "  3253,\n",
       "  3254,\n",
       "  3256,\n",
       "  3260,\n",
       "  3267,\n",
       "  3270,\n",
       "  3271,\n",
       "  3272,\n",
       "  3275,\n",
       "  3276,\n",
       "  3278,\n",
       "  3279,\n",
       "  3281,\n",
       "  3287,\n",
       "  3295,\n",
       "  3298,\n",
       "  3304,\n",
       "  3305,\n",
       "  3306,\n",
       "  3307,\n",
       "  3310,\n",
       "  3317,\n",
       "  3321,\n",
       "  3322,\n",
       "  3325,\n",
       "  3327,\n",
       "  3330,\n",
       "  3333,\n",
       "  3334,\n",
       "  3335,\n",
       "  3337,\n",
       "  3342,\n",
       "  3343,\n",
       "  3346,\n",
       "  3348,\n",
       "  3349,\n",
       "  3353,\n",
       "  3355,\n",
       "  3359,\n",
       "  3360,\n",
       "  3361,\n",
       "  3365,\n",
       "  3366,\n",
       "  3367,\n",
       "  3370,\n",
       "  3373,\n",
       "  3374,\n",
       "  3375,\n",
       "  3376,\n",
       "  3377,\n",
       "  3378,\n",
       "  3379,\n",
       "  3380,\n",
       "  3382,\n",
       "  3383,\n",
       "  3388,\n",
       "  3390,\n",
       "  3395,\n",
       "  3396,\n",
       "  3398,\n",
       "  3400,\n",
       "  3402,\n",
       "  3405,\n",
       "  3407,\n",
       "  3408,\n",
       "  3413,\n",
       "  3415,\n",
       "  3421,\n",
       "  3423,\n",
       "  3424,\n",
       "  3425,\n",
       "  3427,\n",
       "  3429,\n",
       "  3430,\n",
       "  3435,\n",
       "  3445,\n",
       "  3446,\n",
       "  3448,\n",
       "  3449,\n",
       "  3450,\n",
       "  3452,\n",
       "  3454,\n",
       "  3456,\n",
       "  3458,\n",
       "  3459,\n",
       "  3461,\n",
       "  3462,\n",
       "  3464,\n",
       "  3465,\n",
       "  3466,\n",
       "  ...},\n",
       " 'Is Numeral': {52,\n",
       "  53,\n",
       "  54,\n",
       "  55,\n",
       "  56,\n",
       "  57,\n",
       "  58,\n",
       "  59,\n",
       "  60,\n",
       "  387,\n",
       "  512,\n",
       "  723,\n",
       "  1063,\n",
       "  1473,\n",
       "  2980,\n",
       "  3894,\n",
       "  4082,\n",
       "  4086,\n",
       "  4088,\n",
       "  4089,\n",
       "  4090,\n",
       "  4091,\n",
       "  4092,\n",
       "  4093,\n",
       "  4094},\n",
       " 'Is Particle': {268, 370, 2136, 2250},\n",
       " 'Is Pronoun': {76,\n",
       "  108,\n",
       "  120,\n",
       "  260,\n",
       "  264,\n",
       "  276,\n",
       "  282,\n",
       "  288,\n",
       "  292,\n",
       "  311,\n",
       "  313,\n",
       "  316,\n",
       "  325,\n",
       "  340,\n",
       "  341,\n",
       "  342,\n",
       "  345,\n",
       "  354,\n",
       "  364,\n",
       "  366,\n",
       "  368,\n",
       "  373,\n",
       "  397,\n",
       "  424,\n",
       "  431,\n",
       "  434,\n",
       "  469,\n",
       "  477,\n",
       "  483,\n",
       "  492,\n",
       "  524,\n",
       "  539,\n",
       "  580,\n",
       "  583,\n",
       "  587,\n",
       "  601,\n",
       "  617,\n",
       "  623,\n",
       "  625,\n",
       "  641,\n",
       "  659,\n",
       "  660,\n",
       "  672,\n",
       "  716,\n",
       "  728,\n",
       "  740,\n",
       "  746,\n",
       "  756,\n",
       "  798,\n",
       "  806,\n",
       "  822,\n",
       "  828,\n",
       "  864,\n",
       "  915,\n",
       "  945,\n",
       "  1010,\n",
       "  1036,\n",
       "  1051,\n",
       "  1071,\n",
       "  1135,\n",
       "  1137,\n",
       "  1141,\n",
       "  1176,\n",
       "  1235,\n",
       "  1281,\n",
       "  1334,\n",
       "  1342,\n",
       "  1365,\n",
       "  1543,\n",
       "  1556,\n",
       "  1569,\n",
       "  1586,\n",
       "  1593,\n",
       "  1655,\n",
       "  1688,\n",
       "  1758,\n",
       "  1831,\n",
       "  1859,\n",
       "  1891,\n",
       "  1897,\n",
       "  1928,\n",
       "  2357,\n",
       "  2372,\n",
       "  2424,\n",
       "  2425,\n",
       "  2478,\n",
       "  2587,\n",
       "  2682,\n",
       "  2738,\n",
       "  2742,\n",
       "  2875,\n",
       "  2902,\n",
       "  2952,\n",
       "  2959,\n",
       "  2998,\n",
       "  3108,\n",
       "  3312,\n",
       "  3508,\n",
       "  3751,\n",
       "  3887,\n",
       "  4031,\n",
       "  4039,\n",
       "  4052},\n",
       " 'Is Proper Noun': {18,\n",
       "  77,\n",
       "  86,\n",
       "  274,\n",
       "  294,\n",
       "  297,\n",
       "  304,\n",
       "  305,\n",
       "  318,\n",
       "  321,\n",
       "  323,\n",
       "  330,\n",
       "  344,\n",
       "  347,\n",
       "  360,\n",
       "  361,\n",
       "  362,\n",
       "  365,\n",
       "  371,\n",
       "  377,\n",
       "  382,\n",
       "  385,\n",
       "  389,\n",
       "  392,\n",
       "  396,\n",
       "  399,\n",
       "  401,\n",
       "  405,\n",
       "  408,\n",
       "  416,\n",
       "  417,\n",
       "  419,\n",
       "  421,\n",
       "  422,\n",
       "  430,\n",
       "  438,\n",
       "  445,\n",
       "  447,\n",
       "  451,\n",
       "  454,\n",
       "  461,\n",
       "  464,\n",
       "  470,\n",
       "  473,\n",
       "  475,\n",
       "  485,\n",
       "  487,\n",
       "  490,\n",
       "  491,\n",
       "  494,\n",
       "  497,\n",
       "  499,\n",
       "  504,\n",
       "  517,\n",
       "  522,\n",
       "  523,\n",
       "  530,\n",
       "  532,\n",
       "  535,\n",
       "  536,\n",
       "  540,\n",
       "  542,\n",
       "  545,\n",
       "  546,\n",
       "  550,\n",
       "  554,\n",
       "  557,\n",
       "  558,\n",
       "  561,\n",
       "  563,\n",
       "  566,\n",
       "  570,\n",
       "  571,\n",
       "  589,\n",
       "  590,\n",
       "  594,\n",
       "  595,\n",
       "  596,\n",
       "  600,\n",
       "  606,\n",
       "  609,\n",
       "  618,\n",
       "  627,\n",
       "  633,\n",
       "  638,\n",
       "  644,\n",
       "  646,\n",
       "  649,\n",
       "  650,\n",
       "  658,\n",
       "  662,\n",
       "  664,\n",
       "  665,\n",
       "  669,\n",
       "  674,\n",
       "  684,\n",
       "  686,\n",
       "  693,\n",
       "  703,\n",
       "  717,\n",
       "  721,\n",
       "  734,\n",
       "  738,\n",
       "  743,\n",
       "  744,\n",
       "  747,\n",
       "  749,\n",
       "  750,\n",
       "  760,\n",
       "  761,\n",
       "  766,\n",
       "  768,\n",
       "  773,\n",
       "  774,\n",
       "  787,\n",
       "  789,\n",
       "  795,\n",
       "  797,\n",
       "  818,\n",
       "  820,\n",
       "  827,\n",
       "  833,\n",
       "  845,\n",
       "  846,\n",
       "  847,\n",
       "  855,\n",
       "  857,\n",
       "  861,\n",
       "  863,\n",
       "  866,\n",
       "  870,\n",
       "  871,\n",
       "  880,\n",
       "  881,\n",
       "  890,\n",
       "  896,\n",
       "  898,\n",
       "  899,\n",
       "  906,\n",
       "  907,\n",
       "  911,\n",
       "  914,\n",
       "  918,\n",
       "  938,\n",
       "  943,\n",
       "  952,\n",
       "  953,\n",
       "  957,\n",
       "  960,\n",
       "  965,\n",
       "  967,\n",
       "  975,\n",
       "  978,\n",
       "  980,\n",
       "  983,\n",
       "  994,\n",
       "  996,\n",
       "  999,\n",
       "  1002,\n",
       "  1006,\n",
       "  1012,\n",
       "  1013,\n",
       "  1014,\n",
       "  1017,\n",
       "  1024,\n",
       "  1026,\n",
       "  1039,\n",
       "  1043,\n",
       "  1044,\n",
       "  1049,\n",
       "  1050,\n",
       "  1054,\n",
       "  1058,\n",
       "  1059,\n",
       "  1062,\n",
       "  1064,\n",
       "  1066,\n",
       "  1068,\n",
       "  1069,\n",
       "  1070,\n",
       "  1073,\n",
       "  1074,\n",
       "  1078,\n",
       "  1080,\n",
       "  1081,\n",
       "  1082,\n",
       "  1084,\n",
       "  1087,\n",
       "  1092,\n",
       "  1106,\n",
       "  1112,\n",
       "  1114,\n",
       "  1116,\n",
       "  1119,\n",
       "  1123,\n",
       "  1124,\n",
       "  1127,\n",
       "  1130,\n",
       "  1142,\n",
       "  1150,\n",
       "  1156,\n",
       "  1158,\n",
       "  1159,\n",
       "  1160,\n",
       "  1163,\n",
       "  1167,\n",
       "  1168,\n",
       "  1186,\n",
       "  1191,\n",
       "  1197,\n",
       "  1198,\n",
       "  1204,\n",
       "  1208,\n",
       "  1217,\n",
       "  1218,\n",
       "  1222,\n",
       "  1226,\n",
       "  1227,\n",
       "  1228,\n",
       "  1229,\n",
       "  1231,\n",
       "  1239,\n",
       "  1240,\n",
       "  1244,\n",
       "  1245,\n",
       "  1249,\n",
       "  1252,\n",
       "  1257,\n",
       "  1258,\n",
       "  1268,\n",
       "  1269,\n",
       "  1270,\n",
       "  1274,\n",
       "  1285,\n",
       "  1287,\n",
       "  1289,\n",
       "  1290,\n",
       "  1291,\n",
       "  1295,\n",
       "  1301,\n",
       "  1306,\n",
       "  1311,\n",
       "  1319,\n",
       "  1320,\n",
       "  1325,\n",
       "  1332,\n",
       "  1333,\n",
       "  1346,\n",
       "  1354,\n",
       "  1356,\n",
       "  1357,\n",
       "  1358,\n",
       "  1362,\n",
       "  1366,\n",
       "  1370,\n",
       "  1374,\n",
       "  1378,\n",
       "  1381,\n",
       "  1388,\n",
       "  1400,\n",
       "  1415,\n",
       "  1426,\n",
       "  1431,\n",
       "  1432,\n",
       "  1438,\n",
       "  1443,\n",
       "  1444,\n",
       "  1446,\n",
       "  1451,\n",
       "  1452,\n",
       "  1453,\n",
       "  1469,\n",
       "  1472,\n",
       "  1474,\n",
       "  1481,\n",
       "  1482,\n",
       "  1484,\n",
       "  1491,\n",
       "  1497,\n",
       "  1500,\n",
       "  1503,\n",
       "  1511,\n",
       "  1515,\n",
       "  1519,\n",
       "  1520,\n",
       "  1538,\n",
       "  1548,\n",
       "  1551,\n",
       "  1553,\n",
       "  1563,\n",
       "  1564,\n",
       "  1566,\n",
       "  1573,\n",
       "  1576,\n",
       "  1577,\n",
       "  1578,\n",
       "  1581,\n",
       "  1585,\n",
       "  1590,\n",
       "  1597,\n",
       "  1598,\n",
       "  1601,\n",
       "  1609,\n",
       "  1612,\n",
       "  1614,\n",
       "  1617,\n",
       "  1618,\n",
       "  1622,\n",
       "  1628,\n",
       "  1630,\n",
       "  1637,\n",
       "  1640,\n",
       "  1644,\n",
       "  1646,\n",
       "  1648,\n",
       "  1654,\n",
       "  1658,\n",
       "  1659,\n",
       "  1663,\n",
       "  1669,\n",
       "  1675,\n",
       "  1682,\n",
       "  1684,\n",
       "  1686,\n",
       "  1692,\n",
       "  1694,\n",
       "  1696,\n",
       "  1697,\n",
       "  1699,\n",
       "  1707,\n",
       "  1708,\n",
       "  1711,\n",
       "  1720,\n",
       "  1721,\n",
       "  1725,\n",
       "  1734,\n",
       "  1735,\n",
       "  1736,\n",
       "  1737,\n",
       "  1739,\n",
       "  1742,\n",
       "  1749,\n",
       "  1751,\n",
       "  1759,\n",
       "  1761,\n",
       "  1764,\n",
       "  1766,\n",
       "  1768,\n",
       "  1769,\n",
       "  1772,\n",
       "  1777,\n",
       "  1786,\n",
       "  1789,\n",
       "  1792,\n",
       "  1801,\n",
       "  1802,\n",
       "  1810,\n",
       "  1816,\n",
       "  1823,\n",
       "  1827,\n",
       "  1830,\n",
       "  1833,\n",
       "  1836,\n",
       "  1840,\n",
       "  1845,\n",
       "  1846,\n",
       "  1851,\n",
       "  1853,\n",
       "  1856,\n",
       "  1865,\n",
       "  1869,\n",
       "  1874,\n",
       "  1875,\n",
       "  1879,\n",
       "  1887,\n",
       "  1893,\n",
       "  1894,\n",
       "  1899,\n",
       "  1900,\n",
       "  1902,\n",
       "  1903,\n",
       "  1905,\n",
       "  1906,\n",
       "  1911,\n",
       "  1913,\n",
       "  1915,\n",
       "  1916,\n",
       "  1920,\n",
       "  1921,\n",
       "  1924,\n",
       "  1925,\n",
       "  1926,\n",
       "  1927,\n",
       "  1929,\n",
       "  1930,\n",
       "  1931,\n",
       "  1933,\n",
       "  1934,\n",
       "  1939,\n",
       "  1941,\n",
       "  1942,\n",
       "  1943,\n",
       "  1952,\n",
       "  1953,\n",
       "  1955,\n",
       "  1957,\n",
       "  1960,\n",
       "  1966,\n",
       "  1970,\n",
       "  1974,\n",
       "  1978,\n",
       "  1991,\n",
       "  1993,\n",
       "  1995,\n",
       "  1999,\n",
       "  2003,\n",
       "  2007,\n",
       "  2010,\n",
       "  2013,\n",
       "  2016,\n",
       "  2017,\n",
       "  2025,\n",
       "  2026,\n",
       "  2037,\n",
       "  2040,\n",
       "  2047,\n",
       "  2050,\n",
       "  2054,\n",
       "  2066,\n",
       "  2067,\n",
       "  2074,\n",
       "  2076,\n",
       "  2078,\n",
       "  2083,\n",
       "  2084,\n",
       "  2087,\n",
       "  2090,\n",
       "  2091,\n",
       "  2095,\n",
       "  2096,\n",
       "  2097,\n",
       "  2099,\n",
       "  2100,\n",
       "  2102,\n",
       "  2104,\n",
       "  2107,\n",
       "  2108,\n",
       "  2112,\n",
       "  2114,\n",
       "  2115,\n",
       "  2120,\n",
       "  2121,\n",
       "  2123,\n",
       "  2130,\n",
       "  2138,\n",
       "  2141,\n",
       "  2142,\n",
       "  2144,\n",
       "  2150,\n",
       "  2152,\n",
       "  2154,\n",
       "  2155,\n",
       "  2162,\n",
       "  2166,\n",
       "  2169,\n",
       "  2170,\n",
       "  2172,\n",
       "  2182,\n",
       "  2186,\n",
       "  2192,\n",
       "  2194,\n",
       "  2200,\n",
       "  2206,\n",
       "  2207,\n",
       "  2209,\n",
       "  2212,\n",
       "  2213,\n",
       "  2215,\n",
       "  2218,\n",
       "  2220,\n",
       "  2225,\n",
       "  2231,\n",
       "  2233,\n",
       "  2235,\n",
       "  2239,\n",
       "  2240,\n",
       "  2243,\n",
       "  2245,\n",
       "  2251,\n",
       "  2252,\n",
       "  2257,\n",
       "  2258,\n",
       "  2261,\n",
       "  2262,\n",
       "  2263,\n",
       "  2266,\n",
       "  2270,\n",
       "  2272,\n",
       "  2276,\n",
       "  2277,\n",
       "  2278,\n",
       "  2285,\n",
       "  2289,\n",
       "  2293,\n",
       "  2294,\n",
       "  2296,\n",
       "  2298,\n",
       "  2301,\n",
       "  2302,\n",
       "  2304,\n",
       "  2314,\n",
       "  2316,\n",
       "  2328,\n",
       "  2329,\n",
       "  2331,\n",
       "  2332,\n",
       "  2333,\n",
       "  2334,\n",
       "  2348,\n",
       "  2363,\n",
       "  2365,\n",
       "  2366,\n",
       "  2367,\n",
       "  2371,\n",
       "  2382,\n",
       "  2386,\n",
       "  2389,\n",
       "  2393,\n",
       "  2394,\n",
       "  2396,\n",
       "  2400,\n",
       "  2401,\n",
       "  2407,\n",
       "  2409,\n",
       "  2410,\n",
       "  2411,\n",
       "  2416,\n",
       "  2419,\n",
       "  2429,\n",
       "  2432,\n",
       "  2437,\n",
       "  2438,\n",
       "  2439,\n",
       "  2440,\n",
       "  2444,\n",
       "  2448,\n",
       "  2450,\n",
       "  2459,\n",
       "  2463,\n",
       "  2468,\n",
       "  2469,\n",
       "  2473,\n",
       "  2483,\n",
       "  2484,\n",
       "  2492,\n",
       "  2494,\n",
       "  2497,\n",
       "  2499,\n",
       "  2501,\n",
       "  2506,\n",
       "  2518,\n",
       "  2519,\n",
       "  2520,\n",
       "  2524,\n",
       "  2525,\n",
       "  2526,\n",
       "  2538,\n",
       "  2540,\n",
       "  2544,\n",
       "  2549,\n",
       "  2553,\n",
       "  2554,\n",
       "  2555,\n",
       "  2558,\n",
       "  2559,\n",
       "  2564,\n",
       "  2566,\n",
       "  2568,\n",
       "  2573,\n",
       "  2575,\n",
       "  2576,\n",
       "  2580,\n",
       "  2584,\n",
       "  2585,\n",
       "  2593,\n",
       "  2598,\n",
       "  2606,\n",
       "  2607,\n",
       "  2608,\n",
       "  2609,\n",
       "  2624,\n",
       "  2627,\n",
       "  2629,\n",
       "  2631,\n",
       "  2635,\n",
       "  2637,\n",
       "  2640,\n",
       "  2641,\n",
       "  2644,\n",
       "  2649,\n",
       "  2650,\n",
       "  2651,\n",
       "  2655,\n",
       "  2657,\n",
       "  2660,\n",
       "  2669,\n",
       "  2671,\n",
       "  2680,\n",
       "  2681,\n",
       "  2689,\n",
       "  2692,\n",
       "  2702,\n",
       "  2703,\n",
       "  2705,\n",
       "  2706,\n",
       "  2710,\n",
       "  2715,\n",
       "  2722,\n",
       "  2725,\n",
       "  2727,\n",
       "  2730,\n",
       "  2735,\n",
       "  2741,\n",
       "  2744,\n",
       "  2745,\n",
       "  2746,\n",
       "  2755,\n",
       "  2758,\n",
       "  2760,\n",
       "  2761,\n",
       "  2763,\n",
       "  2765,\n",
       "  2766,\n",
       "  2768,\n",
       "  2770,\n",
       "  2776,\n",
       "  2778,\n",
       "  2782,\n",
       "  2786,\n",
       "  2793,\n",
       "  2795,\n",
       "  2798,\n",
       "  2802,\n",
       "  2803,\n",
       "  2809,\n",
       "  2812,\n",
       "  2814,\n",
       "  2818,\n",
       "  2820,\n",
       "  2823,\n",
       "  2825,\n",
       "  2826,\n",
       "  2827,\n",
       "  2831,\n",
       "  2832,\n",
       "  2843,\n",
       "  2845,\n",
       "  2846,\n",
       "  2855,\n",
       "  2857,\n",
       "  2858,\n",
       "  2861,\n",
       "  2870,\n",
       "  2872,\n",
       "  2878,\n",
       "  2879,\n",
       "  2886,\n",
       "  2899,\n",
       "  2905,\n",
       "  2907,\n",
       "  2908,\n",
       "  2924,\n",
       "  2925,\n",
       "  2927,\n",
       "  2929,\n",
       "  2941,\n",
       "  2945,\n",
       "  2947,\n",
       "  2949,\n",
       "  2951,\n",
       "  2953,\n",
       "  2958,\n",
       "  2962,\n",
       "  2963,\n",
       "  2966,\n",
       "  2968,\n",
       "  2971,\n",
       "  2984,\n",
       "  2985,\n",
       "  2987,\n",
       "  2993,\n",
       "  2996,\n",
       "  3004,\n",
       "  3008,\n",
       "  3016,\n",
       "  3017,\n",
       "  3019,\n",
       "  3022,\n",
       "  3024,\n",
       "  3026,\n",
       "  3028,\n",
       "  3031,\n",
       "  3034,\n",
       "  3039,\n",
       "  3041,\n",
       "  3042,\n",
       "  3044,\n",
       "  3063,\n",
       "  3068,\n",
       "  3069,\n",
       "  3072,\n",
       "  3088,\n",
       "  3089,\n",
       "  3095,\n",
       "  3099,\n",
       "  3100,\n",
       "  3103,\n",
       "  3107,\n",
       "  3112,\n",
       "  3118,\n",
       "  3125,\n",
       "  3128,\n",
       "  3130,\n",
       "  3140,\n",
       "  3145,\n",
       "  3149,\n",
       "  3153,\n",
       "  3159,\n",
       "  3160,\n",
       "  3161,\n",
       "  3164,\n",
       "  3165,\n",
       "  3177,\n",
       "  3178,\n",
       "  3179,\n",
       "  3180,\n",
       "  3181,\n",
       "  3183,\n",
       "  3186,\n",
       "  3187,\n",
       "  3189,\n",
       "  3190,\n",
       "  3196,\n",
       "  3199,\n",
       "  3201,\n",
       "  3204,\n",
       "  3207,\n",
       "  3208,\n",
       "  3209,\n",
       "  3215,\n",
       "  3219,\n",
       "  3222,\n",
       "  3229,\n",
       "  3231,\n",
       "  3232,\n",
       "  3236,\n",
       "  3239,\n",
       "  3245,\n",
       "  3246,\n",
       "  3249,\n",
       "  3251,\n",
       "  3255,\n",
       "  3258,\n",
       "  3259,\n",
       "  3261,\n",
       "  3263,\n",
       "  3264,\n",
       "  3265,\n",
       "  3268,\n",
       "  3269,\n",
       "  3273,\n",
       "  3274,\n",
       "  3277,\n",
       "  3280,\n",
       "  3282,\n",
       "  3284,\n",
       "  3290,\n",
       "  3291,\n",
       "  3292,\n",
       "  3300,\n",
       "  3303,\n",
       "  3308,\n",
       "  3311,\n",
       "  3313,\n",
       "  3315,\n",
       "  3316,\n",
       "  3318,\n",
       "  3324,\n",
       "  3328,\n",
       "  3329,\n",
       "  3331,\n",
       "  3332,\n",
       "  3336,\n",
       "  3338,\n",
       "  3341,\n",
       "  3344,\n",
       "  3350,\n",
       "  3351,\n",
       "  3354,\n",
       "  3364,\n",
       "  3369,\n",
       "  3371,\n",
       "  3372,\n",
       "  3381,\n",
       "  3384,\n",
       "  3386,\n",
       "  3387,\n",
       "  3389,\n",
       "  3391,\n",
       "  3392,\n",
       "  3394,\n",
       "  3399,\n",
       "  3403,\n",
       "  3406,\n",
       "  3412,\n",
       "  3414,\n",
       "  3416,\n",
       "  3417,\n",
       "  3418,\n",
       "  3420,\n",
       "  3432,\n",
       "  3440,\n",
       "  3441,\n",
       "  3442,\n",
       "  3443,\n",
       "  3444,\n",
       "  3447,\n",
       "  3453,\n",
       "  3460,\n",
       "  3472,\n",
       "  3473,\n",
       "  3478,\n",
       "  3480,\n",
       "  3481,\n",
       "  3483,\n",
       "  3487,\n",
       "  3490,\n",
       "  3491,\n",
       "  3497,\n",
       "  3504,\n",
       "  3511,\n",
       "  3512,\n",
       "  3515,\n",
       "  3516,\n",
       "  3526,\n",
       "  3534,\n",
       "  3540,\n",
       "  3545,\n",
       "  3549,\n",
       "  3550,\n",
       "  3551,\n",
       "  3559,\n",
       "  3567,\n",
       "  3583,\n",
       "  3588,\n",
       "  3590,\n",
       "  3591,\n",
       "  3603,\n",
       "  3604,\n",
       "  3605,\n",
       "  3608,\n",
       "  3618,\n",
       "  3620,\n",
       "  3626,\n",
       "  3631,\n",
       "  3632,\n",
       "  3634,\n",
       "  3639,\n",
       "  3641,\n",
       "  3643,\n",
       "  3647,\n",
       "  3648,\n",
       "  3652,\n",
       "  3655,\n",
       "  3659,\n",
       "  3664,\n",
       "  3666,\n",
       "  3676,\n",
       "  3688,\n",
       "  3689,\n",
       "  3692,\n",
       "  3693,\n",
       "  3694,\n",
       "  3697,\n",
       "  3698,\n",
       "  3701,\n",
       "  3705,\n",
       "  3707,\n",
       "  3713,\n",
       "  3714,\n",
       "  3715,\n",
       "  3716,\n",
       "  3718,\n",
       "  3721,\n",
       "  3723,\n",
       "  3728,\n",
       "  3729,\n",
       "  3730,\n",
       "  3733,\n",
       "  3737,\n",
       "  3738,\n",
       "  3746,\n",
       "  3748,\n",
       "  3755,\n",
       "  3756,\n",
       "  3759,\n",
       "  3765,\n",
       "  3769,\n",
       "  3770,\n",
       "  3777,\n",
       "  3779,\n",
       "  3785,\n",
       "  3789,\n",
       "  3792,\n",
       "  3794,\n",
       "  3799,\n",
       "  3802,\n",
       "  3804,\n",
       "  3808,\n",
       "  3814,\n",
       "  3816,\n",
       "  3818,\n",
       "  3822,\n",
       "  3824,\n",
       "  3825,\n",
       "  3827,\n",
       "  3830,\n",
       "  3832,\n",
       "  3834,\n",
       "  3840,\n",
       "  3841,\n",
       "  3845,\n",
       "  3854,\n",
       "  3859,\n",
       "  3871,\n",
       "  3873,\n",
       "  3879,\n",
       "  3880,\n",
       "  3883,\n",
       "  3888,\n",
       "  3890,\n",
       "  3903,\n",
       "  3904,\n",
       "  3907,\n",
       "  3910,\n",
       "  3919,\n",
       "  3920,\n",
       "  3921,\n",
       "  3926,\n",
       "  3933,\n",
       "  3939,\n",
       "  3940,\n",
       "  3941,\n",
       "  3946,\n",
       "  3949,\n",
       "  3952,\n",
       "  3953,\n",
       "  3954,\n",
       "  3957,\n",
       "  3962,\n",
       "  3965,\n",
       "  3967,\n",
       "  3971,\n",
       "  3975,\n",
       "  3977,\n",
       "  3978,\n",
       "  3981,\n",
       "  3983,\n",
       "  3988,\n",
       "  3990,\n",
       "  3997,\n",
       "  4006,\n",
       "  4007,\n",
       "  4013,\n",
       "  4016,\n",
       "  4022,\n",
       "  4050,\n",
       "  4066},\n",
       " 'Is Punctuation': {0,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  6,\n",
       "  7,\n",
       "  8,\n",
       "  9,\n",
       "  10,\n",
       "  11,\n",
       "  17,\n",
       "  19,\n",
       "  20,\n",
       "  21,\n",
       "  22,\n",
       "  23,\n",
       "  24,\n",
       "  25,\n",
       "  26,\n",
       "  27,\n",
       "  28,\n",
       "  30,\n",
       "  36,\n",
       "  37,\n",
       "  38,\n",
       "  40,\n",
       "  42,\n",
       "  43,\n",
       "  44,\n",
       "  45,\n",
       "  46,\n",
       "  47,\n",
       "  48,\n",
       "  49,\n",
       "  50,\n",
       "  51,\n",
       "  61,\n",
       "  62,\n",
       "  63,\n",
       "  64,\n",
       "  65,\n",
       "  66,\n",
       "  67,\n",
       "  94,\n",
       "  95,\n",
       "  97,\n",
       "  98,\n",
       "  99,\n",
       "  126,\n",
       "  127,\n",
       "  128,\n",
       "  129,\n",
       "  130,\n",
       "  131,\n",
       "  132,\n",
       "  133,\n",
       "  134,\n",
       "  135,\n",
       "  136,\n",
       "  137,\n",
       "  138,\n",
       "  139,\n",
       "  140,\n",
       "  141,\n",
       "  142,\n",
       "  143,\n",
       "  144,\n",
       "  145,\n",
       "  146,\n",
       "  147,\n",
       "  148,\n",
       "  149,\n",
       "  150,\n",
       "  151,\n",
       "  152,\n",
       "  153,\n",
       "  154,\n",
       "  155,\n",
       "  156,\n",
       "  157,\n",
       "  158,\n",
       "  159,\n",
       "  160,\n",
       "  161,\n",
       "  162,\n",
       "  163,\n",
       "  164,\n",
       "  165,\n",
       "  166,\n",
       "  167,\n",
       "  168,\n",
       "  169,\n",
       "  170,\n",
       "  171,\n",
       "  172,\n",
       "  173,\n",
       "  174,\n",
       "  175,\n",
       "  176,\n",
       "  177,\n",
       "  178,\n",
       "  179,\n",
       "  180,\n",
       "  181,\n",
       "  182,\n",
       "  183,\n",
       "  184,\n",
       "  185,\n",
       "  186,\n",
       "  187,\n",
       "  188,\n",
       "  189,\n",
       "  190,\n",
       "  191,\n",
       "  192,\n",
       "  193,\n",
       "  194,\n",
       "  195,\n",
       "  196,\n",
       "  197,\n",
       "  198,\n",
       "  199,\n",
       "  200,\n",
       "  201,\n",
       "  202,\n",
       "  203,\n",
       "  204,\n",
       "  205,\n",
       "  206,\n",
       "  207,\n",
       "  208,\n",
       "  209,\n",
       "  210,\n",
       "  211,\n",
       "  212,\n",
       "  213,\n",
       "  214,\n",
       "  215,\n",
       "  216,\n",
       "  217,\n",
       "  218,\n",
       "  219,\n",
       "  220,\n",
       "  221,\n",
       "  222,\n",
       "  223,\n",
       "  224,\n",
       "  225,\n",
       "  226,\n",
       "  227,\n",
       "  228,\n",
       "  229,\n",
       "  230,\n",
       "  231,\n",
       "  232,\n",
       "  233,\n",
       "  234,\n",
       "  235,\n",
       "  236,\n",
       "  237,\n",
       "  238,\n",
       "  239,\n",
       "  240,\n",
       "  241,\n",
       "  242,\n",
       "  243,\n",
       "  244,\n",
       "  245,\n",
       "  246,\n",
       "  247,\n",
       "  248,\n",
       "  249,\n",
       "  250,\n",
       "  251,\n",
       "  252,\n",
       "  253,\n",
       "  254,\n",
       "  255,\n",
       "  256,\n",
       "  257,\n",
       "  258,\n",
       "  307,\n",
       "  398,\n",
       "  411,\n",
       "  471,\n",
       "  632,\n",
       "  1568,\n",
       "  1641,\n",
       "  1713,\n",
       "  2847,\n",
       "  3674,\n",
       "  4037,\n",
       "  4045,\n",
       "  4048,\n",
       "  4054,\n",
       "  4056,\n",
       "  4063,\n",
       "  4077,\n",
       "  4078,\n",
       "  4083,\n",
       "  4087},\n",
       " 'Is Subordinating conjuction': {386,\n",
       "  440,\n",
       "  615,\n",
       "  631,\n",
       "  706,\n",
       "  724,\n",
       "  764,\n",
       "  842,\n",
       "  1001,\n",
       "  1072,\n",
       "  1299,\n",
       "  1347,\n",
       "  1465,\n",
       "  1522,\n",
       "  2312,\n",
       "  2423,\n",
       "  2511,\n",
       "  2539,\n",
       "  2749,\n",
       "  3013,\n",
       "  3203},\n",
       " 'Is Symbol': set(),\n",
       " 'Is Verb': {266,\n",
       "  301,\n",
       "  326,\n",
       "  327,\n",
       "  338,\n",
       "  356,\n",
       "  369,\n",
       "  374,\n",
       "  379,\n",
       "  384,\n",
       "  407,\n",
       "  409,\n",
       "  412,\n",
       "  423,\n",
       "  428,\n",
       "  429,\n",
       "  435,\n",
       "  446,\n",
       "  448,\n",
       "  453,\n",
       "  465,\n",
       "  468,\n",
       "  474,\n",
       "  482,\n",
       "  502,\n",
       "  505,\n",
       "  507,\n",
       "  509,\n",
       "  514,\n",
       "  531,\n",
       "  533,\n",
       "  534,\n",
       "  538,\n",
       "  541,\n",
       "  543,\n",
       "  549,\n",
       "  551,\n",
       "  553,\n",
       "  555,\n",
       "  564,\n",
       "  565,\n",
       "  567,\n",
       "  572,\n",
       "  577,\n",
       "  579,\n",
       "  582,\n",
       "  584,\n",
       "  586,\n",
       "  598,\n",
       "  612,\n",
       "  616,\n",
       "  628,\n",
       "  642,\n",
       "  645,\n",
       "  653,\n",
       "  655,\n",
       "  656,\n",
       "  657,\n",
       "  661,\n",
       "  668,\n",
       "  673,\n",
       "  682,\n",
       "  683,\n",
       "  687,\n",
       "  697,\n",
       "  701,\n",
       "  704,\n",
       "  705,\n",
       "  711,\n",
       "  712,\n",
       "  714,\n",
       "  730,\n",
       "  731,\n",
       "  735,\n",
       "  752,\n",
       "  754,\n",
       "  758,\n",
       "  767,\n",
       "  769,\n",
       "  781,\n",
       "  782,\n",
       "  788,\n",
       "  800,\n",
       "  801,\n",
       "  809,\n",
       "  812,\n",
       "  815,\n",
       "  819,\n",
       "  829,\n",
       "  832,\n",
       "  838,\n",
       "  840,\n",
       "  841,\n",
       "  851,\n",
       "  868,\n",
       "  884,\n",
       "  891,\n",
       "  893,\n",
       "  895,\n",
       "  900,\n",
       "  902,\n",
       "  903,\n",
       "  909,\n",
       "  913,\n",
       "  917,\n",
       "  922,\n",
       "  925,\n",
       "  929,\n",
       "  937,\n",
       "  944,\n",
       "  948,\n",
       "  958,\n",
       "  977,\n",
       "  984,\n",
       "  987,\n",
       "  989,\n",
       "  993,\n",
       "  1018,\n",
       "  1019,\n",
       "  1022,\n",
       "  1027,\n",
       "  1031,\n",
       "  1032,\n",
       "  1034,\n",
       "  1037,\n",
       "  1045,\n",
       "  1046,\n",
       "  1053,\n",
       "  1083,\n",
       "  1089,\n",
       "  1090,\n",
       "  1093,\n",
       "  1096,\n",
       "  1097,\n",
       "  1100,\n",
       "  1105,\n",
       "  1107,\n",
       "  1108,\n",
       "  1117,\n",
       "  1121,\n",
       "  1122,\n",
       "  1126,\n",
       "  1132,\n",
       "  1134,\n",
       "  1139,\n",
       "  1143,\n",
       "  1148,\n",
       "  1151,\n",
       "  1152,\n",
       "  1153,\n",
       "  1154,\n",
       "  1155,\n",
       "  1177,\n",
       "  1181,\n",
       "  1194,\n",
       "  1202,\n",
       "  1207,\n",
       "  1216,\n",
       "  1230,\n",
       "  1236,\n",
       "  1238,\n",
       "  1241,\n",
       "  1243,\n",
       "  1248,\n",
       "  1251,\n",
       "  1254,\n",
       "  1260,\n",
       "  1279,\n",
       "  1283,\n",
       "  1286,\n",
       "  1294,\n",
       "  1296,\n",
       "  1297,\n",
       "  1300,\n",
       "  1302,\n",
       "  1309,\n",
       "  1310,\n",
       "  1317,\n",
       "  1321,\n",
       "  1329,\n",
       "  1337,\n",
       "  1341,\n",
       "  1345,\n",
       "  1348,\n",
       "  1350,\n",
       "  1364,\n",
       "  1369,\n",
       "  1372,\n",
       "  1376,\n",
       "  1385,\n",
       "  1393,\n",
       "  1394,\n",
       "  1397,\n",
       "  1401,\n",
       "  1402,\n",
       "  1404,\n",
       "  1407,\n",
       "  1408,\n",
       "  1412,\n",
       "  1419,\n",
       "  1420,\n",
       "  1422,\n",
       "  1425,\n",
       "  1429,\n",
       "  1434,\n",
       "  1436,\n",
       "  1439,\n",
       "  1447,\n",
       "  1448,\n",
       "  1450,\n",
       "  1457,\n",
       "  1459,\n",
       "  1460,\n",
       "  1470,\n",
       "  1483,\n",
       "  1485,\n",
       "  1488,\n",
       "  1494,\n",
       "  1496,\n",
       "  1502,\n",
       "  1504,\n",
       "  1509,\n",
       "  1510,\n",
       "  1514,\n",
       "  1527,\n",
       "  1537,\n",
       "  1541,\n",
       "  1542,\n",
       "  1546,\n",
       "  1547,\n",
       "  1565,\n",
       "  1567,\n",
       "  1572,\n",
       "  1584,\n",
       "  1599,\n",
       "  1602,\n",
       "  1606,\n",
       "  1607,\n",
       "  1608,\n",
       "  1616,\n",
       "  1620,\n",
       "  1627,\n",
       "  1636,\n",
       "  1639,\n",
       "  1647,\n",
       "  1650,\n",
       "  1657,\n",
       "  1660,\n",
       "  1667,\n",
       "  1673,\n",
       "  1698,\n",
       "  1700,\n",
       "  1701,\n",
       "  1704,\n",
       "  1706,\n",
       "  1715,\n",
       "  1717,\n",
       "  1718,\n",
       "  1719,\n",
       "  1723,\n",
       "  1730,\n",
       "  1731,\n",
       "  1732,\n",
       "  1747,\n",
       "  1748,\n",
       "  1765,\n",
       "  1773,\n",
       "  1778,\n",
       "  1783,\n",
       "  1791,\n",
       "  1795,\n",
       "  1800,\n",
       "  1805,\n",
       "  1807,\n",
       "  1813,\n",
       "  1817,\n",
       "  1838,\n",
       "  1839,\n",
       "  1852,\n",
       "  1863,\n",
       "  1864,\n",
       "  1866,\n",
       "  1883,\n",
       "  1884,\n",
       "  1888,\n",
       "  1896,\n",
       "  1898,\n",
       "  1908,\n",
       "  1910,\n",
       "  1917,\n",
       "  1922,\n",
       "  1945,\n",
       "  1948,\n",
       "  1956,\n",
       "  1961,\n",
       "  1973,\n",
       "  1983,\n",
       "  1988,\n",
       "  2004,\n",
       "  2009,\n",
       "  2012,\n",
       "  2030,\n",
       "  2046,\n",
       "  2064,\n",
       "  2075,\n",
       "  2080,\n",
       "  2092,\n",
       "  2113,\n",
       "  2116,\n",
       "  2118,\n",
       "  2122,\n",
       "  2126,\n",
       "  2135,\n",
       "  2145,\n",
       "  2147,\n",
       "  2161,\n",
       "  2164,\n",
       "  2173,\n",
       "  2181,\n",
       "  2185,\n",
       "  2189,\n",
       "  2195,\n",
       "  2198,\n",
       "  2204,\n",
       "  2217,\n",
       "  2226,\n",
       "  2227,\n",
       "  2237,\n",
       "  2238,\n",
       "  2247,\n",
       "  2249,\n",
       "  2269,\n",
       "  2287,\n",
       "  2297,\n",
       "  2311,\n",
       "  2319,\n",
       "  2324,\n",
       "  2349,\n",
       "  2350,\n",
       "  2351,\n",
       "  2352,\n",
       "  2358,\n",
       "  2359,\n",
       "  2360,\n",
       "  2376,\n",
       "  2377,\n",
       "  2378,\n",
       "  2383,\n",
       "  2399,\n",
       "  2403,\n",
       "  2405,\n",
       "  2414,\n",
       "  2415,\n",
       "  2422,\n",
       "  2426,\n",
       "  2433,\n",
       "  2442,\n",
       "  2443,\n",
       "  2445,\n",
       "  2446,\n",
       "  2455,\n",
       "  2458,\n",
       "  2462,\n",
       "  2464,\n",
       "  2470,\n",
       "  2475,\n",
       "  2482,\n",
       "  2488,\n",
       "  2496,\n",
       "  2508,\n",
       "  2512,\n",
       "  2523,\n",
       "  2528,\n",
       "  2530,\n",
       "  2537,\n",
       "  2545,\n",
       "  2546,\n",
       "  2548,\n",
       "  2557,\n",
       "  2560,\n",
       "  2586,\n",
       "  2601,\n",
       "  2610,\n",
       "  2620,\n",
       "  2632,\n",
       "  2642,\n",
       "  2643,\n",
       "  2645,\n",
       "  2647,\n",
       "  2658,\n",
       "  2659,\n",
       "  2664,\n",
       "  2665,\n",
       "  2667,\n",
       "  2674,\n",
       "  2676,\n",
       "  2688,\n",
       "  2717,\n",
       "  2719,\n",
       "  2720,\n",
       "  2734,\n",
       "  2743,\n",
       "  2747,\n",
       "  2753,\n",
       "  2780,\n",
       "  2781,\n",
       "  2791,\n",
       "  2792,\n",
       "  2800,\n",
       "  2801,\n",
       "  2807,\n",
       "  2808,\n",
       "  2811,\n",
       "  2813,\n",
       "  2824,\n",
       "  2834,\n",
       "  2836,\n",
       "  2841,\n",
       "  2851,\n",
       "  2852,\n",
       "  2859,\n",
       "  2868,\n",
       "  2877,\n",
       "  2881,\n",
       "  2893,\n",
       "  2896,\n",
       "  2903,\n",
       "  2910,\n",
       "  2912,\n",
       "  2915,\n",
       "  2926,\n",
       "  2928,\n",
       "  2937,\n",
       "  2956,\n",
       "  2967,\n",
       "  2969,\n",
       "  2992,\n",
       "  2995,\n",
       "  3025,\n",
       "  3035,\n",
       "  3043,\n",
       "  3052,\n",
       "  3054,\n",
       "  3061,\n",
       "  3071,\n",
       "  3075,\n",
       "  3076,\n",
       "  3078,\n",
       "  3079,\n",
       "  3084,\n",
       "  3085,\n",
       "  3087,\n",
       "  3091,\n",
       "  3098,\n",
       "  3105,\n",
       "  3126,\n",
       "  3147,\n",
       "  3171,\n",
       "  3175,\n",
       "  3182,\n",
       "  3188,\n",
       "  3191,\n",
       "  3200,\n",
       "  3234,\n",
       "  3241,\n",
       "  3248,\n",
       "  3257,\n",
       "  3262,\n",
       "  3283,\n",
       "  3286,\n",
       "  3288,\n",
       "  3293,\n",
       "  3296,\n",
       "  3297,\n",
       "  3301,\n",
       "  3323,\n",
       "  3339,\n",
       "  3345,\n",
       "  3363,\n",
       "  3385,\n",
       "  3397,\n",
       "  3401,\n",
       "  3404,\n",
       "  3409,\n",
       "  3419,\n",
       "  3426,\n",
       "  3433,\n",
       "  3434,\n",
       "  3451,\n",
       "  3467,\n",
       "  3469,\n",
       "  3486,\n",
       "  3489,\n",
       "  3496,\n",
       "  3510,\n",
       "  3525,\n",
       "  3529,\n",
       "  3530,\n",
       "  3531,\n",
       "  3539,\n",
       "  3544,\n",
       "  3548,\n",
       "  3553,\n",
       "  3555,\n",
       "  3557,\n",
       "  3561,\n",
       "  3563,\n",
       "  3574,\n",
       "  3575,\n",
       "  3586,\n",
       "  3589,\n",
       "  3592,\n",
       "  3593,\n",
       "  3600,\n",
       "  3614,\n",
       "  3621,\n",
       "  3649,\n",
       "  3657,\n",
       "  3675,\n",
       "  3678,\n",
       "  3682,\n",
       "  3683,\n",
       "  3685,\n",
       "  3699,\n",
       "  3700,\n",
       "  3702,\n",
       "  3703,\n",
       "  3708,\n",
       "  3712,\n",
       "  3724,\n",
       "  3725,\n",
       "  3736,\n",
       "  3742,\n",
       "  3744,\n",
       "  3752,\n",
       "  3766,\n",
       "  3782,\n",
       "  3786,\n",
       "  3796,\n",
       "  3805,\n",
       "  3820,\n",
       "  3821,\n",
       "  3823,\n",
       "  3829,\n",
       "  3850,\n",
       "  3855,\n",
       "  3856,\n",
       "  3867,\n",
       "  3877,\n",
       "  3881,\n",
       "  3886,\n",
       "  3889,\n",
       "  3892,\n",
       "  3897,\n",
       "  3899,\n",
       "  3905,\n",
       "  3909,\n",
       "  3918,\n",
       "  3934,\n",
       "  3936,\n",
       "  3950,\n",
       "  3958,\n",
       "  3960,\n",
       "  3966,\n",
       "  3968,\n",
       "  3970,\n",
       "  3973,\n",
       "  3979,\n",
       "  3989,\n",
       "  3995,\n",
       "  3998,\n",
       "  4000,\n",
       "  4010,\n",
       "  4012,\n",
       "  4020},\n",
       " 'Is Other': {96,\n",
       "  122,\n",
       "  125,\n",
       "  263,\n",
       "  322,\n",
       "  343,\n",
       "  378,\n",
       "  402,\n",
       "  456,\n",
       "  458,\n",
       "  480,\n",
       "  620,\n",
       "  634,\n",
       "  643,\n",
       "  680,\n",
       "  709,\n",
       "  783,\n",
       "  817,\n",
       "  860,\n",
       "  961,\n",
       "  1162,\n",
       "  1175,\n",
       "  1331,\n",
       "  1631,\n",
       "  1880,\n",
       "  1904,\n",
       "  1968,\n",
       "  1996,\n",
       "  2024,\n",
       "  2188,\n",
       "  2205,\n",
       "  2232,\n",
       "  2673,\n",
       "  3151,\n",
       "  3205,\n",
       "  3210,\n",
       "  3299,\n",
       "  3935,\n",
       "  3943,\n",
       "  4038,\n",
       "  4065}}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "tg = {k: sorted(list(v)) for k, v in token_groups.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"../data/token_groups.json\", \"w\") as f:\n",
    "    json.dump(tg, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(432,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=432, model='delphi-llama2-100k', logprob_sum=-8307.888183057308, count=17415),\n",
       " (440,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=440, model='delphi-llama2-100k', logprob_sum=-1179.9694573320448, count=16567),\n",
       " (261,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=261, model='delphi-llama2-100k', logprob_sum=-150585.52900058636, count=151848),\n",
       " (403,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=403, model='delphi-llama2-100k', logprob_sum=-9401.606191883911, count=21844),\n",
       " (4045,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=4045, model='delphi-llama2-100k', logprob_sum=-207269.675427588, count=233957),\n",
       " (406,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=406, model='delphi-llama2-100k', logprob_sum=-26130.437831838615, count=21305),\n",
       " (286,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=286, model='delphi-llama2-100k', logprob_sum=-125618.99626725074, count=107556),\n",
       " (799,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=799, model='delphi-llama2-100k', logprob_sum=-12123.617525309324, count=3151),\n",
       " (478,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=478, model='delphi-llama2-100k', logprob_sum=-18903.716076817364, count=12365),\n",
       " (407,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=407, model='delphi-llama2-100k', logprob_sum=-9651.548405426904, count=21040),\n",
       " (385,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=385, model='delphi-llama2-100k', logprob_sum=-37560.27122853976, count=20568),\n",
       " (4037,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=4037, model='delphi-llama2-100k', logprob_sum=-274867.8461031233, count=419484),\n",
       " (505,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=505, model='delphi-llama2-100k', logprob_sum=-20895.584796205163, count=10482),\n",
       " (268,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=268, model='delphi-llama2-100k', logprob_sum=-136369.46767106897, count=150129),\n",
       " (1555,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1555, model='delphi-llama2-100k', logprob_sum=-2180.317711830139, count=389),\n",
       " (622,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=622, model='delphi-llama2-100k', logprob_sum=-16479.318051477894, count=5907),\n",
       " (387,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=387, model='delphi-llama2-100k', logprob_sum=-21857.45202998817, count=15317),\n",
       " (331,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=331, model='delphi-llama2-100k', logprob_sum=-13728.139138053753, count=43098),\n",
       " (397,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=397, model='delphi-llama2-100k', logprob_sum=-35331.459838295355, count=21493),\n",
       " (509,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=509, model='delphi-llama2-100k', logprob_sum=-28463.58284400776, count=10425),\n",
       " (350,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=350, model='delphi-llama2-100k', logprob_sum=-72418.7455187589, count=34938),\n",
       " (614,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=614, model='delphi-llama2-100k', logprob_sum=-13862.97884219396, count=5977),\n",
       " (1318,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1318, model='delphi-llama2-100k', logprob_sum=-5210.574332475662, count=1118),\n",
       " (375,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=375, model='delphi-llama2-100k', logprob_sum=-28468.81613742761, count=25200),\n",
       " (1280,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1280, model='delphi-llama2-100k', logprob_sum=-3918.2366712652147, count=1159),\n",
       " (381,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=381, model='delphi-llama2-100k', logprob_sum=-54592.59120862931, count=25283),\n",
       " (380,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=380, model='delphi-llama2-100k', logprob_sum=-37441.50451241713, count=25793),\n",
       " (13,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=13, model='delphi-llama2-100k', logprob_sum=-68629.48184800183, count=91185),\n",
       " (2112,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2112, model='delphi-llama2-100k', logprob_sum=-6075.0870826561, count=4092),\n",
       " (606,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=606, model='delphi-llama2-100k', logprob_sum=-25576.50695568323, count=6290),\n",
       " (486,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=486, model='delphi-llama2-100k', logprob_sum=-23888.150235034525, count=7107),\n",
       " (2929,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2929, model='delphi-llama2-100k', logprob_sum=-1614.1293687820435, count=215),\n",
       " (4040,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=4040, model='delphi-llama2-100k', logprob_sum=-1730.4620931502432, count=963),\n",
       " (669,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=669, model='delphi-llama2-100k', logprob_sum=-19135.28017473221, count=5047),\n",
       " (269,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=269, model='delphi-llama2-100k', logprob_sum=-258536.64844002645, count=194588),\n",
       " (921,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=921, model='delphi-llama2-100k', logprob_sum=-11373.71804779768, count=2509),\n",
       " (341,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=341, model='delphi-llama2-100k', logprob_sum=-36041.169386230875, count=37723),\n",
       " (2652,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2652, model='delphi-llama2-100k', logprob_sum=-1073.4563946723938, count=250),\n",
       " (492,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=492, model='delphi-llama2-100k', logprob_sum=-28816.198710268363, count=11158),\n",
       " (457,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=457, model='delphi-llama2-100k', logprob_sum=-27744.75704645738, count=14302),\n",
       " (579,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=579, model='delphi-llama2-100k', logprob_sum=-29722.53632134199, count=7090),\n",
       " (544,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=544, model='delphi-llama2-100k', logprob_sum=-27594.45975126326, count=8186),\n",
       " (920,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=920, model='delphi-llama2-100k', logprob_sum=-2082.5957894325256, count=343),\n",
       " (1752,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1752, model='delphi-llama2-100k', logprob_sum=-3354.0809030532837, count=524),\n",
       " (4056,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=4056, model='delphi-llama2-100k', logprob_sum=-47062.34914426878, count=18617),\n",
       " (395,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=395, model='delphi-llama2-100k', logprob_sum=-47754.13096880913, count=18855),\n",
       " (729,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=729, model='delphi-llama2-100k', logprob_sum=-10167.552930183709, count=4074),\n",
       " (412,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=412, model='delphi-llama2-100k', logprob_sum=-47556.82427226752, count=19908),\n",
       " (675,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=675, model='delphi-llama2-100k', logprob_sum=-18605.7873211205, count=4732),\n",
       " (4071,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=4071, model='delphi-llama2-100k', logprob_sum=-1577.710058927536, count=246),\n",
       " (3212,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=3212, model='delphi-llama2-100k', logprob_sum=-84.14499370753765, count=86),\n",
       " (1316,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1316, model='delphi-llama2-100k', logprob_sum=-6333.783849239349, count=1211),\n",
       " (1057,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1057, model='delphi-llama2-100k', logprob_sum=-8425.571177840233, count=1696),\n",
       " (1726,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1726, model='delphi-llama2-100k', logprob_sum=-3348.6774327754974, count=583),\n",
       " (892,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=892, model='delphi-llama2-100k', logprob_sum=-8233.354217082262, count=2508),\n",
       " (1897,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1897, model='delphi-llama2-100k', logprob_sum=-1802.3593538962305, count=503),\n",
       " (993,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=993, model='delphi-llama2-100k', logprob_sum=-9843.402307271957, count=2009),\n",
       " (342,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=342, model='delphi-llama2-100k', logprob_sum=-65437.6459093485, count=38493),\n",
       " (390,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=390, model='delphi-llama2-100k', logprob_sum=-21824.53887132369, count=21231),\n",
       " (720,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=720, model='delphi-llama2-100k', logprob_sum=-7833.757345015183, count=3669),\n",
       " (366,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=366, model='delphi-llama2-100k', logprob_sum=-47455.7790489234, count=29736),\n",
       " (410,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=410, model='delphi-llama2-100k', logprob_sum=-34515.91429725289, count=20029),\n",
       " (425,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=425, model='delphi-llama2-100k', logprob_sum=-39899.869742162526, count=11246),\n",
       " (311,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=311, model='delphi-llama2-100k', logprob_sum=-57498.20430041477, count=52188),\n",
       " (434,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=434, model='delphi-llama2-100k', logprob_sum=-52961.66323093325, count=17045),\n",
       " (628,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=628, model='delphi-llama2-100k', logprob_sum=-12342.385053880513, count=5939),\n",
       " (981,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=981, model='delphi-llama2-100k', logprob_sum=-3670.453022061847, count=2060),\n",
       " (924,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=924, model='delphi-llama2-100k', logprob_sum=-3516.568485688884, count=2363),\n",
       " (888,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=888, model='delphi-llama2-100k', logprob_sum=-7346.444836028852, count=2585),\n",
       " (1,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1, model='delphi-llama2-100k', logprob_sum=-18479.299718447146, count=27511),\n",
       " (367,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=367, model='delphi-llama2-100k', logprob_sum=-5613.086778223515, count=1126),\n",
       " (501,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=501, model='delphi-llama2-100k', logprob_sum=-377.2179862111807, count=148),\n",
       " (1917,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1917, model='delphi-llama2-100k', logprob_sum=-2350.1868218779564, count=481),\n",
       " (372,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=372, model='delphi-llama2-100k', logprob_sum=-25203.102346471976, count=11694),\n",
       " (3398,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=3398, model='delphi-llama2-100k', logprob_sum=-1115.7475950717926, count=166),\n",
       " (577,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=577, model='delphi-llama2-100k', logprob_sum=-26538.549996972084, count=6577),\n",
       " (359,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=359, model='delphi-llama2-100k', logprob_sum=-59394.43541361904, count=25631),\n",
       " (1854,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1854, model='delphi-llama2-100k', logprob_sum=-1925.2099948376417, count=487),\n",
       " (1811,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1811, model='delphi-llama2-100k', logprob_sum=-2187.2254636883736, count=545),\n",
       " (482,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=482, model='delphi-llama2-100k', logprob_sum=-25908.773093402386, count=9479),\n",
       " (698,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=698, model='delphi-llama2-100k', logprob_sum=-15882.704790771008, count=4488),\n",
       " (264,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=264, model='delphi-llama2-100k', logprob_sum=-237800.78725457005, count=209949),\n",
       " (525,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=525, model='delphi-llama2-100k', logprob_sum=-12521.253503884189, count=9166),\n",
       " (1014,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1014, model='delphi-llama2-100k', logprob_sum=-6752.659204062074, count=1849),\n",
       " (429,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=429, model='delphi-llama2-100k', logprob_sum=-45350.72503050417, count=17621),\n",
       " (1004,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1004, model='delphi-llama2-100k', logprob_sum=-3300.3575892448425, count=643),\n",
       " (384,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=384, model='delphi-llama2-100k', logprob_sum=-47507.2030008845, count=24810),\n",
       " (1101,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1101, model='delphi-llama2-100k', logprob_sum=-6211.792765751481, count=1560),\n",
       " (1091,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1091, model='delphi-llama2-100k', logprob_sum=-4447.808271032758, count=1574),\n",
       " (4032,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=4032, model='delphi-llama2-100k', logprob_sum=-24288.217041477397, count=42823),\n",
       " (507,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=507, model='delphi-llama2-100k', logprob_sum=-34048.92972216755, count=10360),\n",
       " (624,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=624, model='delphi-llama2-100k', logprob_sum=-17927.53972554207, count=6121),\n",
       " (837,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=837, model='delphi-llama2-100k', logprob_sum=-5006.776573388837, count=2921),\n",
       " (370,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=370, model='delphi-llama2-100k', logprob_sum=-37003.13807610521, count=27029),\n",
       " (2241,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2241, model='delphi-llama2-100k', logprob_sum=-1602.1098029613495, count=234),\n",
       " (317,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=317, model='delphi-llama2-100k', logprob_sum=-98312.73838175833, count=38740),\n",
       " (670,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=670, model='delphi-llama2-100k', logprob_sum=-4642.016611814499, count=869),\n",
       " (1728,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1728, model='delphi-llama2-100k', logprob_sum=-2646.5350339710712, count=610),\n",
       " (959,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=959, model='delphi-llama2-100k', logprob_sum=-5341.023637890816, count=1150),\n",
       " (829,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=829, model='delphi-llama2-100k', logprob_sum=-10477.966302931309, count=2907),\n",
       " (1067,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1067, model='delphi-llama2-100k', logprob_sum=-3677.979906268418, count=1689),\n",
       " (424,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=424, model='delphi-llama2-100k', logprob_sum=-38598.64833884314, count=17305),\n",
       " (466,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=466, model='delphi-llama2-100k', logprob_sum=-25602.49306824431, count=13072),\n",
       " (3824,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=3824, model='delphi-llama2-100k', logprob_sum=-518.7817126512527, count=98),\n",
       " (1526,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1526, model='delphi-llama2-100k', logprob_sum=-4783.561835885048, count=768),\n",
       " (1102,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1102, model='delphi-llama2-100k', logprob_sum=-3704.4464192921296, count=1603),\n",
       " (1256,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1256, model='delphi-llama2-100k', logprob_sum=-3931.415304630995, count=1115),\n",
       " (515,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=515, model='delphi-llama2-100k', logprob_sum=-25328.1303319484, count=9662),\n",
       " (1019,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1019, model='delphi-llama2-100k', logprob_sum=-9530.377584815025, count=1899),\n",
       " (697,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=697, model='delphi-llama2-100k', logprob_sum=-15469.85566085577, count=4457),\n",
       " (713,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=713, model='delphi-llama2-100k', logprob_sum=-15182.873721659184, count=4465),\n",
       " (602,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=602, model='delphi-llama2-100k', logprob_sum=-14167.94644734636, count=6016),\n",
       " (886,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=886, model='delphi-llama2-100k', logprob_sum=-10183.264666803181, count=2584),\n",
       " (560,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=560, model='delphi-llama2-100k', logprob_sum=-22648.770629048347, count=7634),\n",
       " (1000,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1000, model='delphi-llama2-100k', logprob_sum=-4283.318835604936, count=1941),\n",
       " (2567,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2567, model='delphi-llama2-100k', logprob_sum=-1980.3642435073853, count=272),\n",
       " (500,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=500, model='delphi-llama2-100k', logprob_sum=-19333.92378589604, count=10833),\n",
       " (1235,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1235, model='delphi-llama2-100k', logprob_sum=-6081.393727302551, count=1229),\n",
       " (369,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=369, model='delphi-llama2-100k', logprob_sum=-72439.45319782197, count=28874),\n",
       " (4001,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=4001, model='delphi-llama2-100k', logprob_sum=-620.8694496825337, count=159),\n",
       " (313,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=313, model='delphi-llama2-100k', logprob_sum=-100029.59973216197, count=51307),\n",
       " (282,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=282, model='delphi-llama2-100k', logprob_sum=-68286.12958767405, count=47010),\n",
       " (1030,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1030, model='delphi-llama2-100k', logprob_sum=-7583.451973795891, count=1881),\n",
       " (1365,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1365, model='delphi-llama2-100k', logprob_sum=-4624.72452044487, count=938),\n",
       " (1700,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1700, model='delphi-llama2-100k', logprob_sum=-3228.159956395626, count=628),\n",
       " (4053,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=4053, model='delphi-llama2-100k', logprob_sum=-7842.190741949715, count=10356),\n",
       " (3935,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=3935, model='delphi-llama2-100k', logprob_sum=-649.6267558646505, count=9509),\n",
       " (2042,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2042, model='delphi-llama2-100k', logprob_sum=-1794.8214253783226, count=431),\n",
       " (551,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=551, model='delphi-llama2-100k', logprob_sum=-19448.60345590487, count=8338),\n",
       " (858,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=858, model='delphi-llama2-100k', logprob_sum=-5963.485726501793, count=1862),\n",
       " (1521,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1521, model='delphi-llama2-100k', logprob_sum=-2073.007172241807, count=918),\n",
       " (876,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=876, model='delphi-llama2-100k', logprob_sum=-9389.306504954584, count=2555),\n",
       " (1516,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1516, model='delphi-llama2-100k', logprob_sum=-4019.6857835054398, count=873),\n",
       " (889,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=889, model='delphi-llama2-100k', logprob_sum=-10396.593260630965, count=2572),\n",
       " (495,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=495, model='delphi-llama2-100k', logprob_sum=-22124.354784704745, count=11232),\n",
       " (467,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=467, model='delphi-llama2-100k', logprob_sum=-28430.83628543839, count=11192),\n",
       " (712,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=712, model='delphi-llama2-100k', logprob_sum=-11372.069007307291, count=3803),\n",
       " (844,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=844, model='delphi-llama2-100k', logprob_sum=-5196.820335317869, count=2794),\n",
       " (4060,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=4060, model='delphi-llama2-100k', logprob_sum=-16776.203116431832, count=8212),\n",
       " (503,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=503, model='delphi-llama2-100k', logprob_sum=-11627.60841033049, count=5290),\n",
       " (435,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=435, model='delphi-llama2-100k', logprob_sum=-26952.469406079035, count=13162),\n",
       " (316,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=316, model='delphi-llama2-100k', logprob_sum=-50198.01291294256, count=49155),\n",
       " (711,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=711, model='delphi-llama2-100k', logprob_sum=-16816.40267699957, count=4393),\n",
       " (3749,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=3749, model='delphi-llama2-100k', logprob_sum=-1017.7812118530273, count=158),\n",
       " (1126,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1126, model='delphi-llama2-100k', logprob_sum=-8445.293231248856, count=1580),\n",
       " (601,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=601, model='delphi-llama2-100k', logprob_sum=-21074.542423263192, count=5650),\n",
       " (1301,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1301, model='delphi-llama2-100k', logprob_sum=-1871.1829713582993, count=295),\n",
       " (1947,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1947, model='delphi-llama2-100k', logprob_sum=-1957.853378918022, count=566),\n",
       " (2164,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2164, model='delphi-llama2-100k', logprob_sum=-2497.6384100914, count=424),\n",
       " (599,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=599, model='delphi-llama2-100k', logprob_sum=-24013.598751218058, count=6599),\n",
       " (3673,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=3673, model='delphi-llama2-100k', logprob_sum=-1024.2394304275513, count=111),\n",
       " (1104,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1104, model='delphi-llama2-100k', logprob_sum=-8174.8072682619095, count=1572),\n",
       " (1515,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1515, model='delphi-llama2-100k', logprob_sum=-1928.5542156994343, count=745),\n",
       " (3018,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=3018, model='delphi-llama2-100k', logprob_sum=-1566.787005662918, count=232),\n",
       " (3158,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=3158, model='delphi-llama2-100k', logprob_sum=-1061.8167496919632, count=189),\n",
       " (4054,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=4054, model='delphi-llama2-100k', logprob_sum=-50703.832288629936, count=41177),\n",
       " (1788,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1788, model='delphi-llama2-100k', logprob_sum=-2651.9338334798813, count=539),\n",
       " (330,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=330, model='delphi-llama2-100k', logprob_sum=-48244.78036542982, count=37800),\n",
       " (477,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=477, model='delphi-llama2-100k', logprob_sum=-23341.474450707436, count=11475),\n",
       " (326,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=326, model='delphi-llama2-100k', logprob_sum=-39288.989949245006, count=24636),\n",
       " (332,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=332, model='delphi-llama2-100k', logprob_sum=-84431.51035606675, count=42768),\n",
       " (345,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=345, model='delphi-llama2-100k', logprob_sum=-70457.55642100493, count=38618),\n",
       " (415,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=415, model='delphi-llama2-100k', logprob_sum=-25738.005046429695, count=19423),\n",
       " (4026,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=4026, model='delphi-llama2-100k', logprob_sum=-4681.911520883768, count=14223),\n",
       " (363,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=363, model='delphi-llama2-100k', logprob_sum=-17733.812844001455, count=9804),\n",
       " (504,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=504, model='delphi-llama2-100k', logprob_sum=-16624.44399268739, count=9553),\n",
       " (327,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=327, model='delphi-llama2-100k', logprob_sum=-68286.89681806788, count=43508),\n",
       " (307,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=307, model='delphi-llama2-100k', logprob_sum=-27214.61829027065, count=48830),\n",
       " (1088,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1088, model='delphi-llama2-100k', logprob_sum=-3373.2517703026533, count=1650),\n",
       " (832,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=832, model='delphi-llama2-100k', logprob_sum=-12260.731413573027, count=2957),\n",
       " (411,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=411, model='delphi-llama2-100k', logprob_sum=-34333.051152065396, count=19663),\n",
       " (413,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=413, model='delphi-llama2-100k', logprob_sum=-22889.03831784008, count=17632),\n",
       " (3821,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=3821, model='delphi-llama2-100k', logprob_sum=-582.5124964416027, count=131),\n",
       " (543,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=543, model='delphi-llama2-100k', logprob_sum=-24130.87918008305, count=8486),\n",
       " (1901,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1901, model='delphi-llama2-100k', logprob_sum=-2210.8478595018387, count=541),\n",
       " (468,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=468, model='delphi-llama2-100k', logprob_sum=-23165.90574304387, count=12359),\n",
       " (340,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=340, model='delphi-llama2-100k', logprob_sum=-28372.28549745679, count=18384),\n",
       " (471,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=471, model='delphi-llama2-100k', logprob_sum=-11057.995320104063, count=12071),\n",
       " (567,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=567, model='delphi-llama2-100k', logprob_sum=-21886.71235898137, count=7638),\n",
       " (1495,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1495, model='delphi-llama2-100k', logprob_sum=-2577.6428919434547, count=885),\n",
       " (1181,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1181, model='delphi-llama2-100k', logprob_sum=-2531.5230657458305, count=505),\n",
       " (324,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=324, model='delphi-llama2-100k', logprob_sum=-30887.437264923006, count=13207),\n",
       " (559,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=559, model='delphi-llama2-100k', logprob_sum=-19376.23958107829, count=6891),\n",
       " (398,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=398, model='delphi-llama2-100k', logprob_sum=-36727.57169709355, count=21964),\n",
       " (4057,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=4057, model='delphi-llama2-100k', logprob_sum=-4532.951385729015, count=1657),\n",
       " (1497,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1497, model='delphi-llama2-100k', logprob_sum=-72.42996371537447, count=83),\n",
       " (474,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=474, model='delphi-llama2-100k', logprob_sum=-28056.270981620997, count=12381),\n",
       " (757,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=757, model='delphi-llama2-100k', logprob_sum=-5087.3496936376905, count=3675),\n",
       " (443,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=443, model='delphi-llama2-100k', logprob_sum=-22811.955473690876, count=13969),\n",
       " (718,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=718, model='delphi-llama2-100k', logprob_sum=-11098.430332928896, count=2711),\n",
       " (583,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=583, model='delphi-llama2-100k', logprob_sum=-22739.039746433496, count=6944),\n",
       " (904,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=904, model='delphi-llama2-100k', logprob_sum=-1784.6408425280824, count=2445),\n",
       " (801,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=801, model='delphi-llama2-100k', logprob_sum=-1796.8496067552478, count=3127),\n",
       " (388,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=388, model='delphi-llama2-100k', logprob_sum=-9481.61401951313, count=2258),\n",
       " (575,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=575, model='delphi-llama2-100k', logprob_sum=-15138.47351012379, count=7145),\n",
       " (1670,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1670, model='delphi-llama2-100k', logprob_sum=-3414.3142869472504, count=636),\n",
       " (422,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=422, model='delphi-llama2-100k', logprob_sum=-18722.586640179157, count=5720),\n",
       " (823,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=823, model='delphi-llama2-100k', logprob_sum=-2364.9650921931025, count=3035),\n",
       " (895,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=895, model='delphi-llama2-100k', logprob_sum=-5879.506444945931, count=2478),\n",
       " (572,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=572, model='delphi-llama2-100k', logprob_sum=-19291.01316844113, count=7035),\n",
       " (625,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=625, model='delphi-llama2-100k', logprob_sum=-16548.815319031477, count=5510),\n",
       " (752,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=752, model='delphi-llama2-100k', logprob_sum=-14502.423465967178, count=3471),\n",
       " (4047,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=4047, model='delphi-llama2-100k', logprob_sum=-7944.828968316317, count=2412),\n",
       " (4027,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=4027, model='delphi-llama2-100k', logprob_sum=-4914.041024692357, count=3979),\n",
       " (454,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=454, model='delphi-llama2-100k', logprob_sum=-48.26717188069597, count=222),\n",
       " (391,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=391, model='delphi-llama2-100k', logprob_sum=-56691.10930927005, count=21981),\n",
       " (777,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=777, model='delphi-llama2-100k', logprob_sum=-10913.82538881898, count=2619),\n",
       " (660,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=660, model='delphi-llama2-100k', logprob_sum=-13546.080581199378, count=4996),\n",
       " (1196,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1196, model='delphi-llama2-100k', logprob_sum=-2920.860192462802, count=1410),\n",
       " (997,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=997, model='delphi-llama2-100k', logprob_sum=-3088.064556928264, count=2031),\n",
       " (433,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=433, model='delphi-llama2-100k', logprob_sum=-21154.350488648284, count=16440),\n",
       " (386,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=386, model='delphi-llama2-100k', logprob_sum=-52867.9059853123, count=24505),\n",
       " (872,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=872, model='delphi-llama2-100k', logprob_sum=-13235.25618392229, count=2642),\n",
       " (631,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=631, model='delphi-llama2-100k', logprob_sum=-24069.16661298275, count=5622),\n",
       " (1587,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1587, model='delphi-llama2-100k', logprob_sum=-2367.4449874628335, count=751),\n",
       " (534,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=534, model='delphi-llama2-100k', logprob_sum=-24105.346024900675, count=7822),\n",
       " (1688,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1688, model='delphi-llama2-100k', logprob_sum=-3963.364117860794, count=613),\n",
       " (1183,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1183, model='delphi-llama2-100k', logprob_sum=-7233.625628173351, count=1372),\n",
       " (787,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=787, model='delphi-llama2-100k', logprob_sum=-5952.425135821104, count=1937),\n",
       " (396,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=396, model='delphi-llama2-100k', logprob_sum=-35366.99018897652, count=19054),\n",
       " (484,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=484, model='delphi-llama2-100k', logprob_sum=-16271.492150751874, count=11518),\n",
       " (519,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=519, model='delphi-llama2-100k', logprob_sum=-24729.434556068853, count=8653),\n",
       " (541,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=541, model='delphi-llama2-100k', logprob_sum=-19890.907532811165, count=7460),\n",
       " (3278,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=3278, model='delphi-llama2-100k', logprob_sum=-487.86977409757674, count=156),\n",
       " (1143,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1143, model='delphi-llama2-100k', logprob_sum=-4715.67968198657, count=1477),\n",
       " (663,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=663, model='delphi-llama2-100k', logprob_sum=-14994.074913322926, count=5148),\n",
       " (510,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=510, model='delphi-llama2-100k', logprob_sum=-3161.0435978770256, count=419),\n",
       " (1311,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1311, model='delphi-llama2-100k', logprob_sum=-427.92528631165624, count=221),\n",
       " (4048,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=4048, model='delphi-llama2-100k', logprob_sum=-14952.537914472166, count=12642),\n",
       " (1100,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1100, model='delphi-llama2-100k', logprob_sum=-3580.9301199764013, count=1606),\n",
       " (655,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=655, model='delphi-llama2-100k', logprob_sum=-5935.762620597146, count=5075),\n",
       " (1051,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1051, model='delphi-llama2-100k', logprob_sum=-5480.646248102188, count=1880),\n",
       " (1213,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1213, model='delphi-llama2-100k', logprob_sum=-6739.2166657447815, count=1292),\n",
       " (732,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=732, model='delphi-llama2-100k', logprob_sum=-4511.546476805583, count=4116),\n",
       " (632,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=632, model='delphi-llama2-100k', logprob_sum=-15917.077916637063, count=5734),\n",
       " (1844,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1844, model='delphi-llama2-100k', logprob_sum=-10594.505805164576, count=3593),\n",
       " (368,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=368, model='delphi-llama2-100k', logprob_sum=-17267.130629241467, count=5479),\n",
       " (2147,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2147, model='delphi-llama2-100k', logprob_sum=-1764.5460320711136, count=373),\n",
       " (1317,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1317, model='delphi-llama2-100k', logprob_sum=-5016.4426638484, count=1099),\n",
       " (896,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=896, model='delphi-llama2-100k', logprob_sum=-10023.02084928751, count=2336),\n",
       " (822,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=822, model='delphi-llama2-100k', logprob_sum=-4675.457979977131, count=1347),\n",
       " (1942,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1942, model='delphi-llama2-100k', logprob_sum=-5461.305574478582, count=3439),\n",
       " (1620,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1620, model='delphi-llama2-100k', logprob_sum=-2389.7523630857468, count=720),\n",
       " (1839,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1839, model='delphi-llama2-100k', logprob_sum=-1584.5321506261826, count=467),\n",
       " (2685,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2685, model='delphi-llama2-100k', logprob_sum=-1673.1496176719666, count=216),\n",
       " (1309,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1309, model='delphi-llama2-100k', logprob_sum=-4157.7635489702225, count=1157),\n",
       " (984,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=984, model='delphi-llama2-100k', logprob_sum=-6742.042004153132, count=2024),\n",
       " (3630,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=3630, model='delphi-llama2-100k', logprob_sum=-1092.6159119606018, count=138),\n",
       " (518,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=518, model='delphi-llama2-100k', logprob_sum=-823.401353658177, count=389),\n",
       " (1238,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1238, model='delphi-llama2-100k', logprob_sum=-5763.820513784885, count=1322),\n",
       " (796,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=796, model='delphi-llama2-100k', logprob_sum=-6001.0889941602945, count=1573),\n",
       " (1293,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1293, model='delphi-llama2-100k', logprob_sum=-4111.322653267533, count=1136),\n",
       " (547,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=547, model='delphi-llama2-100k', logprob_sum=-12023.898039616644, count=3181),\n",
       " (1254,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1254, model='delphi-llama2-100k', logprob_sum=-6058.743788123131, count=1239),\n",
       " (887,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=887, model='delphi-llama2-100k', logprob_sum=-10094.18115618825, count=2564),\n",
       " (616,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=616, model='delphi-llama2-100k', logprob_sum=-12562.778915748, count=5849),\n",
       " (354,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=354, model='delphi-llama2-100k', logprob_sum=-29525.759100882162, count=28177),\n",
       " (1034,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1034, model='delphi-llama2-100k', logprob_sum=-2531.9519317522645, count=1025),\n",
       " (1931,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1931, model='delphi-llama2-100k', logprob_sum=-255.28350734710693, count=26),\n",
       " (945,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=945, model='delphi-llama2-100k', logprob_sum=-444.00651411764557, count=608),\n",
       " (2012,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2012, model='delphi-llama2-100k', logprob_sum=-1813.0740970373154, count=436),\n",
       " (2052,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2052, model='delphi-llama2-100k', logprob_sum=-2859.970588684082, count=455),\n",
       " (1103,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1103, model='delphi-llama2-100k', logprob_sum=-1844.2638178616762, count=368),\n",
       " (1873,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1873, model='delphi-llama2-100k', logprob_sum=-1297.1381556987762, count=213),\n",
       " (1134,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1134, model='delphi-llama2-100k', logprob_sum=-3007.6766847372055, count=614),\n",
       " (1369,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1369, model='delphi-llama2-100k', logprob_sum=-2563.5093397647142, count=967),\n",
       " (626,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=626, model='delphi-llama2-100k', logprob_sum=-3419.214287519455, count=442),\n",
       " (463,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=463, model='delphi-llama2-100k', logprob_sum=-482.0314843133092, count=326),\n",
       " (4038,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=4038, model='delphi-llama2-100k', logprob_sum=-3315.817830549553, count=928),\n",
       " (3895,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=3895, model='delphi-llama2-100k', logprob_sum=-90.80814646556973, count=116),\n",
       " (3111,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=3111, model='delphi-llama2-100k', logprob_sum=-641.0541359782219, count=178),\n",
       " (4050,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=4050, model='delphi-llama2-100k', logprob_sum=-14160.87977720797, count=5242),\n",
       " (766,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=766, model='delphi-llama2-100k', logprob_sum=-872.4766107918695, count=1010),\n",
       " (1821,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1821, model='delphi-llama2-100k', logprob_sum=-1725.3955295085907, count=516),\n",
       " (2532,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2532, model='delphi-llama2-100k', logprob_sum=-1171.1237672567368, count=276),\n",
       " (2223,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2223, model='delphi-llama2-100k', logprob_sum=-1424.2912335395813, count=335),\n",
       " (1962,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1962, model='delphi-llama2-100k', logprob_sum=-1232.9899306111038, count=447),\n",
       " (1434,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1434, model='delphi-llama2-100k', logprob_sum=-3861.64783680439, count=942),\n",
       " (3560,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=3560, model='delphi-llama2-100k', logprob_sum=-545.1975323781371, count=126),\n",
       " (607,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=607, model='delphi-llama2-100k', logprob_sum=-17189.860363453627, count=6332),\n",
       " (4052,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=4052, model='delphi-llama2-100k', logprob_sum=-17554.705426760018, count=9797),\n",
       " (735,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=735, model='delphi-llama2-100k', logprob_sum=-16390.137991070747, count=4006),\n",
       " (539,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=539, model='delphi-llama2-100k', logprob_sum=-6017.851866334677, count=2515),\n",
       " (939,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=939, model='delphi-llama2-100k', logprob_sum=-7004.374821275473, count=2199),\n",
       " (617,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=617, model='delphi-llama2-100k', logprob_sum=-9569.739454045892, count=5673),\n",
       " (524,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=524, model='delphi-llama2-100k', logprob_sum=-12541.936262448784, count=6437),\n",
       " (779,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=779, model='delphi-llama2-100k', logprob_sum=-6182.726673755329, count=3469),\n",
       " (3690,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=3690, model='delphi-llama2-100k', logprob_sum=-899.398848772049, count=161),\n",
       " (288,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=288, model='delphi-llama2-100k', logprob_sum=-48827.3730467353, count=32859),\n",
       " (1345,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1345, model='delphi-llama2-100k', logprob_sum=-4865.899679005146, count=1044),\n",
       " (453,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=453, model='delphi-llama2-100k', logprob_sum=-36919.424418121576, count=11499),\n",
       " (612,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=612, model='delphi-llama2-100k', logprob_sum=-6108.447943329811, count=1291),\n",
       " (1498,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1498, model='delphi-llama2-100k', logprob_sum=-844.3058241825784, count=831),\n",
       " (489,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=489, model='delphi-llama2-100k', logprob_sum=-28821.712659299374, count=8643),\n",
       " (2068,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2068, model='delphi-llama2-100k', logprob_sum=-980.5749118234962, count=444),\n",
       " (2851,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2851, model='delphi-llama2-100k', logprob_sum=-317.26954859495163, count=214),\n",
       " (394,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=394, model='delphi-llama2-100k', logprob_sum=-44507.49868307263, count=23802),\n",
       " (3621,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=3621, model='delphi-llama2-100k', logprob_sum=-884.0253291130066, count=146),\n",
       " (707,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=707, model='delphi-llama2-100k', logprob_sum=-9659.20057392586, count=4472),\n",
       " (992,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=992, model='delphi-llama2-100k', logprob_sum=-9134.852061033249, count=2025),\n",
       " (421,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=421, model='delphi-llama2-100k', logprob_sum=-1705.9536555870436, count=864),\n",
       " (1998,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1998, model='delphi-llama2-100k', logprob_sum=-2364.146763443947, count=469),\n",
       " (1022,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1022, model='delphi-llama2-100k', logprob_sum=-4073.146684244275, count=1934),\n",
       " (502,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=502, model='delphi-llama2-100k', logprob_sum=-27370.97134178877, count=10377),\n",
       " (745,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=745, model='delphi-llama2-100k', logprob_sum=-15536.951192706823, count=3793),\n",
       " (623,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=623, model='delphi-llama2-100k', logprob_sum=-15250.232338417321, count=5485),\n",
       " (806,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=806, model='delphi-llama2-100k', logprob_sum=-6263.407369082794, count=2381),\n",
       " (1394,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1394, model='delphi-llama2-100k', logprob_sum=-3828.646357625723, count=979),\n",
       " (862,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=862, model='delphi-llama2-100k', logprob_sum=-10256.795525968075, count=2304),\n",
       " (1164,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1164, model='delphi-llama2-100k', logprob_sum=-6729.717947578058, count=1297),\n",
       " (2433,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2433, model='delphi-llama2-100k', logprob_sum=-1714.9400166273117, count=299),\n",
       " (754,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=754, model='delphi-llama2-100k', logprob_sum=-15867.48402416706, count=3758),\n",
       " (1530,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1530, model='delphi-llama2-100k', logprob_sum=-3271.588918477297, count=831),\n",
       " (610,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=610, model='delphi-llama2-100k', logprob_sum=-15851.747674327344, count=6450),\n",
       " (1035,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1035, model='delphi-llama2-100k', logprob_sum=-4981.371967077255, count=1561),\n",
       " (635,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=635, model='delphi-llama2-100k', logprob_sum=-12356.658711474389, count=5854),\n",
       " (1461,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1461, model='delphi-llama2-100k', logprob_sum=-5156.523537993431, count=953),\n",
       " (1395,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1395, model='delphi-llama2-100k', logprob_sum=-3631.5145628051832, count=949),\n",
       " (917,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=917, model='delphi-llama2-100k', logprob_sum=-9114.720046281815, count=2159),\n",
       " (1211,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1211, model='delphi-llama2-100k', logprob_sum=-3970.786314368248, count=771),\n",
       " (1315,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1315, model='delphi-llama2-100k', logprob_sum=-4402.855592310429, count=1067),\n",
       " (1061,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1061, model='delphi-llama2-100k', logprob_sum=-6258.6609479263425, count=1770),\n",
       " (2645,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2645, model='delphi-llama2-100k', logprob_sum=-1087.7964992523193, count=238),\n",
       " (810,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=810, model='delphi-llama2-100k', logprob_sum=-5328.763680398464, count=1348),\n",
       " (869,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=869, model='delphi-llama2-100k', logprob_sum=-5713.7020098008215, count=2497),\n",
       " (770,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=770, model='delphi-llama2-100k', logprob_sum=-3647.0717237368226, count=1157),\n",
       " (1086,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1086, model='delphi-llama2-100k', logprob_sum=-7401.195590145886, count=1628),\n",
       " (1376,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1376, model='delphi-llama2-100k', logprob_sum=-4795.263516962528, count=1036),\n",
       " (3442,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=3442, model='delphi-llama2-100k', logprob_sum=-535.8396240845323, count=140),\n",
       " (460,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=460, model='delphi-llama2-100k', logprob_sum=-22921.26872279588, count=12527),\n",
       " (1360,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1360, model='delphi-llama2-100k', logprob_sum=-5706.897490203381, count=998),\n",
       " (531,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=531, model='delphi-llama2-100k', logprob_sum=-23448.9556710124, count=9001),\n",
       " (1407,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1407, model='delphi-llama2-100k', logprob_sum=-2922.458784211427, count=933),\n",
       " (2556,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2556, model='delphi-llama2-100k', logprob_sum=-1635.0799416303635, count=272),\n",
       " (445,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=445, model='delphi-llama2-100k', logprob_sum=-23996.07101525739, count=9201),\n",
       " (930,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=930, model='delphi-llama2-100k', logprob_sum=-4476.21759647876, count=2103),\n",
       " (798,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=798, model='delphi-llama2-100k', logprob_sum=-6517.520116224885, count=3070),\n",
       " (861,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=861, model='delphi-llama2-100k', logprob_sum=-8621.365989655256, count=2746),\n",
       " (769,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=769, model='delphi-llama2-100k', logprob_sum=-6507.626415014267, count=2025),\n",
       " (1037,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1037, model='delphi-llama2-100k', logprob_sum=-4859.122698664665, count=1845),\n",
       " (1135,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1135, model='delphi-llama2-100k', logprob_sum=-6147.0553433299065, count=1493),\n",
       " (780,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=780, model='delphi-llama2-100k', logprob_sum=-9858.66612466774, count=3557),\n",
       " (549,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=549, model='delphi-llama2-100k', logprob_sum=-28828.646812677383, count=8304),\n",
       " (1229,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1229, model='delphi-llama2-100k', logprob_sum=-2304.5674493312836, count=308),\n",
       " (545,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=545, model='delphi-llama2-100k', logprob_sum=-685.7799012791365, count=413),\n",
       " (1016,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1016, model='delphi-llama2-100k', logprob_sum=-756.7845815464389, count=374),\n",
       " (716,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=716, model='delphi-llama2-100k', logprob_sum=-15254.684145152569, count=4468),\n",
       " (1627,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1627, model='delphi-llama2-100k', logprob_sum=-3883.940268278122, count=698),\n",
       " (667,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=667, model='delphi-llama2-100k', logprob_sum=-13735.99890290387, count=5093),\n",
       " (733,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=733, model='delphi-llama2-100k', logprob_sum=-11328.818991452456, count=3834),\n",
       " (4029,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=4029, model='delphi-llama2-100k', logprob_sum=-5972.4664483872475, count=3069),\n",
       " (2287,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2287, model='delphi-llama2-100k', logprob_sum=-2026.1863768100739, count=339),\n",
       " (469,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=469, model='delphi-llama2-100k', logprob_sum=-34507.86435186118, count=12501),\n",
       " (1770,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1770, model='delphi-llama2-100k', logprob_sum=-2273.791415050626, count=503),\n",
       " (1702,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1702, model='delphi-llama2-100k', logprob_sum=-1657.3265574909747, count=599),\n",
       " (648,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=648, model='delphi-llama2-100k', logprob_sum=-5181.640225721989, count=2452),\n",
       " (682,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=682, model='delphi-llama2-100k', logprob_sum=-15489.56349053979, count=4585),\n",
       " (702,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=702, model='delphi-llama2-100k', logprob_sum=-15163.028053879738, count=4501),\n",
       " (805,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=805, model='delphi-llama2-100k', logprob_sum=-17279.822612047195, count=3122),\n",
       " (1009,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1009, model='delphi-llama2-100k', logprob_sum=-7145.215389847755, count=1909),\n",
       " (2062,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2062, model='delphi-llama2-100k', logprob_sum=-2695.234347343445, count=423),\n",
       " (2451,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2451, model='delphi-llama2-100k', logprob_sum=-1872.8334004282951, count=323),\n",
       " (811,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=811, model='delphi-llama2-100k', logprob_sum=-12354.513798713684, count=2797),\n",
       " (1328,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1328, model='delphi-llama2-100k', logprob_sum=-5433.284677095711, count=1196),\n",
       " (587,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=587, model='delphi-llama2-100k', logprob_sum=-11736.83872269094, count=3537),\n",
       " (1146,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1146, model='delphi-llama2-100k', logprob_sum=-4672.462004840374, count=1492),\n",
       " (1299,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1299, model='delphi-llama2-100k', logprob_sum=-2866.6501820608974, count=1190),\n",
       " (1891,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1891, model='delphi-llama2-100k', logprob_sum=-21665.442757641897, count=17222),\n",
       " (374,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=374, model='delphi-llama2-100k', logprob_sum=-13155.819621518254, count=7786),\n",
       " (737,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=737, model='delphi-llama2-100k', logprob_sum=-5579.78949829936, count=2688),\n",
       " (1439,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1439, model='delphi-llama2-100k', logprob_sum=-5272.252313375473, count=900),\n",
       " (989,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=989, model='delphi-llama2-100k', logprob_sum=-10309.415244698524, count=2082),\n",
       " (2413,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2413, model='delphi-llama2-100k', logprob_sum=-1751.8104481697083, count=303),\n",
       " (840,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=840, model='delphi-llama2-100k', logprob_sum=-4452.122948268428, count=2928),\n",
       " (4035,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=4035, model='delphi-llama2-100k', logprob_sum=-8457.704491624143, count=6560),\n",
       " (638,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=638, model='delphi-llama2-100k', logprob_sum=-1962.639416217804, count=254),\n",
       " (2114,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2114, model='delphi-llama2-100k', logprob_sum=-379.4362865462899, count=205),\n",
       " (1748,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1748, model='delphi-llama2-100k', logprob_sum=-2468.094850599766, count=587),\n",
       " (1105,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1105, model='delphi-llama2-100k', logprob_sum=-6293.837068773806, count=1664),\n",
       " (687,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=687, model='delphi-llama2-100k', logprob_sum=-13847.448910817504, count=4675),\n",
       " (949,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=949, model='delphi-llama2-100k', logprob_sum=-5675.929556131363, count=2098),\n",
       " (962,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=962, model='delphi-llama2-100k', logprob_sum=-4813.889331743121, count=2147),\n",
       " (3988,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=3988, model='delphi-llama2-100k', logprob_sum=-512.3788496479392, count=132),\n",
       " (420,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=420, model='delphi-llama2-100k', logprob_sum=-26609.287347828504, count=17331),\n",
       " (1810,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1810, model='delphi-llama2-100k', logprob_sum=-1417.770658493042, count=166),\n",
       " (677,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=677, model='delphi-llama2-100k', logprob_sum=-442.08007353311405, count=407),\n",
       " (940,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=940, model='delphi-llama2-100k', logprob_sum=-8136.53135356307, count=2224),\n",
       " (728,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=728, model='delphi-llama2-100k', logprob_sum=-16829.946371495724, count=4095),\n",
       " (585,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=585, model='delphi-llama2-100k', logprob_sum=-17255.523845572025, count=7026),\n",
       " (2038,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2038, model='delphi-llama2-100k', logprob_sum=-1509.291984796524, count=253),\n",
       " (1237,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1237, model='delphi-llama2-100k', logprob_sum=-5206.716533780098, count=1231),\n",
       " (656,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=656, model='delphi-llama2-100k', logprob_sum=-9293.816119091585, count=4873),\n",
       " (580,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=580, model='delphi-llama2-100k', logprob_sum=-15807.987591691315, count=7032),\n",
       " (379,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=379, model='delphi-llama2-100k', logprob_sum=-17574.711834556423, count=6259),\n",
       " (582,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=582, model='delphi-llama2-100k', logprob_sum=-24627.557903543115, count=6879),\n",
       " (838,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=838, model='delphi-llama2-100k', logprob_sum=-9970.699522018433, count=2914),\n",
       " (723,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=723, model='delphi-llama2-100k', logprob_sum=-19556.205936677754, count=4102),\n",
       " (1645,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1645, model='delphi-llama2-100k', logprob_sum=-1965.1819100882858, count=627),\n",
       " (552,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=552, model='delphi-llama2-100k', logprob_sum=-14922.23673180095, count=6581),\n",
       " (1248,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1248, model='delphi-llama2-100k', logprob_sum=-5084.73407548666, count=1254),\n",
       " (782,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=782, model='delphi-llama2-100k', logprob_sum=-138.5426989942789, count=130),\n",
       " (885,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=885, model='delphi-llama2-100k', logprob_sum=-475.2356791496277, count=61),\n",
       " (318,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=318, model='delphi-llama2-100k', logprob_sum=-951.2232907284051, count=535),\n",
       " (988,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=988, model='delphi-llama2-100k', logprob_sum=-1088.2590236258693, count=696),\n",
       " (1437,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1437, model='delphi-llama2-100k', logprob_sum=-4610.657659769058, count=896),\n",
       " (908,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=908, model='delphi-llama2-100k', logprob_sum=-5151.663560390472, count=1424),\n",
       " (1779,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1779, model='delphi-llama2-100k', logprob_sum=-737.3966829925776, count=525),\n",
       " (894,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=894, model='delphi-llama2-100k', logprob_sum=-8937.323208600283, count=2561),\n",
       " (3936,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=3936, model='delphi-llama2-100k', logprob_sum=-654.7092788219452, count=129),\n",
       " (3970,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=3970, model='delphi-llama2-100k', logprob_sum=-548.2271795272827, count=112),\n",
       " (3188,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=3188, model='delphi-llama2-100k', logprob_sum=-963.0919435024261, count=166),\n",
       " (1448,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1448, model='delphi-llama2-100k', logprob_sum=-3778.013473302126, count=959),\n",
       " (1652,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1652, model='delphi-llama2-100k', logprob_sum=-2315.124507457018, count=678),\n",
       " (1397,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1397, model='delphi-llama2-100k', logprob_sum=-5327.270740389824, count=1004),\n",
       " (2317,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2317, model='delphi-llama2-100k', logprob_sum=-2157.9811491966248, count=341),\n",
       " (581,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=581, model='delphi-llama2-100k', logprob_sum=-25668.245160251856, count=7121),\n",
       " (1221,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1221, model='delphi-llama2-100k', logprob_sum=-3174.6481983065605, count=1270),\n",
       " (1382,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1382, model='delphi-llama2-100k', logprob_sum=-5204.802939176559, count=855),\n",
       " (1302,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1302, model='delphi-llama2-100k', logprob_sum=-3796.945957660675, count=1010),\n",
       " (701,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=701, model='delphi-llama2-100k', logprob_sum=-14081.98167160526, count=3556),\n",
       " (450,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=450, model='delphi-llama2-100k', logprob_sum=-29137.373496366665, count=12349),\n",
       " (814,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=814, model='delphi-llama2-100k', logprob_sum=-6327.863778845407, count=3096),\n",
       " (1480,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1480, model='delphi-llama2-100k', logprob_sum=-2316.499329544604, count=610),\n",
       " (262,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=262, model='delphi-llama2-100k', logprob_sum=-9306.660396814346, count=1310),\n",
       " (568,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=568, model='delphi-llama2-100k', logprob_sum=-1158.646315611899, count=475),\n",
       " (1272,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1272, model='delphi-llama2-100k', logprob_sum=-1926.0024495143443, count=823),\n",
       " (731,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=731, model='delphi-llama2-100k', logprob_sum=-9015.632934570312, count=2509),\n",
       " (2647,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2647, model='delphi-llama2-100k', logprob_sum=-1403.0066959261894, count=244),\n",
       " (1314,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1314, model='delphi-llama2-100k', logprob_sum=-2658.159124620259, count=852),\n",
       " (1693,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1693, model='delphi-llama2-100k', logprob_sum=-2702.3159519732, count=718),\n",
       " (2230,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2230, model='delphi-llama2-100k', logprob_sum=-945.8058798089623, count=302),\n",
       " (1029,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1029, model='delphi-llama2-100k', logprob_sum=-10418.902546405792, count=1942),\n",
       " (3818,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=3818, model='delphi-llama2-100k', logprob_sum=-606.8049639388919, count=168),\n",
       " (2443,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2443, model='delphi-llama2-100k', logprob_sum=-1557.0764220952988, count=320),\n",
       " (1017,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1017, model='delphi-llama2-100k', logprob_sum=-6207.385980963707, count=1863),\n",
       " (1755,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1755, model='delphi-llama2-100k', logprob_sum=-3358.4420578479767, count=584),\n",
       " (825,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=825, model='delphi-llama2-100k', logprob_sum=-4725.254562386312, count=2367),\n",
       " (357,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=357, model='delphi-llama2-100k', logprob_sum=-6212.070720076561, count=1346),\n",
       " (427,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=427, model='delphi-llama2-100k', logprob_sum=-723.6197103820741, count=246),\n",
       " (3530,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=3530, model='delphi-llama2-100k', logprob_sum=-918.0692881345749, count=163),\n",
       " (586,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=586, model='delphi-llama2-100k', logprob_sum=-16950.932032316923, count=7007),\n",
       " (657,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=657, model='delphi-llama2-100k', logprob_sum=-20554.265035778284, count=5225),\n",
       " (1404,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1404, model='delphi-llama2-100k', logprob_sum=-4291.406599551439, count=971),\n",
       " (1018,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1018, model='delphi-llama2-100k', logprob_sum=-9902.88418239355, count=1980),\n",
       " (1202,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1202, model='delphi-llama2-100k', logprob_sum=-6601.859297126532, count=1437),\n",
       " (1710,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1710, model='delphi-llama2-100k', logprob_sum=-3034.2404901981354, count=497),\n",
       " (821,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=821, model='delphi-llama2-100k', logprob_sum=-7697.558165252209, count=2409),\n",
       " (594,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=594, model='delphi-llama2-100k', logprob_sum=-23807.836288541555, count=6585),\n",
       " (1261,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1261, model='delphi-llama2-100k', logprob_sum=-4648.193906053901, count=1232),\n",
       " (725,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=725, model='delphi-llama2-100k', logprob_sum=-10444.777920868248, count=3276),\n",
       " (1020,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1020, model='delphi-llama2-100k', logprob_sum=-4863.184776607901, count=1785),\n",
       " (730,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=730, model='delphi-llama2-100k', logprob_sum=-8863.048733770847, count=2554),\n",
       " (815,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=815, model='delphi-llama2-100k', logprob_sum=-9185.86094892025, count=2116),\n",
       " (1110,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1110, model='delphi-llama2-100k', logprob_sum=-6489.435090601444, count=1618),\n",
       " (842,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=842, model='delphi-llama2-100k', logprob_sum=-10646.777576819062, count=2876),\n",
       " (2658,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2658, model='delphi-llama2-100k', logprob_sum=-1722.4669892787933, count=256),\n",
       " (1462,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1462, model='delphi-llama2-100k', logprob_sum=-2127.460376739502, count=482),\n",
       " (1241,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1241, model='delphi-llama2-100k', logprob_sum=-6923.432750344276, count=1284),\n",
       " (462,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=462, model='delphi-llama2-100k', logprob_sum=-3645.6570844021626, count=1968),\n",
       " (1405,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1405, model='delphi-llama2-100k', logprob_sum=-3113.2579159736633, count=611),\n",
       " (1817,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1817, model='delphi-llama2-100k', logprob_sum=-3018.8957875967026, count=519),\n",
       " (1980,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1980, model='delphi-llama2-100k', logprob_sum=-1589.7109569311142, count=422),\n",
       " (1487,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1487, model='delphi-llama2-100k', logprob_sum=-2094.828843390569, count=860),\n",
       " (1094,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1094, model='delphi-llama2-100k', logprob_sum=-6738.794082283974, count=1562),\n",
       " (1517,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1517, model='delphi-llama2-100k', logprob_sum=-3601.2503717392683, count=855),\n",
       " (498,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=498, model='delphi-llama2-100k', logprob_sum=-20241.75321654603, count=11103),\n",
       " (1107,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1107, model='delphi-llama2-100k', logprob_sum=-6126.805188894272, count=1519),\n",
       " (3672,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=3672, model='delphi-llama2-100k', logprob_sum=-1251.4735803604126, count=167),\n",
       " (2191,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2191, model='delphi-llama2-100k', logprob_sum=-1428.5225713402033, count=366),\n",
       " (3898,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=3898, model='delphi-llama2-100k', logprob_sum=-597.3070337772369, count=89),\n",
       " (1131,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1131, model='delphi-llama2-100k', logprob_sum=-7375.407154560089, count=1452),\n",
       " (1836,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1836, model='delphi-llama2-100k', logprob_sum=-6325.126745950431, count=5292),\n",
       " (1364,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1364, model='delphi-llama2-100k', logprob_sum=-3115.8665163517, count=514),\n",
       " (1001,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1001, model='delphi-llama2-100k', logprob_sum=-6851.677026882768, count=1990),\n",
       " (1090,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1090, model='delphi-llama2-100k', logprob_sum=-6305.783476471901, count=1349),\n",
       " (2516,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2516, model='delphi-llama2-100k', logprob_sum=-706.3054519891739, count=126),\n",
       " (1218,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1218, model='delphi-llama2-100k', logprob_sum=-2888.9382662773132, count=830),\n",
       " (1096,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1096, model='delphi-llama2-100k', logprob_sum=-5793.4227721095085, count=1662),\n",
       " (775,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=775, model='delphi-llama2-100k', logprob_sum=-5059.705024719238, count=1058),\n",
       " (1820,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1820, model='delphi-llama2-100k', logprob_sum=-2512.8491899967194, count=559),\n",
       " (1260,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1260, model='delphi-llama2-100k', logprob_sum=-5797.3313945531845, count=1176),\n",
       " (605,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=605, model='delphi-llama2-100k', logprob_sum=-4158.309886932373, count=575),\n",
       " (516,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=516, model='delphi-llama2-100k', logprob_sum=-405.7205851152539, count=138),\n",
       " (809,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=809, model='delphi-llama2-100k', logprob_sum=-12846.751116514206, count=3052),\n",
       " (764,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=764, model='delphi-llama2-100k', logprob_sum=-11263.924876451492, count=3650),\n",
       " (645,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=645, model='delphi-llama2-100k', logprob_sum=-17790.848513484, count=4870),\n",
       " (2349,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2349, model='delphi-llama2-100k', logprob_sum=-1931.392012000084, count=338),\n",
       " (653,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=653, model='delphi-llama2-100k', logprob_sum=-20762.339582547545, count=5368),\n",
       " (909,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=909, model='delphi-llama2-100k', logprob_sum=-10092.528188765049, count=2507),\n",
       " (846,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=846, model='delphi-llama2-100k', logprob_sum=-11300.915365815163, count=2956),\n",
       " (1047,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1047, model='delphi-llama2-100k', logprob_sum=-1175.2865678071976, count=161),\n",
       " (266,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=266, model='delphi-llama2-100k', logprob_sum=-5593.6918564855005, count=6481),\n",
       " (301,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=301, model='delphi-llama2-100k', logprob_sum=-9176.896871061843, count=7651),\n",
       " (2486,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2486, model='delphi-llama2-100k', logprob_sum=-2028.4637231826782, count=282),\n",
       " (1268,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1268, model='delphi-llama2-100k', logprob_sum=-3669.2381577417254, count=1138),\n",
       " (2091,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2091, model='delphi-llama2-100k', logprob_sum=-1512.3486575484276, count=448),\n",
       " (955,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=955, model='delphi-llama2-100k', logprob_sum=-8390.048870801926, count=1988),\n",
       " (1636,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1636, model='delphi-llama2-100k', logprob_sum=-3166.935896754265, count=653),\n",
       " (1549,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1549, model='delphi-llama2-100k', logprob_sum=-2928.251664698124, count=750),\n",
       " (915,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=915, model='delphi-llama2-100k', logprob_sum=-1060.1276593208313, count=117),\n",
       " (932,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=932, model='delphi-llama2-100k', logprob_sum=-597.0804397240281, count=704),\n",
       " (759,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=759, model='delphi-llama2-100k', logprob_sum=-7308.42890083231, count=2739),\n",
       " (1166,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1166, model='delphi-llama2-100k', logprob_sum=-4633.856747150421, count=711),\n",
       " (2211,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2211, model='delphi-llama2-100k', logprob_sum=-2030.6029212474823, count=346),\n",
       " (976,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=976, model='delphi-llama2-100k', logprob_sum=-9183.460240125656, count=2071),\n",
       " (1463,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1463, model='delphi-llama2-100k', logprob_sum=-4652.948447525501, count=978),\n",
       " (1474,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1474, model='delphi-llama2-100k', logprob_sum=-1795.355498845689, count=988),\n",
       " (2272,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2272, model='delphi-llama2-100k', logprob_sum=-896.7507284246385, count=348),\n",
       " (673,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=673, model='delphi-llama2-100k', logprob_sum=-19810.950978577137, count=5008),\n",
       " (1005,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1005, model='delphi-llama2-100k', logprob_sum=-4520.86322221905, count=1199),\n",
       " (538,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=538, model='delphi-llama2-100k', logprob_sum=-31538.67856580019, count=8657),\n",
       " (824,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=824, model='delphi-llama2-100k', logprob_sum=-8354.322253774852, count=2912),\n",
       " (923,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=923, model='delphi-llama2-100k', logprob_sum=-11138.935138344765, count=2303),\n",
       " (1465,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1465, model='delphi-llama2-100k', logprob_sum=-3434.0721442997456, count=875),\n",
       " (1930,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1930, model='delphi-llama2-100k', logprob_sum=-242.83840324170887, count=187),\n",
       " (1982,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1982, model='delphi-llama2-100k', logprob_sum=-2785.8523013591766, count=357),\n",
       " (980,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=980, model='delphi-llama2-100k', logprob_sum=-637.5889285579324, count=285),\n",
       " (807,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=807, model='delphi-llama2-100k', logprob_sum=-9450.391783382744, count=3169),\n",
       " (704,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=704, model='delphi-llama2-100k', logprob_sum=-9167.220285087824, count=2088),\n",
       " (1882,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1882, model='delphi-llama2-100k', logprob_sum=-3123.370534658432, count=524),\n",
       " (1148,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1148, model='delphi-llama2-100k', logprob_sum=-5796.06705494225, count=1369),\n",
       " (689,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=689, model='delphi-llama2-100k', logprob_sum=-9071.99475744646, count=4703),\n",
       " (2522,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2522, model='delphi-llama2-100k', logprob_sum=-1513.5066010951996, count=261),\n",
       " (1247,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1247, model='delphi-llama2-100k', logprob_sum=-4965.64472746104, count=1276),\n",
       " (724,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=724, model='delphi-llama2-100k', logprob_sum=-10148.508767843246, count=2395),\n",
       " (1264,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1264, model='delphi-llama2-100k', logprob_sum=-5677.385695494711, count=1236),\n",
       " (1323,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1323, model='delphi-llama2-100k', logprob_sum=-5343.646439790726, count=1116),\n",
       " (792,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=792, model='delphi-llama2-100k', logprob_sum=-6668.939937423915, count=2827),\n",
       " (533,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=533, model='delphi-llama2-100k', logprob_sum=-22042.219335502014, count=8899),\n",
       " (636,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=636, model='delphi-llama2-100k', logprob_sum=-11344.706662595272, count=3857),\n",
       " (1337,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1337, model='delphi-llama2-100k', logprob_sum=-3796.315528988838, count=676),\n",
       " (565,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=565, model='delphi-llama2-100k', logprob_sum=-8044.124095737934, count=2198),\n",
       " (4024,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=4024, model='delphi-llama2-100k', logprob_sum=-5341.98062903923, count=3651),\n",
       " (692,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=692, model='delphi-llama2-100k', logprob_sum=-11764.073604404926, count=4166),\n",
       " (715,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=715, model='delphi-llama2-100k', logprob_sum=-6010.163973428309, count=1691),\n",
       " (272,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=272, model='delphi-llama2-100k', logprob_sum=-5787.141291379929, count=749),\n",
       " (797,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=797, model='delphi-llama2-100k', logprob_sum=-186.74510461091995, count=83),\n",
       " (276,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=276, model='delphi-llama2-100k', logprob_sum=-1539.2007136517204, count=747),\n",
       " (613,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=613, model='delphi-llama2-100k', logprob_sum=-397.24781187670305, count=181),\n",
       " (1403,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1403, model='delphi-llama2-100k', logprob_sum=-3765.747411504388, count=955),\n",
       " (2048,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2048, model='delphi-llama2-100k', logprob_sum=-2194.7518582344055, count=396),\n",
       " (706,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=706, model='delphi-llama2-100k', logprob_sum=-16767.537737242877, count=4552),\n",
       " (2692,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2692, model='delphi-llama2-100k', logprob_sum=-1966.6154422033578, count=1149),\n",
       " (1349,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1349, model='delphi-llama2-100k', logprob_sum=-4520.627306193113, count=892),\n",
       " (1393,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1393, model='delphi-llama2-100k', logprob_sum=-4260.95392164588, count=930),\n",
       " (1216,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1216, model='delphi-llama2-100k', logprob_sum=-2986.4596461057663, count=483),\n",
       " (1232,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1232, model='delphi-llama2-100k', logprob_sum=-4111.031245157123, count=1334),\n",
       " (1643,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1643, model='delphi-llama2-100k', logprob_sum=-3396.5283029079437, count=644),\n",
       " (853,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=853, model='delphi-llama2-100k', logprob_sum=-11145.76432056725, count=2776),\n",
       " (1599,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1599, model='delphi-llama2-100k', logprob_sum=-3698.2714478373528, count=689),\n",
       " (2197,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2197, model='delphi-llama2-100k', logprob_sum=-2167.5407140254974, count=300),\n",
       " (2358,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2358, model='delphi-llama2-100k', logprob_sum=-2032.1952424049377, count=323),\n",
       " (633,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=633, model='delphi-llama2-100k', logprob_sum=-11808.721346110106, count=3849),\n",
       " (1209,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1209, model='delphi-llama2-100k', logprob_sum=-6627.147490024567, count=1334),\n",
       " (2565,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2565, model='delphi-llama2-100k', logprob_sum=-1933.0761647224426, count=286),\n",
       " (1226,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1226, model='delphi-llama2-100k', logprob_sum=-4032.630728872493, count=1356),\n",
       " (2030,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2030, model='delphi-llama2-100k', logprob_sum=-2132.2532999515533, count=433),\n",
       " (1182,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1182, model='delphi-llama2-100k', logprob_sum=-6750.682844281197, count=1361),\n",
       " (1038,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1038, model='delphi-llama2-100k', logprob_sum=-8484.603376567364, count=1799),\n",
       " (683,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=683, model='delphi-llama2-100k', logprob_sum=-4420.851754710078, count=1449),\n",
       " (1093,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1093, model='delphi-llama2-100k', logprob_sum=-8543.067841768265, count=1623),\n",
       " (4061,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=4061, model='delphi-llama2-100k', logprob_sum=-8506.436921715736, count=2478),\n",
       " (491,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=491, model='delphi-llama2-100k', logprob_sum=-625.103045420954, count=3491),\n",
       " (1271,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1271, model='delphi-llama2-100k', logprob_sum=-5129.46991950646, count=1305),\n",
       " (476,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=476, model='delphi-llama2-100k', logprob_sum=-19247.56041847123, count=11376),\n",
       " (756,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=756, model='delphi-llama2-100k', logprob_sum=-11516.87780834362, count=3747),\n",
       " (1385,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1385, model='delphi-llama2-100k', logprob_sum=-4990.763309717178, count=1007),\n",
       " (1305,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1305, model='delphi-llama2-100k', logprob_sum=-1859.5130970478058, count=369),\n",
       " (604,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=604, model='delphi-llama2-100k', logprob_sum=-15802.774330470711, count=6559),\n",
       " (2083,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2083, model='delphi-llama2-100k', logprob_sum=-2678.5312284231186, count=438),\n",
       " (739,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=739, model='delphi-llama2-100k', logprob_sum=-14722.652121417224, count=3947),\n",
       " (1733,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1733, model='delphi-llama2-100k', logprob_sum=-2141.874392386526, count=521),\n",
       " (3115,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=3115, model='delphi-llama2-100k', logprob_sum=-823.6505477428436, count=186),\n",
       " (449,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=449, model='delphi-llama2-100k', logprob_sum=-17905.344113422558, count=4259),\n",
       " (3861,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=3861, model='delphi-llama2-100k', logprob_sum=-654.1336656212807, count=128),\n",
       " (2080,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2080, model='delphi-llama2-100k', logprob_sum=-138.66096484917216, count=373),\n",
       " (788,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=788, model='delphi-llama2-100k', logprob_sum=-11968.320081748068, count=3394),\n",
       " (905,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=905, model='delphi-llama2-100k', logprob_sum=-7390.679767767899, count=2538),\n",
       " (1483,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1483, model='delphi-llama2-100k', logprob_sum=-1483.0605947002769, count=901),\n",
       " (1071,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1071, model='delphi-llama2-100k', logprob_sum=-4192.770407736301, count=1600),\n",
       " (746,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=746, model='delphi-llama2-100k', logprob_sum=-9671.053739704192, count=3211),\n",
       " (1141,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1141, model='delphi-llama2-100k', logprob_sum=-5543.055844962597, count=1661),\n",
       " (852,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=852, model='delphi-llama2-100k', logprob_sum=-11642.345999479294, count=2866),\n",
       " (1072,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1072, model='delphi-llama2-100k', logprob_sum=-7991.914467930794, count=1657),\n",
       " (1447,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1447, model='delphi-llama2-100k', logprob_sum=-3456.5601902604103, count=534),\n",
       " (2481,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2481, model='delphi-llama2-100k', logprob_sum=-2022.725128531456, count=302),\n",
       " (902,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=902, model='delphi-llama2-100k', logprob_sum=-10053.48216292262, count=2523),\n",
       " (1490,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1490, model='delphi-llama2-100k', logprob_sum=-2704.937996864319, count=673),\n",
       " (1178,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1178, model='delphi-llama2-100k', logprob_sum=-4300.999971903861, count=1475),\n",
       " (2541,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2541, model='delphi-llama2-100k', logprob_sum=-1034.9234310984612, count=184),\n",
       " (878,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=878, model='delphi-llama2-100k', logprob_sum=-6486.283912036568, count=2915),\n",
       " (848,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=848, model='delphi-llama2-100k', logprob_sum=-7244.188932210207, count=2814),\n",
       " (2620,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2620, model='delphi-llama2-100k', logprob_sum=-1806.76385140419, count=281),\n",
       " (738,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=738, model='delphi-llama2-100k', logprob_sum=-158.8813919723034, count=76),\n",
       " (1990,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1990, model='delphi-llama2-100k', logprob_sum=-1836.9569410979748, count=461),\n",
       " (1010,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1010, model='delphi-llama2-100k', logprob_sum=-8695.252073705196, count=1934),\n",
       " (2458,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2458, model='delphi-llama2-100k', logprob_sum=-203.18482725135982, count=290),\n",
       " (1056,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1056, model='delphi-llama2-100k', logprob_sum=-7838.650790333748, count=1839),\n",
       " (2046,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2046, model='delphi-llama2-100k', logprob_sum=-1589.5197229236364, count=442),\n",
       " (1039,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1039, model='delphi-llama2-100k', logprob_sum=-7261.275014698505, count=1816),\n",
       " (535,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=535, model='delphi-llama2-100k', logprob_sum=-1126.4206538200378, count=122),\n",
       " (719,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=719, model='delphi-llama2-100k', logprob_sum=-2034.046761734644, count=997),\n",
       " (2707,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2707, model='delphi-llama2-100k', logprob_sum=-1797.975706577301, count=239),\n",
       " (2561,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2561, model='delphi-llama2-100k', logprob_sum=-1320.2702153921127, count=230),\n",
       " (383,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=383, model='delphi-llama2-100k', logprob_sum=-2658.2206756547384, count=1788),\n",
       " (2127,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2127, model='delphi-llama2-100k', logprob_sum=-1333.5202910006046, count=391),\n",
       " (554,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=554, model='delphi-llama2-100k', logprob_sum=-2432.9578932523727, count=343),\n",
       " (4031,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=4031, model='delphi-llama2-100k', logprob_sum=-2529.1984371677972, count=1512),\n",
       " (2110,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2110, model='delphi-llama2-100k', logprob_sum=-211.32732200808823, count=130),\n",
       " (910,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=910, model='delphi-llama2-100k', logprob_sum=-7578.088507577777, count=2157),\n",
       " (2063,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2063, model='delphi-llama2-100k', logprob_sum=-962.3318572342396, count=386),\n",
       " (3831,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=3831, model='delphi-llama2-100k', logprob_sum=-708.7487353980541, count=145),\n",
       " (1892,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1892, model='delphi-llama2-100k', logprob_sum=-1815.7969331741333, count=536),\n",
       " (2842,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2842, model='delphi-llama2-100k', logprob_sum=-1384.7729625701904, count=198),\n",
       " (652,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=652, model='delphi-llama2-100k', logprob_sum=-3122.8467658758163, count=517),\n",
       " (472,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=472, model='delphi-llama2-100k', logprob_sum=-329.1158164255321, count=196),\n",
       " (2305,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2305, model='delphi-llama2-100k', logprob_sum=-1456.6981826424599, count=315),\n",
       " (2834,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2834, model='delphi-llama2-100k', logprob_sum=-1622.7801704406738, count=229),\n",
       " (3723,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=3723, model='delphi-llama2-100k', logprob_sum=-887.5058240294456, count=159),\n",
       " (1340,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1340, model='delphi-llama2-100k', logprob_sum=-5547.9508854448795, count=896),\n",
       " (2319,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2319, model='delphi-llama2-100k', logprob_sum=-1515.1887340545654, count=314),\n",
       " (1003,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1003, model='delphi-llama2-100k', logprob_sum=-5621.860565140843, count=1462),\n",
       " (1076,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1076, model='delphi-llama2-100k', logprob_sum=-7961.067251801491, count=1689),\n",
       " (1053,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1053, model='delphi-llama2-100k', logprob_sum=-2831.606333255768, count=552),\n",
       " (3896,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=3896, model='delphi-llama2-100k', logprob_sum=-317.6953511759639, count=104),\n",
       " (2425,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2425, model='delphi-llama2-100k', logprob_sum=-1340.520313501358, count=296),\n",
       " (3886,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=3886, model='delphi-llama2-100k', logprob_sum=-622.9744794368744, count=112),\n",
       " (3625,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=3625, model='delphi-llama2-100k', logprob_sum=-793.9453880190849, count=135),\n",
       " (854,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=854, model='delphi-llama2-100k', logprob_sum=-13787.14383277297, count=2689),\n",
       " (1971,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1971, model='delphi-llama2-100k', logprob_sum=-2613.779897212982, count=433),\n",
       " (934,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=934, model='delphi-llama2-100k', logprob_sum=-10020.419447422028, count=2115),\n",
       " (3467,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=3467, model='delphi-llama2-100k', logprob_sum=-832.205245256424, count=166),\n",
       " (1025,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1025, model='delphi-llama2-100k', logprob_sum=-6748.387411594391, count=1867),\n",
       " (4067,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=4067, model='delphi-llama2-100k', logprob_sum=-5691.560409426689, count=1699),\n",
       " (817,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=817, model='delphi-llama2-100k', logprob_sum=-718.4851450808346, count=311),\n",
       " (919,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=919, model='delphi-llama2-100k', logprob_sum=-7779.461500175297, count=2295),\n",
       " (4036,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=4036, model='delphi-llama2-100k', logprob_sum=-3042.7639462219086, count=3483),\n",
       " (3393,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=3393, model='delphi-llama2-100k', logprob_sum=-63.12376618385315, count=33),\n",
       " (260,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=260, model='delphi-llama2-100k', logprob_sum=-2237.152949373238, count=1635),\n",
       " (2577,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2577, model='delphi-llama2-100k', logprob_sum=-1190.8162422776222, count=292),\n",
       " (2414,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2414, model='delphi-llama2-100k', logprob_sum=-2101.602922439575, count=317),\n",
       " (925,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=925, model='delphi-llama2-100k', logprob_sum=-8929.880057513714, count=2307),\n",
       " (1231,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1231, model='delphi-llama2-100k', logprob_sum=-3485.825465172529, count=1318),\n",
       " (1262,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1262, model='delphi-llama2-100k', logprob_sum=-2008.7460739836097, count=1226),\n",
       " (2227,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2227, model='delphi-llama2-100k', logprob_sum=-1502.4472715854645, count=315),\n",
       " (1255,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1255, model='delphi-llama2-100k', logprob_sum=-5828.74217915535, count=1123),\n",
       " (2534,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2534, model='delphi-llama2-100k', logprob_sum=-1157.5705277323723, count=234),\n",
       " (527,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=527, model='delphi-llama2-100k', logprob_sum=-14920.721382945776, count=5725),\n",
       " (2122,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2122, model='delphi-llama2-100k', logprob_sum=-2049.694171965122, count=369),\n",
       " (1445,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1445, model='delphi-llama2-100k', logprob_sum=-6109.52938914299, count=893),\n",
       " (1539,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1539, model='delphi-llama2-100k', logprob_sum=-3975.8637095838785, count=814),\n",
       " (2903,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2903, model='delphi-llama2-100k', logprob_sum=-1250.7933735847473, count=225),\n",
       " (1796,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1796, model='delphi-llama2-100k', logprob_sum=-2930.637407064438, count=551),\n",
       " (1401,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1401, model='delphi-llama2-100k', logprob_sum=-3918.5795146524906, count=961),\n",
       " (1350,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1350, model='delphi-llama2-100k', logprob_sum=-3943.679187953472, count=1083),\n",
       " (4051,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=4051, model='delphi-llama2-100k', logprob_sum=-8569.308701179922, count=3038),\n",
       " (2031,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2031, model='delphi-llama2-100k', logprob_sum=-1221.6091777086258, count=435),\n",
       " (1418,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1418, model='delphi-llama2-100k', logprob_sum=-4086.8566849827766, count=790),\n",
       " (1534,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1534, model='delphi-llama2-100k', logprob_sum=-3682.366121530533, count=790),\n",
       " (1322,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1322, model='delphi-llama2-100k', logprob_sum=-5901.978536486626, count=1123),\n",
       " (2969,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2969, model='delphi-llama2-100k', logprob_sum=-1072.410718291998, count=189),\n",
       " (3036,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=3036, model='delphi-llama2-100k', logprob_sum=-612.3802275508642, count=157),\n",
       " (776,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=776, model='delphi-llama2-100k', logprob_sum=-8739.850937515497, count=1747),\n",
       " (1297,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1297, model='delphi-llama2-100k', logprob_sum=-4158.724821165204, count=1129),\n",
       " (4063,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=4063, model='delphi-llama2-100k', logprob_sum=-5085.183257818222, count=1520),\n",
       " (2551,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2551, model='delphi-llama2-100k', logprob_sum=-1118.4261207580566, count=238),\n",
       " (1139,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1139, model='delphi-llama2-100k', logprob_sum=-4098.408808872104, count=1209),\n",
       " (969,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=969, model='delphi-llama2-100k', logprob_sum=-9569.083818852901, count=2216),\n",
       " (1251,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1251, model='delphi-llama2-100k', logprob_sum=-4961.535601139069, count=955),\n",
       " (2650,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2650, model='delphi-llama2-100k', logprob_sum=-615.1631603240967, count=82),\n",
       " (344,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=344, model='delphi-llama2-100k', logprob_sum=-468.8390092179179, count=140),\n",
       " (3918,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=3918, model='delphi-llama2-100k', logprob_sum=-1092.8294200897217, count=149),\n",
       " (1419,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1419, model='delphi-llama2-100k', logprob_sum=-4761.063318014145, count=968),\n",
       " (2546,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2546, model='delphi-llama2-100k', logprob_sum=-1711.6575446128845, count=264),\n",
       " (2229,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2229, model='delphi-llama2-100k', logprob_sum=-1664.6700387001038, count=341),\n",
       " (2774,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2774, model='delphi-llama2-100k', logprob_sum=-1611.8533606529236, count=235),\n",
       " (3479,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=3479, model='delphi-llama2-100k', logprob_sum=-54.84346267580986, count=25),\n",
       " (2148,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2148, model='delphi-llama2-100k', logprob_sum=-1885.3939434289932, count=364),\n",
       " (2131,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2131, model='delphi-llama2-100k', logprob_sum=-2289.123886346817, count=381),\n",
       " (2482,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2482, model='delphi-llama2-100k', logprob_sum=-1275.31146723032, count=283),\n",
       " (1565,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1565, model='delphi-llama2-100k', logprob_sum=-3972.658970117569, count=717),\n",
       " (868,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=868, model='delphi-llama2-100k', logprob_sum=-6762.41019654274, count=2036),\n",
       " (1117,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1117, model='delphi-llama2-100k', logprob_sum=-4023.4197190999985, count=1480),\n",
       " (2378,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2378, model='delphi-llama2-100k', logprob_sum=-1613.5758415460587, count=333),\n",
       " (289,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=289, model='delphi-llama2-100k', logprob_sum=-1645.4619087772444, count=1195),\n",
       " (2132,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2132, model='delphi-llama2-100k', logprob_sum=-1018.8165489435196, count=391),\n",
       " (1949,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1949, model='delphi-llama2-100k', logprob_sum=-215.50829401046212, count=476),\n",
       " (2402,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2402, model='delphi-llama2-100k', logprob_sum=-1340.3531565666199, count=313),\n",
       " (2579,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2579, model='delphi-llama2-100k', logprob_sum=-1084.5682094097137, count=253),\n",
       " (520,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=520, model='delphi-llama2-100k', logprob_sum=-749.8141468446702, count=299),\n",
       " (1665,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1665, model='delphi-llama2-100k', logprob_sum=-2870.319121271372, count=687),\n",
       " (1661,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1661, model='delphi-llama2-100k', logprob_sum=-1773.2476501464844, count=226),\n",
       " (1762,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1762, model='delphi-llama2-100k', logprob_sum=-251.4471630535554, count=257),\n",
       " (1812,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1812, model='delphi-llama2-100k', logprob_sum=-55.87101041153073, count=67),\n",
       " (2280,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2280, model='delphi-llama2-100k', logprob_sum=-1941.882511138916, count=348),\n",
       " (1177,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1177, model='delphi-llama2-100k', logprob_sum=-4719.400824606419, count=1430),\n",
       " (2009,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2009, model='delphi-llama2-100k', logprob_sum=-1985.4529242515564, count=460),\n",
       " (1888,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1888, model='delphi-llama2-100k', logprob_sum=-2585.855229973793, count=516),\n",
       " (1195,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1195, model='delphi-llama2-100k', logprob_sum=-4001.1089654788375, count=1304),\n",
       " (550,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=550, model='delphi-llama2-100k', logprob_sum=-352.58738604094833, count=262),\n",
       " (1567,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1567, model='delphi-llama2-100k', logprob_sum=-3160.3667735755444, count=718),\n",
       " (3015,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=3015, model='delphi-llama2-100k', logprob_sum=-1252.8975239992142, count=230),\n",
       " (639,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=639, model='delphi-llama2-100k', logprob_sum=-11373.802259892225, count=2959),\n",
       " (1353,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1353, model='delphi-llama2-100k', logprob_sum=-3254.749791767448, count=1118),\n",
       " (986,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=986, model='delphi-llama2-100k', logprob_sum=-2857.7152042984962, count=437),\n",
       " (1837,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1837, model='delphi-llama2-100k', logprob_sum=-561.3821570724249, count=320),\n",
       " (312,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=312, model='delphi-llama2-100k', logprob_sum=-1710.9673932418227, count=691),\n",
       " (3747,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=3747, model='delphi-llama2-100k', logprob_sum=-439.3148742429912, count=182),\n",
       " (2120,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2120, model='delphi-llama2-100k', logprob_sum=-1874.3518734890968, count=371),\n",
       " (3536,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=3536, model='delphi-llama2-100k', logprob_sum=-1185.283503651619, count=182),\n",
       " (944,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=944, model='delphi-llama2-100k', logprob_sum=-5495.980260483921, count=1653),\n",
       " (275,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=275, model='delphi-llama2-100k', logprob_sum=-2953.0693417685106, count=1969),\n",
       " (1784,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1784, model='delphi-llama2-100k', logprob_sum=-1146.7985130436718, count=564),\n",
       " (1304,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1304, model='delphi-llama2-100k', logprob_sum=-2584.590323805809, count=516),\n",
       " (3924,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=3924, model='delphi-llama2-100k', logprob_sum=-818.9477114006877, count=141),\n",
       " (2463,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2463, model='delphi-llama2-100k', logprob_sum=-1107.7914681434631, count=154),\n",
       " (523,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=523, model='delphi-llama2-100k', logprob_sum=-17272.41136990674, count=8381),\n",
       " (3100,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=3100, model='delphi-llama2-100k', logprob_sum=-2109.9810562431812, count=1012),\n",
       " (1055,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1055, model='delphi-llama2-100k', logprob_sum=-8205.555271208286, count=1688),\n",
       " (1603,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1603, model='delphi-llama2-100k', logprob_sum=-2618.235779516399, count=729),\n",
       " (1745,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1745, model='delphi-llama2-100k', logprob_sum=-2650.4246648214757, count=572),\n",
       " (1396,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1396, model='delphi-llama2-100k', logprob_sum=-1004.8351697195321, count=970),\n",
       " (1951,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1951, model='delphi-llama2-100k', logprob_sum=-1534.6263655722141, count=430),\n",
       " (3003,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=3003, model='delphi-llama2-100k', logprob_sum=-862.1240981221199, count=175),\n",
       " (1352,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1352, model='delphi-llama2-100k', logprob_sum=-6243.733981847763, count=1027),\n",
       " (1785,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1785, model='delphi-llama2-100k', logprob_sum=-2579.4890991300344, count=552),\n",
       " (1236,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1236, model='delphi-llama2-100k', logprob_sum=-4755.726889371872, count=896),\n",
       " (2356,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2356, model='delphi-llama2-100k', logprob_sum=-1837.9476552009583, count=306),\n",
       " (1078,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1078, model='delphi-llama2-100k', logprob_sum=-5068.498323623091, count=1826),\n",
       " (3014,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=3014, model='delphi-llama2-100k', logprob_sum=-1046.254275918007, count=213),\n",
       " (717,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=717, model='delphi-llama2-100k', logprob_sum=-2828.646458506584, count=402),\n",
       " (637,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=637, model='delphi-llama2-100k', logprob_sum=-1252.027179221157, count=694),\n",
       " (3383,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=3383, model='delphi-llama2-100k', logprob_sum=-291.9034098908305, count=79),\n",
       " (1427,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1427, model='delphi-llama2-100k', logprob_sum=-1292.7214970588684, count=176),\n",
       " (2320,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2320, model='delphi-llama2-100k', logprob_sum=-2327.0620925426483, count=350),\n",
       " (1122,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1122, model='delphi-llama2-100k', logprob_sum=-4869.249618887901, count=986),\n",
       " (2072,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2072, model='delphi-llama2-100k', logprob_sum=-1914.4101070016623, count=439),\n",
       " (1185,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1185, model='delphi-llama2-100k', logprob_sum=-3376.3816760629416, count=935),\n",
       " (4042,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=4042, model='delphi-llama2-100k', logprob_sum=-3285.432432520436, count=1391),\n",
       " (795,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=795, model='delphi-llama2-100k', logprob_sum=-885.2167172133923, count=491),\n",
       " (305,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=305, model='delphi-llama2-100k', logprob_sum=-2424.4274205765687, count=1522),\n",
       " (497,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=497, model='delphi-llama2-100k', logprob_sum=-16322.40117973159, count=10174),\n",
       " (1606,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1606, model='delphi-llama2-100k', logprob_sum=-2322.169058263302, count=727),\n",
       " (1412,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1412, model='delphi-llama2-100k', logprob_sum=-3767.982646584511, count=743),\n",
       " (1054,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1054, model='delphi-llama2-100k', logprob_sum=-7151.610437273979, count=1772),\n",
       " (3712,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=3712, model='delphi-llama2-100k', logprob_sum=-1247.4711604118347, count=174),\n",
       " (1507,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1507, model='delphi-llama2-100k', logprob_sum=-2768.7684977650642, count=845),\n",
       " (1203,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1203, model='delphi-llama2-100k', logprob_sum=-3292.097253460437, count=1417),\n",
       " (1342,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1342, model='delphi-llama2-100k', logprob_sum=-6774.071478366852, count=1089),\n",
       " (1514,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1514, model='delphi-llama2-100k', logprob_sum=-4329.362399175763, count=842),\n",
       " (1493,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1493, model='delphi-llama2-100k', logprob_sum=-2939.8798898682, count=896),\n",
       " (2469,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2469, model='delphi-llama2-100k', logprob_sum=-2065.7390422821045, count=297),\n",
       " (1084,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1084, model='delphi-llama2-100k', logprob_sum=-4418.810594821349, count=1795),\n",
       " (2715,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2715, model='delphi-llama2-100k', logprob_sum=-448.83725152909756, count=191),\n",
       " (1756,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1756, model='delphi-llama2-100k', logprob_sum=-2621.5370077462867, count=652),\n",
       " (263,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=263, model='delphi-llama2-100k', logprob_sum=-3839.567806005478, count=542),\n",
       " (1157,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1157, model='delphi-llama2-100k', logprob_sum=-3968.772450789809, count=1470),\n",
       " (2359,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2359, model='delphi-llama2-100k', logprob_sum=-1733.0244124531746, count=293),\n",
       " (4034,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=4034, model='delphi-llama2-100k', logprob_sum=-3671.9034178070724, count=1903),\n",
       " (1023,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1023, model='delphi-llama2-100k', logprob_sum=-92.27816715557128, count=151),\n",
       " (897,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=897, model='delphi-llama2-100k', logprob_sum=-1012.1815930306911, count=1149),\n",
       " (4000,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=4000, model='delphi-llama2-100k', logprob_sum=-794.4496877193451, count=136),\n",
       " (879,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=879, model='delphi-llama2-100k', logprob_sum=-10086.804143175483, count=2646),\n",
       " (1266,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1266, model='delphi-llama2-100k', logprob_sum=-2925.764499440789, count=1249),\n",
       " (3950,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=3950, model='delphi-llama2-100k', logprob_sum=-1125.179313659668, count=148),\n",
       " (3812,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=3812, model='delphi-llama2-100k', logprob_sum=-424.5452315211296, count=128),\n",
       " (1180,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1180, model='delphi-llama2-100k', logprob_sum=-3318.9322514533997, count=984),\n",
       " (768,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=768, model='delphi-llama2-100k', logprob_sum=-7015.992581598461, count=3161),\n",
       " (3143,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=3143, model='delphi-llama2-100k', logprob_sum=-515.6958132460713, count=154),\n",
       " (3213,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=3213, model='delphi-llama2-100k', logprob_sum=-976.6178696155548, count=167),\n",
       " (483,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=483, model='delphi-llama2-100k', logprob_sum=-1086.5239062956534, count=1185),\n",
       " (1908,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1908, model='delphi-llama2-100k', logprob_sum=-2524.2980412244797, count=475),\n",
       " (3301,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=3301, model='delphi-llama2-100k', logprob_sum=-1097.0615097433329, count=197),\n",
       " (2336,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2336, model='delphi-llama2-100k', logprob_sum=-1093.6240509748459, count=149),\n",
       " (464,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=464, model='delphi-llama2-100k', logprob_sum=-1565.5670303252991, count=893),\n",
       " (1145,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1145, model='delphi-llama2-100k', logprob_sum=-4229.624355897307, count=987),\n",
       " (931,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=931, model='delphi-llama2-100k', logprob_sum=-8404.748440235853, count=1930),\n",
       " (2163,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2163, model='delphi-llama2-100k', logprob_sum=-2222.173759639263, count=391),\n",
       " (1616,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1616, model='delphi-llama2-100k', logprob_sum=-3011.9846782684326, count=717),\n",
       " (3413,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=3413, model='delphi-llama2-100k', logprob_sum=-706.3409936055541, count=182),\n",
       " (1653,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1653, model='delphi-llama2-100k', logprob_sum=-1885.3896531853825, count=599),\n",
       " (2124,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2124, model='delphi-llama2-100k', logprob_sum=-1928.5158296823502, count=320),\n",
       " (1359,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1359, model='delphi-llama2-100k', logprob_sum=-2607.070877790451, count=401),\n",
       " (1657,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1657, model='delphi-llama2-100k', logprob_sum=-1429.7026089169085, count=460),\n",
       " (1043,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1043, model='delphi-llama2-100k', logprob_sum=-8289.824522256851, count=1774),\n",
       " (1808,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1808, model='delphi-llama2-100k', logprob_sum=-1338.4259524345398, count=318),\n",
       " (1092,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1092, model='delphi-llama2-100k', logprob_sum=-1996.3766329288483, count=252),\n",
       " (1773,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1773, model='delphi-llama2-100k', logprob_sum=-100.66139401495457, count=98),\n",
       " (951,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=951, model='delphi-llama2-100k', logprob_sum=-12170.364004135132, count=2191),\n",
       " (901,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=901, model='delphi-llama2-100k', logprob_sum=-5008.020214878023, count=2549),\n",
       " (1194,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1194, model='delphi-llama2-100k', logprob_sum=-6458.378993213177, count=1401),\n",
       " (2678,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2678, model='delphi-llama2-100k', logprob_sum=-2216.334189891815, count=300),\n",
       " (3765,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=3765, model='delphi-llama2-100k', logprob_sum=-451.17283295467496, count=122),\n",
       " (1099,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1099, model='delphi-llama2-100k', logprob_sum=-5349.251591205597, count=1611),\n",
       " (3728,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=3728, model='delphi-llama2-100k', logprob_sum=-49.79694843292236, count=7),\n",
       " (1746,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1746, model='delphi-llama2-100k', logprob_sum=-595.7220533281798, count=399),\n",
       " (1171,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1171, model='delphi-llama2-100k', logprob_sum=-5511.400970831513, count=2242),\n",
       " (851,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=851, model='delphi-llama2-100k', logprob_sum=-1598.4527583122253, count=187),\n",
       " (4044,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=4044, model='delphi-llama2-100k', logprob_sum=-2990.820124514401, count=1070),\n",
       " (285,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=285, model='delphi-llama2-100k', logprob_sum=-6348.961098249361, count=4620),\n",
       " (2473,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2473, model='delphi-llama2-100k', logprob_sum=-969.943589925766, count=120),\n",
       " (343,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=343, model='delphi-llama2-100k', logprob_sum=-1267.7956639416516, count=744),\n",
       " (2873,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2873, model='delphi-llama2-100k', logprob_sum=-1068.0826598405838, count=164),\n",
       " (1556,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1556, model='delphi-llama2-100k', logprob_sum=-3198.7975351810455, count=804),\n",
       " (2237,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2237, model='delphi-llama2-100k', logprob_sum=-1914.7229276299477, count=352),\n",
       " (1281,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1281, model='delphi-llama2-100k', logprob_sum=-4086.691268801689, count=1045),\n",
       " (3525,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=3525, model='delphi-llama2-100k', logprob_sum=-900.7228845357895, count=151),\n",
       " (1651,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1651, model='delphi-llama2-100k', logprob_sum=-3594.756610006094, count=716),\n",
       " (1912,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1912, model='delphi-llama2-100k', logprob_sum=-2785.4322422742844, count=482),\n",
       " (1032,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1032, model='delphi-llama2-100k', logprob_sum=-8138.2120667696, count=1795),\n",
       " (1467,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1467, model='delphi-llama2-100k', logprob_sum=-2313.310262709856, count=823),\n",
       " (1421,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1421, model='delphi-llama2-100k', logprob_sum=-2200.518232518807, count=871),\n",
       " (875,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=875, model='delphi-llama2-100k', logprob_sum=-10022.86004716158, count=2531),\n",
       " (3689,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=3689, model='delphi-llama2-100k', logprob_sum=-604.6344243884087, count=124),\n",
       " (4023,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=4023, model='delphi-llama2-100k', logprob_sum=-23337.65578430891, count=8061),\n",
       " (1743,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1743, model='delphi-llama2-100k', logprob_sum=-1547.7341242432594, count=607),\n",
       " (3654,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=3654, model='delphi-llama2-100k', logprob_sum=-991.908890247345, count=129),\n",
       " (1602,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1602, model='delphi-llama2-100k', logprob_sum=-71.21290039410815, count=122),\n",
       " (3784,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=3784, model='delphi-llama2-100k', logprob_sum=-486.4117602184415, count=119),\n",
       " (1391,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1391, model='delphi-llama2-100k', logprob_sum=-2798.48297894001, count=940),\n",
       " (3296,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=3296, model='delphi-llama2-100k', logprob_sum=-1040.216522693634, count=150),\n",
       " (664,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=664, model='delphi-llama2-100k', logprob_sum=-7749.875435689464, count=3298),\n",
       " (2390,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2390, model='delphi-llama2-100k', logprob_sum=-2375.3181646466255, count=394),\n",
       " (2806,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2806, model='delphi-llama2-100k', logprob_sum=-1043.5283753871918, count=239),\n",
       " (1334,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1334, model='delphi-llama2-100k', logprob_sum=-5118.550177693367, count=995),\n",
       " (569,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=569, model='delphi-llama2-100k', logprob_sum=-598.1507956769783, count=1036),\n",
       " (1320,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1320, model='delphi-llama2-100k', logprob_sum=-1172.1384066343307, count=157),\n",
       " (465,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=465, model='delphi-llama2-100k', logprob_sum=-860.6489907000214, count=807),\n",
       " (1387,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1387, model='delphi-llama2-100k', logprob_sum=-3141.134966611862, count=615),\n",
       " (2548,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2548, model='delphi-llama2-100k', logprob_sum=-1074.4558466672897, count=275),\n",
       " (1650,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1650, model='delphi-llama2-100k', logprob_sum=-2255.308063149452, count=677),\n",
       " (1127,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1127, model='delphi-llama2-100k', logprob_sum=-4934.3832372538745, count=1667),\n",
       " (1214,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1214, model='delphi-llama2-100k', logprob_sum=-2688.8107880353928, count=501),\n",
       " (3636,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=3636, model='delphi-llama2-100k', logprob_sum=-396.44870825111866, count=133),\n",
       " (3934,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=3934, model='delphi-llama2-100k', logprob_sum=-720.2628893852234, count=114),\n",
       " (2073,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2073, model='delphi-llama2-100k', logprob_sum=-2513.9665438234806, count=414),\n",
       " (2621,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2621, model='delphi-llama2-100k', logprob_sum=-2027.8145859241486, count=270),\n",
       " (441,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=441, model='delphi-llama2-100k', logprob_sum=-1101.204241017811, count=955),\n",
       " (841,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=841, model='delphi-llama2-100k', logprob_sum=-7059.607044234872, count=2092),\n",
       " (1547,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1547, model='delphi-llama2-100k', logprob_sum=-4114.647475108504, count=863),\n",
       " (1249,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1249, model='delphi-llama2-100k', logprob_sum=-677.5602903366089, count=84),\n",
       " (4041,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=4041, model='delphi-llama2-100k', logprob_sum=-1675.2652716415469, count=700),\n",
       " (2802,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2802, model='delphi-llama2-100k', logprob_sum=-1257.358142375946, count=179),\n",
       " (1153,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1153, model='delphi-llama2-100k', logprob_sum=-4203.573433160782, count=853),\n",
       " (3349,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=3349, model='delphi-llama2-100k', logprob_sum=-609.5447022169828, count=135),\n",
       " (1471,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1471, model='delphi-llama2-100k', logprob_sum=-4990.864207625389, count=862),\n",
       " (1206,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1206, model='delphi-llama2-100k', logprob_sum=-4624.713850103319, count=1198),\n",
       " (1886,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1886, model='delphi-llama2-100k', logprob_sum=-2873.5859706401825, count=518),\n",
       " (1799,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1799, model='delphi-llama2-100k', logprob_sum=-2447.88187456131, count=524),\n",
       " (3868,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=3868, model='delphi-llama2-100k', logprob_sum=-516.2025147676468, count=115),\n",
       " (1028,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1028, model='delphi-llama2-100k', logprob_sum=-5493.152322474867, count=1712),\n",
       " (3366,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=3366, model='delphi-llama2-100k', logprob_sum=-993.2808421850204, count=175),\n",
       " (2350,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2350, model='delphi-llama2-100k', logprob_sum=-1939.2694764137268, count=313),\n",
       " (355,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=355, model='delphi-llama2-100k', logprob_sum=-3279.0274902042, count=1212),\n",
       " (2638,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2638, model='delphi-llama2-100k', logprob_sum=-92.70454104221426, count=134),\n",
       " (1586,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1586, model='delphi-llama2-100k', logprob_sum=-2685.1207731962204, count=703),\n",
       " (1863,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1863, model='delphi-llama2-100k', logprob_sum=-2749.2007596492767, count=472),\n",
       " (1442,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1442, model='delphi-llama2-100k', logprob_sum=-3141.955788999796, count=904),\n",
       " (1027,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1027, model='delphi-llama2-100k', logprob_sum=-8326.395050317049, count=1866),\n",
       " (1589,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1589, model='delphi-llama2-100k', logprob_sum=-3905.99582862854, count=710),\n",
       " (839,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=839, model='delphi-llama2-100k', logprob_sum=-780.5965974330902, count=114),\n",
       " (1679,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1679, model='delphi-llama2-100k', logprob_sum=-406.24210410937667, count=214),\n",
       " (1717,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1717, model='delphi-llama2-100k', logprob_sum=-3588.1562358140945, count=574),\n",
       " (2807,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2807, model='delphi-llama2-100k', logprob_sum=-1240.9644985198975, count=217),\n",
       " (596,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=596, model='delphi-llama2-100k', logprob_sum=-10538.791454925202, count=5439),\n",
       " (907,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=907, model='delphi-llama2-100k', logprob_sum=-6968.834281593561, count=2351),\n",
       " (1444,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1444, model='delphi-llama2-100k', logprob_sum=-2206.912948739715, count=787),\n",
       " (1826,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1826, model='delphi-llama2-100k', logprob_sum=-1805.4039708264172, count=508),\n",
       " (4059,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=4059, model='delphi-llama2-100k', logprob_sum=-5341.269323520362, count=2247),\n",
       " (573,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=573, model='delphi-llama2-100k', logprob_sum=-634.7761718495749, count=1074),\n",
       " (828,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=828, model='delphi-llama2-100k', logprob_sum=-10067.153622264042, count=2937),\n",
       " (1165,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1165, model='delphi-llama2-100k', logprob_sum=-3684.3238293463364, count=1439),\n",
       " (4055,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=4055, model='delphi-llama2-100k', logprob_sum=-5397.457067206502, count=1867),\n",
       " (1344,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1344, model='delphi-llama2-100k', logprob_sum=-889.4867964461446, count=543),\n",
       " (2655,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2655, model='delphi-llama2-100k', logprob_sum=-1080.1601141691208, count=262),\n",
       " (1386,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1386, model='delphi-llama2-100k', logprob_sum=-2043.595105022192, count=1039),\n",
       " (2302,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2302, model='delphi-llama2-100k', logprob_sum=-392.0792577266693, count=57),\n",
       " (338,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=338, model='delphi-llama2-100k', logprob_sum=-611.0846292602364, count=827),\n",
       " (487,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=487, model='delphi-llama2-100k', logprob_sum=-997.6185164451599, count=111),\n",
       " (2024,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2024, model='delphi-llama2-100k', logprob_sum=-110.983309045434, count=57),\n",
       " (686,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=686, model='delphi-llama2-100k', logprob_sum=-1867.2651544511318, count=1301),\n",
       " (1660,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1660, model='delphi-llama2-100k', logprob_sum=-3029.2839945852757, count=679),\n",
       " (267,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=267, model='delphi-llama2-100k', logprob_sum=-8347.15430176258, count=1168),\n",
       " (987,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=987, model='delphi-llama2-100k', logprob_sum=-571.2953593507409, count=310),\n",
       " (1639,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1639, model='delphi-llama2-100k', logprob_sum=-4579.499507427216, count=722),\n",
       " (3055,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=3055, model='delphi-llama2-100k', logprob_sum=-1083.404188632965, count=167),\n",
       " (1560,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1560, model='delphi-llama2-100k', logprob_sum=-3867.851443991065, count=792),\n",
       " (3354,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=3354, model='delphi-llama2-100k', logprob_sum=-577.1102785654366, count=148),\n",
       " (960,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=960, model='delphi-llama2-100k', logprob_sum=-585.2586116790771, count=69),\n",
       " (597,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=597, model='delphi-llama2-100k', logprob_sum=-2363.3694630842656, count=1516),\n",
       " (3490,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=3490, model='delphi-llama2-100k', logprob_sum=-1742.027198843658, count=1146),\n",
       " (1132,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1132, model='delphi-llama2-100k', logprob_sum=-7148.314822494984, count=1542),\n",
       " (2934,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2934, model='delphi-llama2-100k', logprob_sum=-1635.4573335647583, count=209),\n",
       " (1862,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1862, model='delphi-llama2-100k', logprob_sum=-1770.6414031982422, count=307),\n",
       " (1265,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1265, model='delphi-llama2-100k', logprob_sum=-308.25892279855907, count=174),\n",
       " (979,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=979, model='delphi-llama2-100k', logprob_sum=-4051.2449672222137, count=822),\n",
       " (1187,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1187, model='delphi-llama2-100k', logprob_sum=-4071.7378336787224, count=1269),\n",
       " (281,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=281, model='delphi-llama2-100k', logprob_sum=-8297.3967705369, count=1361),\n",
       " (1855,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1855, model='delphi-llama2-100k', logprob_sum=-390.02505215257406, count=186),\n",
       " (3471,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=3471, model='delphi-llama2-100k', logprob_sum=-487.4709407389164, count=157),\n",
       " (3071,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=3071, model='delphi-llama2-100k', logprob_sum=-1159.7198627591133, count=196),\n",
       " (1046,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1046, model='delphi-llama2-100k', logprob_sum=-7438.452930390835, count=1520),\n",
       " (3011,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=3011, model='delphi-llama2-100k', logprob_sum=-1143.9602987766266, count=168),\n",
       " (1431,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1431, model='delphi-llama2-100k', logprob_sum=-5053.209922611713, count=911),\n",
       " (278,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=278, model='delphi-llama2-100k', logprob_sum=-6098.452402561903, count=936),\n",
       " (1896,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1896, model='delphi-llama2-100k', logprob_sum=-178.51549424417317, count=166),\n",
       " (1335,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1335, model='delphi-llama2-100k', logprob_sum=-4724.1293196082115, count=1025),\n",
       " (1227,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1227, model='delphi-llama2-100k', logprob_sum=-6377.813080787659, count=1286),\n",
       " (2256,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2256, model='delphi-llama2-100k', logprob_sum=-1427.4736187458038, count=333),\n",
       " (1778,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1778, model='delphi-llama2-100k', logprob_sum=-3686.9905869960785, count=581),\n",
       " (456,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=456, model='delphi-llama2-100k', logprob_sum=-1708.135295715183, count=595),\n",
       " (1945,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1945, model='delphi-llama2-100k', logprob_sum=-1609.3125493973494, count=430),\n",
       " (339,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=339, model='delphi-llama2-100k', logprob_sum=-6704.642053604126, count=989),\n",
       " (1192,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1192, model='delphi-llama2-100k', logprob_sum=-1214.8747129142284, count=481),\n",
       " (570,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=570, model='delphi-llama2-100k', logprob_sum=-12408.502558949403, count=7116),\n",
       " (1824,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1824, model='delphi-llama2-100k', logprob_sum=-2123.7244272232056, count=261),\n",
       " (3227,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=3227, model='delphi-llama2-100k', logprob_sum=-1448.2362468242645, count=194),\n",
       " (1089,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1089, model='delphi-llama2-100k', logprob_sum=-3798.323500096798, count=893),\n",
       " (1173,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1173, model='delphi-llama2-100k', logprob_sum=-3289.412954659201, count=1387),\n",
       " (3785,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=3785, model='delphi-llama2-100k', logprob_sum=-1405.3413321189582, count=786),\n",
       " (900,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=900, model='delphi-llama2-100k', logprob_sum=-11096.467710614204, count=2506),\n",
       " (1731,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1731, model='delphi-llama2-100k', logprob_sum=-2546.2428892850876, count=529),\n",
       " (1348,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1348, model='delphi-llama2-100k', logprob_sum=-4604.947605192661, count=1049),\n",
       " (2403,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2403, model='delphi-llama2-100k', logprob_sum=-1754.7588422298431, count=312),\n",
       " (2235,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2235, model='delphi-llama2-100k', logprob_sum=-1366.152880936861, count=305),\n",
       " (2527,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2527, model='delphi-llama2-100k', logprob_sum=-1280.1128400713205, count=288),\n",
       " (2095,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2095, model='delphi-llama2-100k', logprob_sum=-1693.1915818452835, count=217),\n",
       " (3833,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=3833, model='delphi-llama2-100k', logprob_sum=-915.2295768260956, count=127),\n",
       " (1920,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1920, model='delphi-llama2-100k', logprob_sum=-421.35233427770436, count=308),\n",
       " (1697,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1697, model='delphi-llama2-100k', logprob_sum=-2962.1595393419266, count=603),\n",
       " (864,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=864, model='delphi-llama2-100k', logprob_sum=-5924.80203795433, count=1572),\n",
       " (1109,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1109, model='delphi-llama2-100k', logprob_sum=-355.1217526749242, count=179),\n",
       " (679,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=679, model='delphi-llama2-100k', logprob_sum=-3811.8727449290454, count=998),\n",
       " (1502,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1502, model='delphi-llama2-100k', logprob_sum=-5106.986915111542, count=866),\n",
       " (727,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=727, model='delphi-llama2-100k', logprob_sum=-16719.37145012617, count=3940),\n",
       " (1230,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1230, model='delphi-llama2-100k', logprob_sum=-2995.6691032350063, count=809),\n",
       " (1552,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1552, model='delphi-llama2-100k', logprob_sum=-1459.262725982815, count=335),\n",
       " (882,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=882, model='delphi-llama2-100k', logprob_sum=-4175.971992403269, count=1508),\n",
       " (3065,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=3065, model='delphi-llama2-100k', logprob_sum=-336.7222774550319, count=205),\n",
       " (1488,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1488, model='delphi-llama2-100k', logprob_sum=-1643.6780729293823, count=248),\n",
       " (1944,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1944, model='delphi-llama2-100k', logprob_sum=-2073.441962093115, count=458),\n",
       " (2128,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2128, model='delphi-llama2-100k', logprob_sum=-1841.401721417904, count=371),\n",
       " (3627,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=3627, model='delphi-llama2-100k', logprob_sum=-710.0667911022902, count=140),\n",
       " (2372,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2372, model='delphi-llama2-100k', logprob_sum=-1708.6292881965637, count=268),\n",
       " (2265,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2265, model='delphi-llama2-100k', logprob_sum=-2054.8821872472763, count=328),\n",
       " (2134,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2134, model='delphi-llama2-100k', logprob_sum=-1124.047482907772, count=388),\n",
       " (2057,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2057, model='delphi-llama2-100k', logprob_sum=-1797.3539779186249, count=385),\n",
       " (3343,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=3343, model='delphi-llama2-100k', logprob_sum=-838.2848196551204, count=170),\n",
       " (3438,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=3438, model='delphi-llama2-100k', logprob_sum=-1144.9556939601898, count=174),\n",
       " (914,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=914, model='delphi-llama2-100k', logprob_sum=-1692.7709555625916, count=210),\n",
       " (2589,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2589, model='delphi-llama2-100k', logprob_sum=-140.97477054595947, count=40),\n",
       " (3224,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=3224, model='delphi-llama2-100k', logprob_sum=-967.5885062217712, count=172),\n",
       " (2862,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2862, model='delphi-llama2-100k', logprob_sum=-961.847348690033, count=220),\n",
       " (956,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=956, model='delphi-llama2-100k', logprob_sum=-1141.0806809335481, count=1184),\n",
       " (287,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=287, model='delphi-llama2-100k', logprob_sum=-896.2839891588665, count=1233),\n",
       " (4077,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=4077, model='delphi-llama2-100k', logprob_sum=-4632.497534540482, count=1451),\n",
       " (295,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=295, model='delphi-llama2-100k', logprob_sum=-1862.435615960043, count=1044),\n",
       " (584,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=584, model='delphi-llama2-100k', logprob_sum=-145.04674738645554, count=44),\n",
       " (922,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=922, model='delphi-llama2-100k', logprob_sum=-8862.35280328989, count=2420),\n",
       " (1698,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1698, model='delphi-llama2-100k', logprob_sum=-3970.4810004234314, count=628),\n",
       " (1955,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1955, model='delphi-llama2-100k', logprob_sum=-1681.8016708493233, count=420),\n",
       " (1885,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1885, model='delphi-llama2-100k', logprob_sum=-3000.6017532348633, count=505),\n",
       " (703,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=703, model='delphi-llama2-100k', logprob_sum=-4394.24206328392, count=592),\n",
       " (1191,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1191, model='delphi-llama2-100k', logprob_sum=-87.18482914566994, count=77),\n",
       " (1392,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1392, model='delphi-llama2-100k', logprob_sum=-2741.982652425766, count=403),\n",
       " (3740,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=3740, model='delphi-llama2-100k', logprob_sum=-583.9839676618576, count=127),\n",
       " (863,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=863, model='delphi-llama2-100k', logprob_sum=-371.4106786251068, count=52),\n",
       " (382,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=382, model='delphi-llama2-100k', logprob_sum=-1175.2377057550475, count=722),\n",
       " (2998,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2998, model='delphi-llama2-100k', logprob_sum=-914.1990628242493, count=181),\n",
       " (1031,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1031, model='delphi-llama2-100k', logprob_sum=-8665.604760169983, count=1756),\n",
       " (1220,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1220, model='delphi-llama2-100k', logprob_sum=-4603.097181797028, count=1383),\n",
       " (3597,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=3597, model='delphi-llama2-100k', logprob_sum=-281.62703791819513, count=99),\n",
       " (1805,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1805, model='delphi-llama2-100k', logprob_sum=-1303.0068073123693, count=571),\n",
       " (1200,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1200, model='delphi-llama2-100k', logprob_sum=-5637.2945817783475, count=1475),\n",
       " (1375,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1375, model='delphi-llama2-100k', logprob_sum=-1245.7792933518067, count=1014),\n",
       " (2016,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2016, model='delphi-llama2-100k', logprob_sum=-1815.0382849127054, count=462),\n",
       " (2602,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2602, model='delphi-llama2-100k', logprob_sum=-1210.3735783398151, count=293),\n",
       " (1625,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1625, model='delphi-llama2-100k', logprob_sum=-2533.1443884968758, count=635),\n",
       " (3258,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=3258, model='delphi-llama2-100k', logprob_sum=-737.5374999046326, count=132),\n",
       " (2609,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2609, model='delphi-llama2-100k', logprob_sum=-550.9463510513306, count=64),\n",
       " (1527,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1527, model='delphi-llama2-100k', logprob_sum=-4041.8443641662598, count=821),\n",
       " (3331,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=3331, model='delphi-llama2-100k', logprob_sum=-701.8182585835457, count=124),\n",
       " (609,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=609, model='delphi-llama2-100k', logprob_sum=-967.5907943500206, count=422),\n",
       " (2512,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2512, model='delphi-llama2-100k', logprob_sum=-1719.9307672977448, count=272),\n",
       " (1750,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1750, model='delphi-llama2-100k', logprob_sum=-1470.8066062126309, count=372),\n",
       " (2699,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2699, model='delphi-llama2-100k', logprob_sum=-61.93770158290863, count=111),\n",
       " (3982,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=3982, model='delphi-llama2-100k', logprob_sum=-964.7867705821991, count=126),\n",
       " (629,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=629, model='delphi-llama2-100k', logprob_sum=-1064.1186320334673, count=379),\n",
       " (365,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=365, model='delphi-llama2-100k', logprob_sum=-303.8342600171454, count=216),\n",
       " (1932,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1932, model='delphi-llama2-100k', logprob_sum=-3382.9536044597626, count=449),\n",
       " (1330,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1330, model='delphi-llama2-100k', logprob_sum=-5772.709188342094, count=1126),\n",
       " (2683,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=2683, model='delphi-llama2-100k', logprob_sum=-1352.1042934656143, count=242),\n",
       " (958,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=958, model='delphi-llama2-100k', logprob_sum=-6388.08905506134, count=1298),\n",
       " (1783,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1783, model='delphi-llama2-100k', logprob_sum=-3560.6147129535675, count=577),\n",
       " (865,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=865, model='delphi-llama2-100k', logprob_sum=-316.8978683874011, count=220),\n",
       " (361,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=361, model='delphi-llama2-100k', logprob_sum=-968.9530051313341, count=302),\n",
       " (3999,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=3999, model='delphi-llama2-100k', logprob_sum=-103.31581072509289, count=132),\n",
       " (1655,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=1655, model='delphi-llama2-100k', logprob_sum=-3779.8852033615112, count=626),\n",
       " (3580,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=3580, model='delphi-llama2-100k', logprob_sum=-925.0357971191406, count=156),\n",
       " (265,\n",
       "  'delphi-llama2-100k'): TokenModelStats(token=265, model='delphi-llama2-100k', logprob_sum=-1369.0522428031545, count=782),\n",
       " ...}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_model_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert token_model_stats to a DataFrame with four columns\n",
    "\n",
    "import pandas as pd\n",
    "tms_df = pd.DataFrame(\n",
    "    [key + ( value.logprob_sum, value.count ) for key, value in model_token_stats.items()],\n",
    "    columns=[\"token\", \"model\", \"logprob_sum\", \"count\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/jaidhyani/delphi/notebooks'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "tms_df.to_csv(\"../data/token_model_stats.csv\", index=False, compression=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tinyevals",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
