{
  "run_name": "2024_03_15_21_56_35",
  "output_dir": "/Users/jaidhyani/Library/Application Support/delphi",
  "device": "auto",
  "eval_interval": 2000,
  "log_interval": 1,
  "eval_iters": 100,
  "eval_only": false,
  "always_save_checkpoint": false,
  "init_from": "scratch",
  "wandb_config": {
    "log": false,
    "project": "delphi",
    "entity": "set_wandb.entity_to_your_wandb_username_to_make_wandb_logging_work"
  },
  "batch_size": 64,
  "max_seq_len": 512,
  "model_config": {
    "model_type": "mamba",
    "mamba": {
      "vocab_size": 4096,
      "hidden_size": 768,
      "state_size": 16,
      "num_hidden_layers": 32,
      "conv_kernel": 4,
      "expand": 2,
      "use_bias": false,
      "use_conv_bias": true,
      "bos_token_id": 0,
      "eos_token_id": 0,
      "pad_token_id": 0,
      "time_step_rank": "auto",
      "time_step_scale": 1.0,
      "time_step_min": 0.001,
      "time_step_max": 0.1,
      "time_step_init_scheme": "random",
      "time_step_floor": 0.0001,
      "layer_norm_epsilon": 1e-05,
      "hidden_act": "silu",
      "initializer_range": 0.1,
      "residual_in_fp32": true,
      "rescale_prenorm_residual": false,
      "use_cache": true,
      "tie_word_embeddings": true
    }
  },
  "max_epochs": 10,
  "grad_clip": 1.0,
  "optimizer": {
    "gradient_accumulation_steps": 4,
    "learning_rate": 0.0005,
    "weight_decay": 0.1,
    "beta1": 0.9,
    "beta2": 0.95,
    "grad_clip": 1.0,
    "decay_lr": true,
    "warmup_iters": 1000,
    "min_lr": 0.0
  },
  "train_sample_limit": -1,
  "val_sample_limit": -1
}